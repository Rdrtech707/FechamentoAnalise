================================================================================
PROJETO RECEBIMENTOS - ARQUIVOS COMPLETOS
================================================================================
Total de arquivos: 24
================================================================================


================================================================================
ARQUIVO 1/24: .gitignore
TAMANHO: 0.52 KB
================================================================================

# Ambiente virtual
venv/
env/
ENV/

# Arquivos Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Arquivos de configura√ß√£o local
.env
.env.local
.env.development.local
.env.test.local
.env.production.local

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# Logs
*.log

# Arquivos tempor√°rios
*.tmp
*.temp

# Arquivos de dados gerados
*.xlsx
*.xls
*.csv
output/

================================================================================
ARQUIVO 2/24: INSTRUCOES_AUDITORIA.md
TAMANHO: 6.13 KB
================================================================================

# üìã Instru√ß√µes para Auditoria de Dados - TABELA RECEBIMENTOS

Este documento explica como usar o m√≥dulo de auditoria para comparar dados CSV com os dados gerados pela aplica√ß√£o.

## üéØ O que √© a Auditoria?

O m√≥dulo de auditoria permite:
- **Comparar** dados de um arquivo CSV com os dados gerados pela aplica√ß√£o
- **Identificar** discrep√¢ncias entre os valores
- **Gerar relat√≥rios** detalhados das diferen√ßas encontradas
- **Validar** a precis√£o dos dados processados

## üìÅ Arquivos do M√≥dulo

- `modules/auditor.py` - M√≥dulo principal de auditoria
- `audit_example.py` - Exemplo de uso
- `INSTRUCOES_AUDITORIA.md` - Esta documenta√ß√£o

## üöÄ Como Usar

### 1. Preparar o Arquivo CSV

Crie um arquivo CSV com os dados que voc√™ quer comparar. Exemplo:

```csv
numero_os,data_pagamento,valor_total,valor_pago,valor_devedor,cartao,dinheiro,pix,troco,placa_veiculo,codigo_cliente,data_encerramento
001,2024-01-15,1000.50,1000.50,0.00,500.25,300.25,200.00,0.00,ABC1234,CLI001,2024-01-15
002,2024-01-16,2500.75,2400.75,100.00,1200.00,800.75,400.00,0.00,XYZ5678,CLI002,2024-01-16
```

### 2. Configurar o Mapeamento de Campos

No arquivo `audit_example.py`, ajuste o mapeamento de campos:

```python
field_mappings = {
    'numero_os': 'N¬∞ OS',                    # Campo CSV -> Campo Gerado
    'data_pagamento': 'DATA PGTO',
    'valor_total': 'VALOR TOTAL',
    'valor_pago': 'VALOR PAGO',
    'valor_devedor': 'DEVEDOR',
    'cartao': 'CART√ÉO',
    'dinheiro': 'DINHEIRO',
    'pix': 'PIX',
    'troco': 'TROCO',
    'placa_veiculo': 'VE√çCULO (PLACA)',
    'codigo_cliente': 'C√ìDIGO CLIENTE',
    'data_encerramento': 'DATA ENCERRAMENTO'
}
```

### 3. Executar a Auditoria

```bash
python audit_example.py
```

## ‚öôÔ∏è Configura√ß√µes

### Toler√¢ncia para Valores Num√©ricos

```python
# 1% de toler√¢ncia (padr√£o)
auditor = DataAuditor(tolerance_percentage=0.01)

# 5% de toler√¢ncia
auditor = DataAuditor(tolerance_percentage=0.05)

# Sem toler√¢ncia (valores devem ser id√™nticos)
auditor = DataAuditor(tolerance_percentage=0.0)
```

### Campo Chave

Define qual campo usar para relacionar registros:

```python
# Usar N¬∞ OS como chave
key_field='N¬∞ OS'

# Usar c√≥digo do cliente como chave
key_field='C√ìDIGO CLIENTE'
```

## üìä Tipos de Compara√ß√£o

### 1. Valores Num√©ricos
- **Campos**: VALOR TOTAL, VALOR PAGO, DEVEDOR, CART√ÉO, DINHEIRO, PIX, TROCO
- **Compara√ß√£o**: Com toler√¢ncia percentual
- **Exemplo**: Se toler√¢ncia = 1%, valores 100.00 e 101.00 s√£o considerados iguais

### 2. Datas
- **Campos**: DATA PGTO, DATA ENCERRAMENTO
- **Compara√ß√£o**: Exata (mesmo dia)
- **Formatos aceitos**: Qualquer formato reconhecido pelo pandas

### 3. Texto
- **Campos**: N¬∞ OS, VE√çCULO (PLACA), C√ìDIGO CLIENTE
- **Compara√ß√£o**: Exata (ignora mai√∫sculas/min√∫sculas)
- **Exemplo**: "ABC1234" = "abc1234"

## üìà Relat√≥rios Gerados

### 1. Resumo
- Total de registros verificados
- Registros coincidentes/divergentes
- Taxa de sucesso
- Configura√ß√µes usadas

### 2. Detalhes
- Todos os campos verificados
- Valores CSV vs Gerado
- Indicador de coincid√™ncia
- Diferen√ßas encontradas

### 3. Diverg√™ncias
- Apenas campos com diferen√ßas
- Detalhes das discrep√¢ncias
- Observa√ß√µes explicativas

## üîß Exemplo Completo

```python
from modules.auditor import DataAuditor

# Inicializa auditor
auditor = DataAuditor(tolerance_percentage=0.01)

# Define mapeamento
field_mappings = {
    'numero_os': 'N¬∞ OS',
    'valor_total': 'VALOR TOTAL',
    'valor_pago': 'VALOR PAGO'
}

# Executa auditoria
summary, results = auditor.audit_data(
    csv_file_path='meus_dados.csv',
    generated_file_path='Recebimentos_2024-01.xlsx',
    field_mappings=field_mappings,
    key_field='N¬∞ OS'
)

# Gera relat√≥rio
auditor.generate_audit_report(summary, results, 'relatorio.xlsx')
```

## ‚ö†Ô∏è Dicas Importantes

### 1. Prepara√ß√£o dos Dados
- **CSV**: Use encoding UTF-8 ou Latin1
- **Campos num√©ricos**: Use ponto como separador decimal
- **Datas**: Use formato consistente (YYYY-MM-DD recomendado)

### 2. Mapeamento de Campos
- **Nomes exatos**: Os nomes devem corresponder aos do arquivo gerado
- **Case sensitive**: "N¬∞ OS" ‚â† "n¬∞ os"
- **Espa√ßos**: "VALOR TOTAL" ‚â† "VALOR_TOTAL"

### 3. Campo Chave
- **√önico**: Cada valor deve aparecer apenas uma vez
- **Presente**: Deve existir em ambos os arquivos
- **Consistente**: Mesmo formato em CSV e Excel

## üö® Solu√ß√£o de Problemas

### Erro: "Campo n√£o encontrado"
**Problema**: Campo do mapeamento n√£o existe no arquivo
**Solu√ß√£o**: Verifique o nome exato do campo no arquivo

### Erro: "Registro n√£o encontrado"
**Problema**: Valor do campo chave n√£o existe no arquivo gerado
**Solu√ß√£o**: Verifique se o registro foi processado pela aplica√ß√£o

### Erro: "Erro na convers√£o num√©rica"
**Problema**: Campo num√©rico cont√©m texto
**Solu√ß√£o**: Limpe os dados CSV antes da auditoria

### Erro: "Erro na convers√£o de data"
**Problema**: Formato de data n√£o reconhecido
**Solu√ß√£o**: Padronize o formato de datas no CSV

## üìã Checklist de Auditoria

Antes de executar:

- [ ] Arquivo CSV existe e √© leg√≠vel
- [ ] Arquivo Excel gerado existe
- [ ] Mapeamento de campos est√° correto
- [ ] Campo chave √© √∫nico e consistente
- [ ] Toler√¢ncia configurada adequadamente
- [ ] Encoding do CSV √© compat√≠vel

## üéØ Casos de Uso

### 1. Valida√ß√£o de Processamento
- Comparar dados originais com dados processados
- Verificar se c√°lculos est√£o corretos
- Identificar registros n√£o processados

### 2. Auditoria Cont√°bil
- Validar valores monet√°rios
- Verificar formas de pagamento
- Confirmar datas de transa√ß√£o

### 3. Controle de Qualidade
- Detectar inconsist√™ncias
- Validar integridade dos dados
- Gerar relat√≥rios de conformidade

## üìû Suporte

Se encontrar problemas:
1. Verifique os logs no console
2. Confirme se os arquivos existem
3. Valide o mapeamento de campos
4. Teste com dados menores primeiro

---

**üéâ Agora voc√™ pode auditar seus dados com precis√£o e gerar relat√≥rios detalhados!** 

================================================================================
ARQUIVO 3/24: INSTRUCOES_STYLE_CONFIG.md
TAMANHO: 7.45 KB
================================================================================

# üìã Instru√ß√µes para Configura√ß√£o de Estilos - TABELA RECEBIMENTOS

Este arquivo cont√©m instru√ß√µes detalhadas para leigos modificarem o arquivo `style_config.py` e personalizarem a apar√™ncia dos relat√≥rios Excel gerados pelo sistema.

## üìÅ Arquivo: `style_config.py`

Este arquivo controla TODOS os aspectos visuais dos relat√≥rios Excel:
- **Cores** (cabe√ßalhos, dados, fundos)
- **Formatos** (moeda, data, n√∫meros)
- **Largura das colunas**
- **Bordas** (estilos e cores)
- **Temas** (conjuntos de configura√ß√µes)

---

## üé® 1. CONFIGURA√á√ÉO DE CORES

### 1.1 Tabela de Cores Dispon√≠veis

| Cor | C√≥digo | Nome |
|-----|--------|------|
| üî¥ | `FF0000` | Vermelho |
| üü¢ | `00FF00` | Verde |
| üîµ | `0000FF` | Azul |
| ‚ö´ | `000000` | Preto |
| ‚ö™ | `FFFFFF` | Branco |
| üü° | `FFFF00` | Amarelo |
| üü† | `FFA500` | Laranja |
| üü£ | `800080` | Roxo |
| üü§ | `8B4513` | Marrom |
| üîò | `808080` | Cinza |
| üîµ | `1F4E78` | Azul Escuro |
| üü¢ | `90EE90` | Verde Claro |
| üü° | `F2F2F2` | Cinza Claro |

### 1.2 Como Alterar Cores

**Exemplo:** Para mudar a cor do cabe√ßalho para azul escuro:

```python
THEMES = {
    'default': {
        'header_bg': '1F4E78',  # Azul escuro
        'header_font': 'FFFFFF',  # Texto branco
        'contabil_bg': 'F2F2F2',  # Fundo cinza claro
        'contabil_font': '000000',  # Texto preto
    }
}
```

---

## üìè 2. CONFIGURA√á√ÉO DE LARGURA DAS COLUNAS

### 2.1 Como Ajustar a Largura

A se√ß√£o `COLUMN_WIDTHS` controla a largura de cada coluna:

```python
COLUMN_WIDTHS = {
    'N¬∞ OS': 12,              # Largura 12 para coluna N¬∞ OS
    'DATA ENCERRAMENTO': 18,  # Largura 18 para datas
    'VALOR TOTAL': 15,        # Largura 15 para valores
    'VE√çCULO (PLACA)': 25,    # Largura 25 para placas
    'default': 15,            # Largura padr√£o para outras colunas
}
```

### 2.2 Valores Recomendados

- **N√∫meros pequenos**: 8-12
- **Datas**: 15-18
- **Valores monet√°rios**: 12-15
- **Textos longos**: 20-30
- **C√≥digos**: 10-15

### 2.3 Como Adicionar Nova Coluna

Se aparecer uma nova coluna no relat√≥rio, adicione-a assim:

```python
COLUMN_WIDTHS = {
    # ... colunas existentes ...
    'NOVA COLUNA': 15,  # Ajuste o n√∫mero conforme necess√°rio
    'default': 15,
}
```

---

## ÔøΩÔøΩ 3. CONFIGURA√á√ÉO DE BORDAS

### 3.1 Estilos de Borda Dispon√≠veis

| Estilo | Descri√ß√£o | Apar√™ncia |
|--------|-----------|-----------|
| `none` | Sem borda | ‚îÄ |
| `thin` | Borda fina | ‚îÄ |
| `medium` | Borda m√©dia | ‚îÄ |
| `thick` | Borda grossa | ‚îÄ |
| `dashed` | Borda tracejada | ‚îà |
| `dotted` | Borda pontilhada | ‚îà |

### 3.2 Configura√ß√µes de Bordas por Tema

```python
BORDER_CONFIGS = {
    'default': {
        'header_border': 'thin',      # Borda do cabe√ßalho
        'data_border': 'thin',        # Borda dos dados
        'border_color': '000000',     # Cor da borda (preto)
    },
    'corporate': {
        'header_border': 'thick',     # Cabe√ßalho com borda grossa
        'data_border': 'thin',        # Dados com borda fina
        'border_color': '1F4E78',     # Cor azul escuro
    }
}
```

### 3.3 Como Criar Novo Tema de Bordas

```python
BORDER_CONFIGS = {
    # ... temas existentes ...
    'meu_tema': {
        'header_border': 'medium',
        'data_border': 'dashed',
        'border_color': 'FF0000',  # Bordas vermelhas
    }
}
```

---

## üí∞ 4. CONFIGURA√á√ÉO DE FORMATOS DE MOEDA

### 4.1 Formatos Dispon√≠veis

```python
CURRENCY_FORMATS = {
    'BRL': 'R$ #,##0.00',    # Real brasileiro
    'USD': 'US$ #,##0.00',   # D√≥lar americano
    'EUR': '‚Ç¨ #,##0.00',     # Euro
}
```

### 4.2 Como Criar Novo Formato

```python
CURRENCY_FORMATS = {
    # ... formatos existentes ...
    'MXN': 'MX$ #,##0.00',   # Peso mexicano
}
```

---

## üìÖ 5. CONFIGURA√á√ÉO DE FORMATOS DE DATA

### 5.1 Formatos Dispon√≠veis

```python
DATE_FORMATS = {
    'pt_BR': 'dd/mm/yyyy',   # Brasileiro
    'en_US': 'mm/dd/yyyy',   # Americano
    'iso': 'yyyy-mm-dd',     # Internacional
}
```

### 5.2 Como Criar Novo Formato

```python
DATE_FORMATS = {
    # ... formatos existentes ...
    'custom': 'dd-mm-yyyy',  # Formato personalizado
}
```

---

## üé® 6. TEMAS PR√â-DEFINIDOS

### 6.1 Tema Padr√£o (default)
- **Cabe√ßalho**: Azul claro com texto preto
- **Dados cont√°beis**: Cinza claro com texto azul escuro
- **Bordas**: Finas e pretas

### 6.2 Tema Escuro (dark)
- **Cabe√ßalho**: Cinza escuro com texto branco
- **Dados cont√°beis**: Cinza m√©dio com texto verde
- **Bordas**: M√©dias e brancas

### 6.3 Tema Corporativo (corporate)
- **Cabe√ßalho**: Azul escuro com texto branco
- **Dados cont√°beis**: Branco com texto azul escuro
- **Bordas**: Grossas no cabe√ßalho, finas nos dados

### 6.4 Tema Minimal (minimal)
- **Cabe√ßalho**: Cinza claro com texto preto
- **Dados cont√°beis**: Branco com texto preto
- **Bordas**: Apenas no cabe√ßalho

---

## üîß 7. COMO APLICAR MUDAN√áAS

### 7.1 Passo a Passo

1. **Abra o arquivo** `style_config.py`
2. **Localize a se√ß√£o** que deseja modificar
3. **Altere os valores** conforme necess√°rio
4. **Salve o arquivo**
5. **Execute o programa** novamente

### 7.2 Exemplo Pr√°tico

**Problema:** Quero um relat√≥rio com tema escuro e bordas grossas

**Solu√ß√£o:**
1. No `app.py`, mude a linha:
   ```python
   export_to_excel(
       {periodo: df_periodo}, 
       output_dir=OUTPUT_DIR,
       border_theme='dark'  # Mudou de 'default' para 'dark'
   )
   ```

---

## ‚ö†Ô∏è 8. DICAS IMPORTANTES

### 8.1 Cores
- **Sempre use c√≥digos hexadecimais** (6 d√≠gitos)
- **Teste a legibilidade** - texto escuro em fundo escuro n√£o funciona
- **Mantenha consist√™ncia** - use cores similares no mesmo tema

### 8.2 Larguras
- **Valores muito pequenos** (< 8) podem cortar texto
- **Valores muito grandes** (> 30) deixam muito espa√ßo vazio
- **Teste com dados reais** para encontrar o tamanho ideal

### 8.3 Bordas
- **Bordas grossas** no cabe√ßalho destacam a se√ß√£o
- **Bordas finas** nos dados mant√™m a legibilidade
- **Cores contrastantes** melhoram a apar√™ncia

---

## üö® 9. SOLU√á√ÉO DE PROBLEMAS

### 9.1 Erro de C√≥digo de Cor
**Problema:** `ValueError: Invalid color code`
**Solu√ß√£o:** Verifique se o c√≥digo tem exatamente 6 caracteres hexadecimais

### 9.2 Coluna Muito Larga/Estreita
**Problema:** Texto cortado ou muito espa√ßo vazio
**Solu√ß√£o:** Ajuste o valor em `COLUMN_WIDTHS`

### 9.3 Bordas N√£o Aparecem
**Problema:** Bordas n√£o s√£o aplicadas
**Solu√ß√£o:** Verifique se o `border_theme` est√° correto no `app.py`

### 9.4 Formato de Moeda Errado
**Problema:** Valores n√£o aparecem como moeda
**Solu√ß√£o:** Verifique se a coluna est√° em `CONTABEIS_COLS`

---

## üìû 10. SUPORTE

Se encontrar problemas:
1. **Verifique os logs** no arquivo `app.log`
2. **Teste com valores padr√£o** primeiro
3. **Fa√ßa mudan√ßas pequenas** e teste cada uma
4. **Mantenha backup** do arquivo original

---

## üéØ RESUMO R√ÅPIDO

Para mudan√ßas comuns:

**Mudar cor do cabe√ßalho:**
```python
THEMES['default']['header_bg'] = 'NOVA_COR'
```

**Ajustar largura de coluna:**
```python
COLUMN_WIDTHS['NOME_COLUNA'] = NOVA_LARGURA
```

**Mudar tema de bordas:**
```python
# No app.py, mude border_theme='novo_tema'
```

**Adicionar nova coluna cont√°bil:**
```python
CONTABEIS_COLS.append('NOVA_COLUNA')
``` 

================================================================================
ARQUIVO 4/24: README.md
TAMANHO: 1.71 KB
================================================================================

# Tabela Recebimentos

Aplica√ß√£o para processamento de dados de recebimentos.

## Configura√ß√£o do Ambiente

### Pr√©-requisitos
- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)

### Instala√ß√£o

1. **Clone o reposit√≥rio** (se aplic√°vel):
```bash
git clone <url-do-repositorio>
cd "TABELA RECEBIMENTOS"
```

2. **Crie o ambiente virtual**:
```bash
python -m venv venv
```

3. **Ative o ambiente virtual**:

**Windows (PowerShell)**:
```powershell
.\venv\Scripts\Activate.ps1
```

**Windows (Command Prompt)**:
```cmd
.\venv\Scripts\activate.bat
```

**Linux/Mac**:
```bash
source venv/bin/activate
```

4. **Instale as depend√™ncias**:
```bash
pip install -r requirements.txt
```

### Uso

Sempre que for trabalhar no projeto, ative o ambiente virtual primeiro:

```powershell
.\venv\Scripts\Activate.ps1
```

Para desativar o ambiente virtual:
```bash
deactivate
```

### Depend√™ncias Instaladas

- `pyodbc`: Conex√£o com banco de dados SQL Server
- `pandas`: Manipula√ß√£o e an√°lise de dados
- `python-dotenv`: Gerenciamento de vari√°veis de ambiente
- `openpyxl`: Leitura e escrita de arquivos Excel

### Estrutura do Projeto

```
TABELA RECEBIMENTOS/
‚îú‚îÄ‚îÄ app.py              # Arquivo principal da aplica√ß√£o
‚îú‚îÄ‚îÄ config.py           # Configura√ß√µes
‚îú‚îÄ‚îÄ requirements.txt    # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ data/              # Dados da aplica√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ recebimentos/
‚îú‚îÄ‚îÄ modules/           # M√≥dulos da aplica√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ acess_db.py
‚îÇ   ‚îú‚îÄ‚îÄ exporters.py
‚îÇ   ‚îú‚îÄ‚îÄ extractors.py
‚îÇ   ‚îî‚îÄ‚îÄ processors.py
‚îî‚îÄ‚îÄ utils/             # Utilit√°rios
    ‚îî‚îÄ‚îÄ helpers.py
``` 

================================================================================
ARQUIVO 5/24: app.py
TAMANHO: 8.93 KB
================================================================================

import pandas as pd
import logging
import sys
from datetime import datetime
from config import (
    MDB_FILE, MDB_PASSWORD, OUTPUT_DIR, LOG_LEVEL, LOG_FILE, 
    FILE_ENCODING, MAX_RECORDS, EXCEL_SETTINGS, FORMATTING,
    ConfigError, get_config_summary
)
from modules.access_db import get_connection_context, DatabaseConnectionError, test_connection, get_database_info
from modules.extractors import extract_all_data, ExtractionError
from modules.processors import process_recebimentos
from modules.exporters import export_to_excel


def setup_logging():
    """Configura o sistema de logging"""
    logging.basicConfig(
        level=getattr(logging, LOG_LEVEL.upper()),
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(LOG_FILE, encoding=FILE_ENCODING),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)


def validate_input(year: str, month: str) -> tuple[str, str]:
    """
    Valida e formata os inputs de ano e m√™s
    
    Args:
        year: Ano informado pelo usu√°rio
        month: M√™s informado pelo usu√°rio
        
    Returns:
        tuple: (ano_validado, mes_validado)
        
    Raises:
        ValueError: Se os valores n√£o forem v√°lidos
    """
    # Remove espa√ßos e valida se s√£o n√∫meros
    year = year.strip()
    month = month.strip()
    
    if not year.isdigit() or not month.isdigit():
        raise ValueError("Ano e m√™s devem ser n√∫meros v√°lidos")
    
    year_int = int(year)
    month_int = int(month)
    
    # Valida√ß√£o de ano (entre 2000 e 2100)
    if year_int < 2000 or year_int > 2100:
        raise ValueError("Ano deve estar entre 2000 e 2100")
    
    # Valida√ß√£o de m√™s (entre 1 e 12)
    if month_int < 1 or month_int > 12:
        raise ValueError("M√™s deve estar entre 1 e 12")
    
    # Formata m√™s com zero √† esquerda
    month_formatted = f"{month_int:02d}"
    
    return year, month_formatted


def main():
    """Fun√ß√£o principal da aplica√ß√£o"""
    logger = setup_logging()
    
    try:
        logger.info("Iniciando aplica√ß√£o de processamento de recebimentos")
        
        # Exibe resumo das configura√ß√µes
        config_summary = get_config_summary()
        logger.info(f"Configura√ß√µes carregadas: {config_summary}")
        
        # Testa conex√£o com banco antes de prosseguir
        logger.info("Testando conex√£o com banco de dados...")
        if not test_connection(MDB_FILE, MDB_PASSWORD):
            print("‚ùå Falha no teste de conex√£o com banco de dados")
            return
        
        # Obt√©m informa√ß√µes do banco
        db_info = get_database_info(MDB_FILE, MDB_PASSWORD)
        if db_info:
            logger.info(f"Banco de dados: {db_info['file_path']}")
            logger.info(f"Tabelas encontradas: {db_info['table_count']}")
            #logger.info(f"Lista de tabelas: {db_info['tables']}")
        
        # Pergunta m√™s e ano ao usu√°rio
        year = input("Informe o ano (YYYY): ").strip()
        month = input("Informe o m√™s (MM): ").strip()
        
        # Valida inputs
        try:
            year_validated, month_validated = validate_input(year, month)
            periodo = f"{year_validated}-{month_validated}"
            logger.info(f"Per√≠odo selecionado: {periodo}")
        except ValueError as e:
            logger.error(f"Erro na valida√ß√£o de input: {e}")
            print(f"‚ùå Erro: {e}")
            return
        
        # Conecta e extrai dados usando context manager
        logger.info("Conectando ao banco de dados...")
        try:
            with get_connection_context(MDB_FILE, MDB_PASSWORD) as conn:
                logger.info("Conex√£o com banco de dados estabelecida com sucesso")
                
                # Extrai dados usando a nova fun√ß√£o consolidada
                try:
                    ordens_df, contas_df, fcaixa_df = extract_all_data(conn)
                    
                    # Aplica limite de registros se configurado
                    if MAX_RECORDS > 0:
                        logger.info(f"Aplicando limite de {MAX_RECORDS} registros")
                        ordens_df = ordens_df.head(MAX_RECORDS)
                        contas_df = contas_df.head(MAX_RECORDS)
                        fcaixa_df = fcaixa_df.head(MAX_RECORDS)
                        
                except ExtractionError as e:
                    logger.error(f"Erro na extra√ß√£o de dados: {e}")
                    print(f"‚ùå Erro na extra√ß√£o de dados: {e}")
                    return
                except Exception as e:
                    logger.error(f"Erro inesperado na extra√ß√£o: {e}")
                    print(f"‚ùå Erro inesperado na extra√ß√£o: {e}")
                    return
                    
        except DatabaseConnectionError as e:
            logger.error(f"Erro de conex√£o com banco de dados: {e}")
            print(f"‚ùå Erro de conex√£o com banco de dados: {e}")
            return
        except Exception as e:
            logger.error(f"Erro inesperado na conex√£o: {e}")
            print(f"‚ùå Erro inesperado na conex√£o: {e}")
            return

        # Processa recebimentos
        logger.info("Processando recebimentos...")
        try:
            recibos = process_recebimentos(ordens_df, contas_df, fcaixa_df, periodo)
            logger.info(f"Processamento conclu√≠do: {len(recibos)} registros processados")
        except Exception as e:
            logger.error(f"Erro no processamento: {e}")
            print(f"‚ùå Erro no processamento dos dados: {e}")
            return

        # Remove hora, mantendo apenas a data
        try:
            recibos['DATA PGTO'] = pd.to_datetime(recibos['DATA PGTO']).dt.date
            recibos['DATA ENCERRAMENTO'] = pd.to_datetime(recibos['DATA ENCERRAMENTO']).dt.date
        except Exception as e:
            logger.warning(f"Erro ao converter datas: {e}")

        # Reordena colunas
        column_order = [
            'N¬∞ OS', 'DATA PGTO', 'VALOR TOTAL', 'VALOR M√ÉO DE OBRA',
            'VALOR PE√áAS', 'DESCONTO', 'VALOR PAGO', 'DEVEDOR', 'CART√ÉO', 'DINHEIRO',
            'PIX', 'TROCO', 'VE√çCULO (PLACA)', 'C√ìDIGO CLIENTE', 'DATA ENCERRAMENTO'
        ]
        
        # Verifica se todas as colunas existem
        missing_columns = [col for col in column_order if col not in recibos.columns]
        if missing_columns:
            logger.warning(f"Colunas n√£o encontradas: {missing_columns}")
            # Remove colunas que n√£o existem da lista de ordena√ß√£o
            column_order = [col for col in column_order if col in recibos.columns]
        
        recibos = recibos[column_order]

        # Filtra pelo per√≠odo desejado baseado em DATA PGTO
        try:
            valid = recibos.dropna(subset=['DATA PGTO']).copy()
            valid['MES'] = valid['DATA PGTO'].astype(str).str.slice(0, 7)
            
            if periodo in valid['MES'].unique():
                df_periodo = valid[valid['MES'] == periodo].drop(columns='MES')
                logger.info(f"Encontrados {len(df_periodo)} registros para o per√≠odo {periodo}")
                
                # Exporta para Excel
                try:
                    export_to_excel(
                        {periodo: df_periodo}, 
                        output_dir=OUTPUT_DIR,
                        border_theme='default'  # Pode ser alterado para 'corporate', 'dark', 'minimal'
                    )
                    logger.info(f"Arquivo Excel gerado com sucesso em {OUTPUT_DIR}")
                    print(f"‚úÖ Arquivo gerado: {OUTPUT_DIR}/Recebimentos_{periodo}.xlsx")
                except Exception as e:
                    logger.error(f"Erro ao exportar para Excel: {e}")
                    print(f"‚ùå Erro ao gerar arquivo Excel: {e}")
                    return
            else:
                logger.warning(f"Nenhum registro encontrado para o per√≠odo {periodo}")
                print(f"‚ö†Ô∏è Nenhum registro encontrado para o per√≠odo {periodo}")
        except Exception as e:
            logger.error(f"Erro ao filtrar por per√≠odo: {e}")
            print(f"‚ùå Erro ao filtrar dados por per√≠odo: {e}")
            return
        
        logger.info("Processamento conclu√≠do com sucesso")
        print("‚úÖ Processamento conclu√≠do com sucesso!")
        
    except KeyboardInterrupt:
        logger.info("Aplica√ß√£o interrompida pelo usu√°rio")
        print("\n‚ö†Ô∏è Aplica√ß√£o interrompida pelo usu√°rio")
    except ConfigError as e:
        logger.error(f"Erro de configura√ß√£o: {e}")
        print(f"‚ùå Erro de configura√ß√£o: {e}")
    except Exception as e:
        logger.error(f"Erro inesperado: {e}", exc_info=True)
        print(f"‚ùå Erro inesperado: {e}")
        print("Consulte o arquivo app.log para mais detalhes")


if __name__ == '__main__':
    main()


================================================================================
ARQUIVO 6/24: auditoria_gui.py
TAMANHO: 11.50 KB
================================================================================

#!/usr/bin/env python3
"""
Interface Gr√°fica para Auditoria Unificada
Interface amig√°vel para sele√ß√£o de arquivos e execu√ß√£o da auditoria
"""

import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
import os
import sys
import threading
from datetime import datetime
import pandas as pd


class AuditoriaGUI:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("Auditoria 707 - Cart√£o e PIX")
        self.root.geometry("700x700")
        self.root.resizable(True, True)
        
        # Vari√°veis para armazenar caminhos dos arquivos
        self.cartao_csv = tk.StringVar()
        self.banco_csv = tk.StringVar()
        self.recebimentos_excel = tk.StringVar()
        self.nfse_directory = tk.StringVar()
        self.output_dir = tk.StringVar()
        
        # Configura√ß√µes padr√£o
        self.cartao_csv.set("data/extratos/report_20250628_194465.csv")
        self.banco_csv.set("data/extratos/NU_636868111_01JUN2025_27JUN2025.csv")
        self.recebimentos_excel.set("data/recebimentos/Recebimentos_2025-06.xlsx")
        self.nfse_directory.set("data/06-JUN")
        self.output_dir.set("data/relatorios")
        
        self.setup_ui()
    
    def setup_ui(self):
        """Configura a interface do usu√°rio"""
        # T√≠tulo
        title_label = tk.Label(self.root, text="üîç AUDITORIA 707 MOTORSPORT", 
                              font=("Arial", 16, "bold"), fg="#2E86AB")
        title_label.pack(pady=20)
        
        subtitle_label = tk.Label(self.root, text="Cart√£o e PIX", 
                                 font=("Arial", 12), fg="#666666")
        subtitle_label.pack(pady=5)
        
        # Frame principal
        main_frame = ttk.Frame(self.root, padding="20")
        main_frame.pack(fill=tk.BOTH, expand=True)
        
        # Se√ß√£o de arquivos de entrada
        input_frame = ttk.LabelFrame(main_frame, text="Arquivos de Entrada", padding="10")
        input_frame.pack(fill="x", padx=10, pady=5)
        
        # CSV de transa√ß√µes de cart√£o
        ttk.Label(input_frame, text="CSV de Transa√ß√µes de Cart√£o:").grid(row=0, column=0, sticky="w", pady=2)
        ttk.Entry(input_frame, textvariable=self.cartao_csv, width=50).grid(row=0, column=1, padx=5, pady=2)
        ttk.Button(input_frame, text="Selecionar", command=lambda: self.select_file(self.cartao_csv, [("CSV files", "*.csv")])).grid(row=0, column=2, pady=2)
        
        # CSV do banco (PIX)
        ttk.Label(input_frame, text="CSV do Banco (PIX):").grid(row=1, column=0, sticky="w", pady=2)
        ttk.Entry(input_frame, textvariable=self.banco_csv, width=50).grid(row=1, column=1, padx=5, pady=2)
        ttk.Button(input_frame, text="Selecionar", command=lambda: self.select_file(self.banco_csv, [("CSV files", "*.csv")])).grid(row=1, column=2, pady=2)
        
        # Excel de recebimentos
        ttk.Label(input_frame, text="Excel de Recebimentos:").grid(row=2, column=0, sticky="w", pady=2)
        ttk.Entry(input_frame, textvariable=self.recebimentos_excel, width=50).grid(row=2, column=1, padx=5, pady=2)
        ttk.Button(input_frame, text="Selecionar", command=lambda: self.select_file(self.recebimentos_excel, [("Excel files", "*.xlsx")])).grid(row=2, column=2, pady=2)
        
        # Pasta das Notas Fiscais (NFSe)
        ttk.Label(input_frame, text="Pasta das Notas Fiscais (NFSe):").grid(row=3, column=0, sticky="w", pady=2)
        ttk.Entry(input_frame, textvariable=self.nfse_directory, width=50).grid(row=3, column=1, padx=5, pady=2)
        ttk.Button(input_frame, text="Selecionar", command=lambda: self.select_directory_for_var(self.nfse_directory)).grid(row=3, column=2, pady=2)
        
        # Se√ß√£o de pasta de destino
        output_frame = ttk.LabelFrame(main_frame, text="Pasta de Destino", padding="10")
        output_frame.pack(fill="x", padx=10, pady=5)
        
        # Pasta de destino
        ttk.Label(output_frame, text="Pasta de Destino:").grid(row=0, column=0, sticky="w", pady=2)
        ttk.Entry(output_frame, textvariable=self.output_dir, width=50).grid(row=0, column=1, padx=5, pady=2)
        ttk.Button(output_frame, text="Selecionar", command=self.select_directory).grid(row=0, column=2, pady=2)
        
        # Se√ß√£o de op√ß√µes
        options_frame = ttk.LabelFrame(main_frame, text="‚öôÔ∏è Op√ß√µes", padding="15")
        options_frame.pack(fill=tk.X, pady=10)
        
        # Checkbox para abrir relat√≥rio ap√≥s conclus√£o
        self.open_report_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(options_frame, text="Abrir relat√≥rio ap√≥s conclus√£o", 
                       variable=self.open_report_var).pack(anchor=tk.W)
        
        # Bot√µes principais (ANTES da se√ß√£o de status)
        button_frame = ttk.Frame(main_frame)
        button_frame.pack(fill=tk.X, pady=20)
        
        # Bot√£o principal de execu√ß√£o (maior e mais vis√≠vel)
        self.audit_button = tk.Button(button_frame, text="üîç EXECUTAR AUDITORIA", 
                                  command=self.run_audit, 
                                  bg="#2E86AB", fg="white", 
                                  font=("Arial", 12, "bold"),
                                  height=2, width=20)
        self.audit_button.pack(side=tk.LEFT, padx=10)
        
        # Bot√µes secund√°rios
        self.cancel_button = ttk.Button(button_frame, text="‚ùå Cancelar", 
                  command=self.root.quit)
        self.cancel_button.pack(side=tk.RIGHT, padx=5)
        
        self.clear_button = ttk.Button(button_frame, text="üßπ Limpar Log", 
                  command=self.clear_log)
        self.clear_button.pack(side=tk.RIGHT, padx=5)
        
        # Se√ß√£o de status
        status_frame = ttk.LabelFrame(main_frame, text="üìä Status", padding="15")
        status_frame.pack(fill=tk.BOTH, expand=True, pady=10)
        
        # √Årea de log
        self.log_text = tk.Text(status_frame, height=8, wrap=tk.WORD, state=tk.DISABLED)
        log_scrollbar = ttk.Scrollbar(status_frame, orient=tk.VERTICAL, command=self.log_text.yview)
        self.log_text.configure(yscrollcommand=log_scrollbar.set)
        
        self.log_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        log_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
    
    def select_file(self, string_var, filetypes):
        """Abre di√°logo para sele√ß√£o de arquivo"""
        filename = filedialog.askopenfilename(filetypes=filetypes)
        if filename:
            string_var.set(filename)
    
    def select_directory(self):
        """Abre di√°logo para sele√ß√£o de pasta"""
        directory = filedialog.askdirectory()
        if directory:
            self.output_dir.set(directory)
    
    def select_directory_for_var(self, string_var):
        """Abre di√°logo para sele√ß√£o de pasta e atribui √† vari√°vel especificada"""
        directory = filedialog.askdirectory()
        if directory:
            string_var.set(directory)
    
    def open_file(self, filepath):
        """Abre arquivo com aplica√ß√£o padr√£o"""
        try:
            if os.name == 'nt':  # Windows
                os.startfile(filepath)
            else:  # Linux/Mac
                import subprocess
                subprocess.run(['xdg-open', filepath])
            self.log_message(f"Arquivo aberto: {filepath}")
        except Exception as e:
            self.log_message(f"Erro ao abrir arquivo: {e}")
    
    def log_message(self, message):
        """Adiciona mensagem ao log"""
        self.log_text.config(state=tk.NORMAL)
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.log_text.insert(tk.END, f"[{timestamp}] {message}\n")
        self.log_text.see(tk.END)
        self.log_text.config(state=tk.DISABLED)
        self.root.update()
    
    def clear_log(self):
        """Limpa o log"""
        self.log_text.config(state=tk.NORMAL)
        self.log_text.delete(1.0, tk.END)
        self.log_text.config(state=tk.DISABLED)
    
    def validate_files(self):
        """Valida se os arquivos existem"""
        files_to_check = [
            ("CSV do Cart√£o", self.cartao_csv.get()),
            ("CSV do Banco", self.banco_csv.get()),
            ("Excel de Recebimentos", self.recebimentos_excel.get())
        ]
        
        # Verifica se a pasta das notas fiscais existe
        nfse_dir = self.nfse_directory.get()
        if not os.path.exists(nfse_dir):
            error_msg = f"Pasta das Notas Fiscais n√£o encontrada: {nfse_dir}"
            messagebox.showerror("Pasta n√£o encontrada", error_msg)
            return False
        
        missing_files = []
        for name, path in files_to_check:
            if not os.path.exists(path):
                missing_files.append(f"{name}: {path}")
        
        if missing_files:
            error_msg = "Os seguintes arquivos n√£o foram encontrados:\n\n" + "\n".join(missing_files)
            messagebox.showerror("Arquivos n√£o encontrados", error_msg)
            return False
        
        return True
    
    def run_audit(self):
        """Executa a auditoria"""
        try:
            # Desabilita bot√µes durante execu√ß√£o
            self.audit_button.config(state="disabled")
            self.clear_button.config(state="disabled")
            self.cancel_button.config(state="disabled")
            
            # Limpa log
            self.log_text.delete(1.0, tk.END)
            
            # Valida arquivos
            if not self.validate_files():
                return
            
            # Cria pasta de destino se n√£o existir
            output_dir = self.output_dir.get()
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
                self.log_message(f"Pasta criada: {output_dir}")
            
            # Gera nome do arquivo de sa√≠da
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = os.path.join(output_dir, f"auditoria_unificada_{timestamp}.xlsx")
            
            self.log_message("Iniciando auditoria...")
            
            # Importa e executa auditoria
            import auditoria_unificada_completa
            
            # Executa auditoria com os arquivos selecionados
            auditoria_unificada_completa.executar_auditoria(
                cartao_csv=self.cartao_csv.get(),
                banco_csv=self.banco_csv.get(),
                recebimentos_excel=self.recebimentos_excel.get(),
                nfse_directory=self.nfse_directory.get(),
                output_file=output_file
            )
            
            self.log_message(f"Auditoria conclu√≠da! Arquivo salvo: {output_file}")
            
            # Pergunta se deseja abrir o arquivo
            if messagebox.askyesno("Sucesso", "Auditoria conclu√≠da! Deseja abrir o arquivo?"):
                self.open_file(output_file)
                
        except Exception as e:
            self.log_message(f"Erro: {str(e)}")
            messagebox.showerror("Erro", f"Erro durante a auditoria:\n{str(e)}")
        finally:
            # Reabilita bot√µes
            self.audit_button.config(state="normal")
            self.clear_button.config(state="normal")
            self.cancel_button.config(state="normal")
    
    def run(self):
        """Executa a interface gr√°fica"""
        self.root.mainloop()


def main():
    """Fun√ß√£o principal"""
    app = AuditoriaGUI()
    app.run()


if __name__ == "__main__":
    main() 

================================================================================
ARQUIVO 7/24: auditoria_unificada_completa.py
TAMANHO: 64.39 KB
================================================================================

#!/usr/bin/env python3
"""
Auditoria Unificada Completa - Cart√£o e PIX
Combina auditoria de transa√ß√µes de cart√£o e PIX em um √∫nico relat√≥rio Excel
"""

import os
import logging
import pandas as pd
from datetime import datetime
from typing import List, Dict, Optional
from dataclasses import dataclass
import re
import tkinter as tk
from tkinter import filedialog, messagebox
from modules.auditor import DataAuditor, AuditError
from config import OUTPUT_DIR
from style_config import (
    COLUMN_WIDTHS, BORDER_CONFIGS, THEMES, 
    CURRENCY_FORMATS, DATE_FORMATS, CONTABEIS_COLS
)


@dataclass
class PixTransaction:
    """Representa uma transa√ß√£o PIX"""
    data: str
    valor: float
    descricao: str
    origem: str  # 'banco', 'cartao', 'recebimentos'
    identificador: Optional[str] = None
    referencia: Optional[str] = None
    remetente: Optional[str] = None  # Nome ou CPF do remetente
    chave_pix: Optional[str] = None  # Chave PIX do remetente


@dataclass
class GroupedPixTransaction:
    """Representa transa√ß√µes PIX agrupadas por remetente e data"""
    data: str
    valor_total: float
    remetente: str
    origem: str
    transacoes_originais: List[PixTransaction]
    quantidade_transacoes: int
    referencia: Optional[str] = None


@dataclass
class AuditMatch:
    """Resultado de uma correspond√™ncia encontrada"""
    banco_transaction: PixTransaction
    recebimentos_transaction: Optional[PixTransaction] = None
    cartao_transaction: Optional[PixTransaction] = None
    match_type: str = "exato"
    confidence: float = 1.0
    notes: str = ""


def setup_logging():
    """Configura logging para a auditoria unificada"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger(__name__)


def select_files_gui():
    """Interface gr√°fica para sele√ß√£o de arquivos"""
    # Cria janela principal (oculta)
    root = tk.Tk()
    root.withdraw()  # Esconde a janela principal
    
    files = {}
    
    try:
        # Seleciona arquivo CSV do cart√£o
        messagebox.showinfo("Sele√ß√£o de Arquivos", 
                          "Selecione o arquivo CSV de transa√ß√µes do cart√£o")
        cartao_csv = filedialog.askopenfilename(
            title="Selecione o arquivo CSV do cart√£o",
            filetypes=[("CSV files", "*.csv"), ("All files", "*.*")]
        )
        
        if not cartao_csv:
            messagebox.showerror("Erro", "Nenhum arquivo CSV do cart√£o selecionado!")
            return None
        
        files['cartao_csv'] = cartao_csv
        
        # Seleciona arquivo CSV do banco
        messagebox.showinfo("Sele√ß√£o de Arquivos", 
                          "Selecione o arquivo CSV de transa√ß√µes PIX do banco")
        banco_csv = filedialog.askopenfilename(
            title="Selecione o arquivo CSV do banco",
            filetypes=[("CSV files", "*.csv"), ("All files", "*.*")]
        )
        
        if not banco_csv:
            messagebox.showerror("Erro", "Nenhum arquivo CSV do banco selecionado!")
            return None
        
        files['banco_csv'] = banco_csv
        
        # Seleciona arquivo Excel de recebimentos
        messagebox.showinfo("Sele√ß√£o de Arquivos", 
                          "Selecione o arquivo Excel de recebimentos")
        recebimentos_excel = filedialog.askopenfilename(
            title="Selecione o arquivo Excel de recebimentos",
            filetypes=[("Excel files", "*.xlsx"), ("Excel files", "*.xls"), ("All files", "*.*")]
        )
        
        if not recebimentos_excel:
            messagebox.showerror("Erro", "Nenhum arquivo Excel de recebimentos selecionado!")
            return None
        
        files['recebimentos_excel'] = recebimentos_excel
        
        # Confirma sele√ß√£o
        confirm_msg = f"""
Arquivos selecionados:

üìÑ Cart√£o: {os.path.basename(cartao_csv)}
üè¶ Banco: {os.path.basename(banco_csv)}
üìä Recebimentos: {os.path.basename(recebimentos_excel)}

Deseja continuar com a auditoria?
        """
        
        if messagebox.askyesno("Confirmar Arquivos", confirm_msg):
            return files
        else:
            messagebox.showinfo("Cancelado", "Auditoria cancelada pelo usu√°rio")
            return None
            
    except Exception as e:
        messagebox.showerror("Erro", f"Erro ao selecionar arquivos: {e}")
        return None
    finally:
        root.destroy()


def select_files_powershell():
    """Sele√ß√£o de arquivos via PowerShell (fallback)"""
    logger = logging.getLogger(__name__)
    
    print("\n=== SELE√á√ÉO DE ARQUIVOS ===")
    print("Digite os caminhos dos arquivos ou pressione Enter para usar os padr√µes:")
    
    # Arquivo CSV do cart√£o
    cartao_csv = input(f"CSV do cart√£o (padr√£o: data/extratos/report_20250628_194465.csv): ").strip()
    if not cartao_csv:
        cartao_csv = "data/extratos/report_20250628_194465.csv"
    
    # Arquivo CSV do banco
    banco_csv = input(f"CSV do banco (padr√£o: data/extratos/NU_636868111_01JUN2025_27JUN2025.csv): ").strip()
    if not banco_csv:
        banco_csv = "data/extratos/NU_636868111_01JUN2025_27JUN2025.csv"
    
    # Arquivo Excel de recebimentos
    recebimentos_excel = input(f"Excel de recebimentos (padr√£o: data/recebimentos/Recebimentos_2025-06.xlsx): ").strip()
    if not recebimentos_excel:
        recebimentos_excel = "data/recebimentos/Recebimentos_2025-06.xlsx"
    
    return {
        'cartao_csv': cartao_csv,
        'banco_csv': banco_csv,
        'recebimentos_excel': recebimentos_excel
    }


def parse_cartao_csv(csv_file_path: str) -> pd.DataFrame:
    """
    Carrega e processa o CSV de transa√ß√µes de cart√£o
    """
    logger = logging.getLogger(__name__)
    
    try:
        logger.info(f"Carregando CSV de transa√ß√µes: {csv_file_path}")
        
        # Carrega o CSV
        df = pd.read_csv(csv_file_path, encoding='utf-8')
        
        # Processa a coluna de data
        df['Data e hora'] = pd.to_datetime(df['Data e hora'], format='%d %b, %Y ¬∑ %H:%M')
        df['DATA_PGTO'] = df['Data e hora'].dt.date
        
        # Processa valores monet√°rios
        df['Valor (R$)'] = df['Valor (R$)'].str.replace('"', '').str.replace('.', '').str.replace(',', '.').astype(float)
        df['L√≠quido (R$)'] = df['L√≠quido (R$)'].str.replace('"', '').str.replace('.', '').str.replace(',', '.').astype(float)
        
        # Cria colunas para auditoria
        df['TIPO_PAGAMENTO'] = df['Meio - Meio'].apply(lambda x: 'CART√ÉO' if x in ['Cr√©dito', 'D√©bito', 'Credito', 'Debito'] else 'PIX')
        df['VALOR_AUDITORIA'] = df['Valor (R$)']
        
        logger.info(f"CSV processado: {len(df)} transa√ß√µes")
        logger.info(f"Transa√ß√µes por tipo: {df['TIPO_PAGAMENTO'].value_counts().to_dict()}")
        
        return df
        
    except Exception as e:
        error_msg = f"Erro ao processar CSV de transa√ß√µes: {e}"
        logger.error(error_msg)
        raise AuditError(error_msg)


def load_banco_pix_csv(csv_path: str) -> List[PixTransaction]:
    """Carrega transa√ß√µes PIX do CSV do banco, ignorando 707 MOTORSPORT LTDA"""
    logger = logging.getLogger(__name__)
    logger.info(f"Carregando CSV do banco: {csv_path}")
    
    try:
        df = pd.read_csv(csv_path, encoding='utf-8')
        transactions = []
        
        for _, row in df.iterrows():
            descricao = str(row['Descri√ß√£o']).strip()
            
            # Filtra transfer√™ncias recebidas pelo PIX ou Transfer√™ncia Recebida
            if (('Transfer√™ncia recebida' in descricao and 'Pix' in descricao) or 
                'Transfer√™ncia Recebida' in descricao):
                try:
                    valor = float(str(row['Valor']).replace(',', '.'))
                    data = str(row['Data']).strip()
                    
                    # Extrai informa√ß√µes do remetente da descri√ß√£o
                    remetente = extract_remetente_from_description(descricao)
                    if remetente and remetente.strip().upper() == '707 MOTORSPORT LTDA':
                        continue  # Ignora esse remetente
                    chave_pix = extract_chave_pix_from_description(descricao)
                    
                    transaction = PixTransaction(
                        data=data,
                        valor=valor,
                        descricao=descricao,
                        origem='banco',
                        identificador=None,  # N√£o usa o identificador do banco
                        remetente=remetente,
                        chave_pix=chave_pix
                    )
                    transactions.append(transaction)
                    
                except (ValueError, KeyError) as e:
                    logger.warning(f"Erro ao processar linha do banco: {e}")
                    continue
        logger.info(f"Carregadas {len(transactions)} transa√ß√µes PIX do banco (ignorando 707 MOTORSPORT LTDA)")
        return transactions
        
    except Exception as e:
        logger.error(f"Erro ao carregar CSV do banco: {e}")
        return []


def extract_remetente_from_description(descricao: str) -> Optional[str]:
    """Extrai o nome do remetente da descri√ß√£o da transa√ß√£o PIX"""
    try:
        # Padr√µes espec√≠ficos baseados no formato real do CSV
        patterns = [
            # Padr√£o: "Transfer√™ncia recebida pelo Pix - NOME - CPF/CNPJ - BANCO"
            r'Transfer√™ncia recebida pelo Pix\s*-\s*([^-]+?)\s*-\s*[‚Ä¢\d\./-]+\s*-',
            # Padr√£o: "Transfer√™ncia Recebida - NOME - CPF/CNPJ - BANCO"
            r'Transfer√™ncia Recebida\s*-\s*([^-]+?)\s*-\s*[‚Ä¢\d\./-]+\s*-',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, descricao, re.IGNORECASE)
            if match:
                remetente = match.group(1).strip()
                # Remove caracteres especiais e normaliza
                remetente = re.sub(r'[^\w\s]', '', remetente).strip()
                # Remove espa√ßos extras
                remetente = re.sub(r'\s+', ' ', remetente)
                if len(remetente) > 2:  # Nome deve ter pelo menos 3 caracteres
                    return remetente
        
        # Se n√£o encontrou com os padr√µes espec√≠ficos, tenta extrair o nome antes do primeiro CPF/CNPJ
        if '‚Ä¢‚Ä¢‚Ä¢' in descricao or re.search(r'\d{3}\.\d{3}\.\d{3}', descricao):
            # Procura por texto antes do CPF/CNPJ
            parts = descricao.split(' - ')
            if len(parts) >= 2:
                # Pega a segunda parte (ap√≥s "Transfer√™ncia recebida pelo Pix")
                nome_part = parts[1]
                # Remove o CPF/CNPJ se presente
                nome_clean = re.sub(r'[‚Ä¢\d\./-]+', '', nome_part).strip()
                if len(nome_clean) > 2:
                    return nome_clean
        
        return None
    except:
        return None


def extract_chave_pix_from_description(descricao: str) -> Optional[str]:
    """Extrai a chave PIX da descri√ß√£o da transa√ß√£o"""
    try:
        # Padr√µes para CPF, CNPJ, email, telefone
        patterns = [
            r'(\d{3}\.\d{3}\.\d{3}-\d{2})',  # CPF
            r'(\d{2}\.\d{3}\.\d{3}/\d{4}-\d{2})',  # CNPJ
            r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})',  # Email
            r'(\+55\s?\d{2}\s?\d{4,5}\s?\d{4})',  # Telefone
        ]
        
        for pattern in patterns:
            match = re.search(pattern, descricao)
            if match:
                return match.group(1)
        
        return None
    except:
        return None


def load_recebimentos_excel(excel_path: str) -> List[PixTransaction]:
    """Carrega transa√ß√µes PIX da tabela de recebimentos"""
    logger = logging.getLogger(__name__)
    logger.info(f"Carregando Excel de recebimentos: {excel_path}")
    
    try:
        df = pd.read_excel(excel_path)
        transactions = []
        
        for _, row in df.iterrows():
            try:
                # Verifica se tem valor PIX
                valor_pix = row.get('PIX', 0)
                if pd.notna(valor_pix) and float(valor_pix) > 0:
                    data_pgto = str(row.get('DATA PGTO', '')).strip()
                    if data_pgto and data_pgto != 'nan':
                        transaction = PixTransaction(
                            data=data_pgto,
                            valor=float(valor_pix),
                            descricao=f"Recebimento PIX - OS: {row.get('N¬∞ OS', 'N/A')}",
                            origem='recebimentos',
                            referencia=str(row.get('N¬∞ OS', '')).strip()
                        )
                        transactions.append(transaction)
                        
            except (ValueError, KeyError) as e:
                logger.warning(f"Erro ao processar linha de recebimentos: {e}")
                continue
        
        logger.info(f"Carregadas {len(transactions)} transa√ß√µes PIX dos recebimentos")
        return transactions
        
    except Exception as e:
        logger.error(f"Erro ao carregar Excel de recebimentos: {e}")
        return []


def audit_cartao_transactions(cartao_df: pd.DataFrame, generated_df: pd.DataFrame) -> List[Dict]:
    """Executa auditoria de transa√ß√µes de cart√£o"""
    results = []
    
    for idx, cartao_row in cartao_df.iterrows():
        identificador = cartao_row['Identificador']
        valor_cartao = cartao_row['VALOR_AUDITORIA']
        data_cartao = cartao_row['DATA_PGTO']
        tipo_pagamento = cartao_row['TIPO_PAGAMENTO']
        
        # Procura registro correspondente por data
        matching_generated = generated_df[generated_df['DATA PGTO'] == data_cartao]
        
        if len(matching_generated) == 0:
            # Transa√ß√£o n√£o encontrada
            results.append({
                'identificador': identificador,
                'data_cartao': data_cartao,
                'valor_cartao': valor_cartao,
                'tipo_pagamento': tipo_pagamento,
                'status': 'N√ÉO ENCONTRADA',
                'valor_gerado': None,
                'diferenca': None,
                'os_correspondente': None,
                'observacao': f'Data {data_cartao} n√£o encontrada nos dados gerados'
            })
            continue
        
        # Procura por valor na coluna correspondente
        campo_procurado = 'CART√ÉO' if tipo_pagamento == 'CART√ÉO' else 'PIX'
        valor_encontrado = None
        os_correspondente = None
        
        for _, gen_row in matching_generated.iterrows():
            if campo_procurado in gen_row.index:
                valor_gen = gen_row[campo_procurado]
                if pd.notna(valor_gen) and abs(valor_gen - valor_cartao) <= (valor_cartao * 0.01):  # 1% toler√¢ncia
                    valor_encontrado = valor_gen
                    os_correspondente = gen_row.get('N¬∞ OS', 'N/A')
                    break
        
        if valor_encontrado is not None:
            # Valor encontrado
            diferenca = abs(valor_cartao - valor_encontrado)
            is_match = diferenca <= (valor_cartao * 0.01)
            
            results.append({
                'identificador': identificador,
                'data_cartao': data_cartao,
                'valor_cartao': valor_cartao,
                'tipo_pagamento': tipo_pagamento,
                'status': 'COINCIDENTE' if is_match else 'DIVERGENTE',
                'valor_gerado': valor_encontrado,
                'diferenca': diferenca,
                'os_correspondente': os_correspondente,
                'observacao': f'Encontrado na coluna {campo_procurado}'
            })
        else:
            # Valor n√£o encontrado
            results.append({
                'identificador': identificador,
                'data_cartao': data_cartao,
                'valor_cartao': valor_cartao,
                'tipo_pagamento': tipo_pagamento,
                'status': 'VALOR N√ÉO ENCONTRADO',
                'valor_gerado': None,
                'diferenca': None,
                'os_correspondente': None,
                'observacao': f'Valor {valor_cartao} n√£o encontrado na coluna {campo_procurado} para a data {data_cartao}'
            })
    
    return results


def audit_pix_transactions(banco_transactions: List[PixTransaction], 
                          recebimentos_transactions: List[PixTransaction]) -> List[Dict]:
    """Executa auditoria de transa√ß√µes PIX com agrupamento por remetente"""
    logger = logging.getLogger(__name__)
    
    # Agrupa transa√ß√µes do banco por remetente e data
    logger.info("Agrupando transa√ß√µes PIX do banco por remetente...")
    banco_grouped = group_pix_transactions_by_remetente(banco_transactions)
    
    # Agrupa transa√ß√µes dos recebimentos por data (n√£o h√° remetente)
    logger.info("Agrupando transa√ß√µes PIX dos recebimentos por data...")
    recebimentos_grouped = group_recebimentos_by_date(recebimentos_transactions)
    
    results = []
    
    for banco_group in banco_grouped:
        # Procura correspond√™ncia nos recebimentos agrupados
        encontrado = False
        
        for rec_group in recebimentos_grouped:
            # Compara por valor total (com toler√¢ncia de 1%)
            if abs(banco_group.valor_total - rec_group.valor_total) <= (banco_group.valor_total * 0.01):
                encontrado = True
                
                # Cria detalhes das transa√ß√µes individuais
                detalhes_banco = []
                for tx in banco_group.transacoes_originais:
                    detalhes_banco.append(f"R$ {tx.valor:,.2f} - {tx.remetente or 'N/A'}")
                
                detalhes_recebimentos = []
                for tx in rec_group.transacoes_originais:
                    detalhes_recebimentos.append(f"R$ {tx.valor:,.2f} - OS: {tx.referencia}")
                
                results.append({
                    'data_banco': banco_group.data,
                    'valor_banco': banco_group.valor_total,
                    'remetente_banco': banco_group.remetente,
                    'qtd_transacoes_banco': banco_group.quantidade_transacoes,
                    'detalhes_banco': ' | '.join(detalhes_banco),
                    'data_recebimentos': rec_group.data,
                    'valor_recebimentos': rec_group.valor_total,
                    'qtd_transacoes_recebimentos': rec_group.quantidade_transacoes,
                    'detalhes_recebimentos': ' | '.join(detalhes_recebimentos),
                    'status': 'CORRESPOND√äNCIA ENCONTRADA',
                    'tipo_agrupamento': 'M√∫ltiplas transa√ß√µes' if banco_group.quantidade_transacoes > 1 else 'Transa√ß√£o √∫nica',
                    'observacao': f'Valor total R$ {banco_group.valor_total:,.2f} corresponde ao total dos recebimentos'
                })
                break
        
        if not encontrado:
            # Cria detalhes das transa√ß√µes individuais
            detalhes_banco = []
            for tx in banco_group.transacoes_originais:
                detalhes_banco.append(f"R$ {tx.valor:,.2f} - {tx.remetente or 'N/A'}")
            
            results.append({
                'data_banco': banco_group.data,
                'valor_banco': banco_group.valor_total,
                'remetente_banco': banco_group.remetente,
                'qtd_transacoes_banco': banco_group.quantidade_transacoes,
                'detalhes_banco': ' | '.join(detalhes_banco),
                'data_recebimentos': None,
                'valor_recebimentos': None,
                'qtd_transacoes_recebimentos': None,
                'detalhes_recebimentos': None,
                'status': 'SEM CORRESPOND√äNCIA',
                'tipo_agrupamento': 'M√∫ltiplas transa√ß√µes' if banco_group.quantidade_transacoes > 1 else 'Transa√ß√£o √∫nica',
                'observacao': f'Transa√ß√µes de {banco_group.remetente} sem correspond√™ncia nos recebimentos'
            })
    
    return results


def group_pix_transactions_by_remetente(transactions: List[PixTransaction]) -> List[GroupedPixTransaction]:
    """Agrupa transa√ß√µes PIX da mesma pessoa no mesmo dia"""
    logger = logging.getLogger(__name__)
    
    # Agrupa por data (simplificado)
    grouped_dict = {}
    
    for tx in transactions:
        # Cria chave de agrupamento: apenas data
        group_key = tx.data
        
        if group_key not in grouped_dict:
            grouped_dict[group_key] = []
        grouped_dict[group_key].append(tx)
    
    # Cria transa√ß√µes agrupadas
    grouped_transactions = []
    
    for data, transacoes in grouped_dict.items():
        if len(transacoes) == 1:
            # Transa√ß√£o √∫nica - mant√©m como est√°
            tx = transacoes[0]
            grouped_tx = GroupedPixTransaction(
                data=data,
                valor_total=tx.valor,
                remetente=tx.remetente or "Desconhecido",
                origem=tx.origem,
                transacoes_originais=transacoes,
                quantidade_transacoes=1,
                referencia=tx.referencia
            )
        else:
            # M√∫ltiplas transa√ß√µes no mesmo dia - agrupa
            valor_total = sum(tx.valor for tx in transacoes)
            # Tenta identificar um remetente comum ou usa "M√∫ltiplos"
            remetentes = [tx.remetente for tx in transacoes if tx.remetente]
            if len(set(remetentes)) == 1 and remetentes[0]:
                remetente = remetentes[0]
            else:
                remetente = "M√∫ltiplos remetentes"
            
            grouped_tx = GroupedPixTransaction(
                data=data,
                valor_total=valor_total,
                remetente=remetente,
                origem=transacoes[0].origem,
                transacoes_originais=transacoes,
                quantidade_transacoes=len(transacoes),
                referencia="M√∫ltiplas transa√ß√µes"
            )
            logger.info(f"Agrupadas {len(transacoes)} transa√ß√µes em {data} - Total: R$ {valor_total:,.2f}")
        
        grouped_transactions.append(grouped_tx)
    
    logger.info(f"Transa√ß√µes agrupadas: {len(transactions)} -> {len(grouped_transactions)} grupos")
    return grouped_transactions


def group_recebimentos_by_date(transactions: List[PixTransaction]) -> List[GroupedPixTransaction]:
    """Agrupa transa√ß√µes de recebimentos por data"""
    logger = logging.getLogger(__name__)
    
    # Agrupa por data
    grouped_dict = {}
    
    for tx in transactions:
        if tx.data not in grouped_dict:
            grouped_dict[tx.data] = []
        grouped_dict[tx.data].append(tx)
    
    # Cria transa√ß√µes agrupadas
    grouped_transactions = []
    
    for data, transacoes in grouped_dict.items():
        if len(transacoes) == 1:
            # Transa√ß√£o √∫nica
            tx = transacoes[0]
            grouped_tx = GroupedPixTransaction(
                data=data,
                valor_total=tx.valor,
                remetente="Recebimento",
                origem=tx.origem,
                transacoes_originais=transacoes,
                quantidade_transacoes=1,
                referencia=tx.referencia
            )
        else:
            # M√∫ltiplas transa√ß√µes na mesma data
            valor_total = sum(tx.valor for tx in transacoes)
            grouped_tx = GroupedPixTransaction(
                data=data,
                valor_total=valor_total,
                remetente="Recebimentos m√∫ltiplos",
                origem=transacoes[0].origem,
                transacoes_originais=transacoes,
                quantidade_transacoes=len(transacoes),
                referencia="M√∫ltiplas OS"
            )
            logger.info(f"Agrupados {len(transacoes)} recebimentos em {data} - Total: R$ {valor_total:,.2f}")
        
        grouped_transactions.append(grouped_tx)
    
    return grouped_transactions


def generate_unified_report(cartao_results, pix_results, cartao_stats, recebimentos_transactions, banco_transactions, output_file, banco_pix_csv, nfse_df=None, nfse_results=None):
    """Gera relat√≥rio Excel unificado com formata√ß√£o otimizada"""
    try:
        # Garante que a pasta existe
        pasta = os.path.dirname(output_file)
        if pasta and not os.path.exists(pasta):
            os.makedirs(pasta)

        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            # Configura√ß√µes de estilo
            theme = THEMES['default']
            border_config = BORDER_CONFIGS['default']
            
            # Auditoria de Cart√£o - Detalhes
            if cartao_results:
                cartao_df = pd.DataFrame(cartao_results)
                # Calcula diferen√ßa percentual apenas para linhas com diferen√ßa
                cartao_df['dif_percentual'] = cartao_df.apply(
                    lambda row: (row['diferenca'] / row['valor_cartao'] * 100) if row['diferenca'] is not None and row['valor_cartao'] and row['valor_cartao'] > 0 else None, axis=1)
                
                # Define colunas para exibi√ß√£o
                colunas_cartao = [
                    'identificador', 'data_cartao', 'tipo_pagamento', 'valor_cartao', 'valor_gerado',
                    'diferenca', 'dif_percentual', 'status', 'os_correspondente', 'observacao'
                ]
                cartao_df = cartao_df[[c for c in colunas_cartao if c in cartao_df.columns]]
                
                if not cartao_df.empty:
                    safe_to_excel(cartao_df, writer, 'Cart√£o - Detalhes', theme, border_config)
                else:
                    empty_df = pd.DataFrame({'Mensagem': ['Nenhuma transa√ß√£o de cart√£o encontrada']})
                    safe_to_excel(empty_df, writer, 'Cart√£o - Detalhes', theme, border_config)
                
                # Diverg√™ncias de Cart√£o
                divergencias_cartao = [r for r in cartao_results if r['status'] in ['DIVERGENTE', 'N√ÉO ENCONTRADA', 'VALOR N√ÉO ENCONTRADO']]
                if divergencias_cartao:
                    divergencias_df = pd.DataFrame(divergencias_cartao)
                    divergencias_df['dif_percentual'] = divergencias_df.apply(
                        lambda row: (row['diferenca'] / row['valor_cartao'] * 100) if row['diferenca'] is not None and row['valor_cartao'] and row['valor_cartao'] > 0 else None, axis=1)
                    divergencias_df = divergencias_df[[c for c in colunas_cartao if c in divergencias_df.columns]]
                    safe_to_excel(divergencias_df, writer, 'Cart√£o - Diverg√™ncias', theme, border_config)
                else:
                    empty_df = pd.DataFrame({'Mensagem': ['Nenhuma diverg√™ncia encontrada']})
                    safe_to_excel(empty_df, writer, 'Cart√£o - Diverg√™ncias', theme, border_config)
            else:
                empty_df = pd.DataFrame({'Mensagem': ['Nenhuma transa√ß√£o de cart√£o encontrada']})
                safe_to_excel(empty_df, writer, 'Cart√£o - Detalhes', theme, border_config)

            # Notas Fiscais (NFSe) - se dispon√≠vel
            if nfse_df is not None and not nfse_df.empty:
                safe_to_excel(nfse_df, writer, 'Notas Fiscais (NFSe)', theme, border_config)
            elif nfse_df is not None:
                empty_df = pd.DataFrame({'Mensagem': ['Nenhuma nota fiscal encontrada']})
                safe_to_excel(empty_df, writer, 'Notas Fiscais (NFSe)', theme, border_config)
            
            # Auditoria NFSe vs Recebimentos - se dispon√≠vel
            if nfse_results is not None and nfse_results:
                nfse_audit_df = pd.DataFrame(nfse_results)
                
                # Define colunas para exibi√ß√£o
                colunas_nfse = [
                    'numero_nfse', 'nome_tomador', 'valor_nfse', 'data_nfse',
                    'valor_recebimento', 'diferenca', 'dif_percentual', 'status',
                    'os_correspondente', 'observacao'
                ]
                nfse_audit_df = nfse_audit_df[[c for c in colunas_nfse if c in nfse_audit_df.columns]]
                
                safe_to_excel(nfse_audit_df, writer, 'NFSe vs Recebimentos', theme, border_config)
                
                # Diverg√™ncias NFSe
                divergencias_nfse = [r for r in nfse_results if r['status'] in ['N√ÉO ENCONTRADA', 'M√öLTIPLAS CORRESPOND√äNCIAS']]
                if divergencias_nfse:
                    divergencias_nfse_df = pd.DataFrame(divergencias_nfse)
                    divergencias_nfse_df = divergencias_nfse_df[[c for c in colunas_nfse if c in divergencias_nfse_df.columns]]
                    safe_to_excel(divergencias_nfse_df, writer, 'NFSe - Diverg√™ncias', theme, border_config)
                else:
                    empty_df = pd.DataFrame({'Mensagem': ['Nenhuma diverg√™ncia encontrada']})
                    safe_to_excel(empty_df, writer, 'NFSe - Diverg√™ncias', theme, border_config)

            # Auditoria PIX - Detalhes (N√ÉO agrupado)
            # Carrega novamente as transa√ß√µes PIX do banco para garantir granularidade
            banco_pix_df = pd.read_csv(banco_pix_csv, encoding='utf-8')
            # Filtra apenas recebidas pelo Pix ou Transfer√™ncia Recebida
            pix_banco_df = banco_pix_df[
                (banco_pix_df['Descri√ß√£o'].str.contains('Transfer√™ncia recebida', na=False) & 
                 banco_pix_df['Descri√ß√£o'].str.contains('Pix', na=False)) |
                banco_pix_df['Descri√ß√£o'].str.contains('Transfer√™ncia Recebida', na=False)
            ]
            # Ajusta colunas para exibir principais informa√ß√µes
            pix_banco_df = pix_banco_df.rename(columns={
                'Data': 'data',
                'Valor': 'valor',
                'Descri√ß√£o': 'descricao',
            })
            # Extrai remetente para exibi√ß√£o
            pix_banco_df['remetente'] = pix_banco_df['descricao'].apply(extract_remetente_from_description)
            # Remove 707 MOTORSPORT LTDA
            pix_banco_df = pix_banco_df[~(pix_banco_df['remetente'].str.strip().str.upper() == '707 MOTORSPORT LTDA')]
            
            # Adiciona coluna OS correspondente baseada nos resultados da auditoria
            pix_banco_df['os_correspondente'] = None
            pix_banco_df['status_correspondencia'] = 'SEM CORRESPOND√äNCIA'
            
            # Carrega os dados de recebimentos para compara√ß√£o individual
            recebimentos_df = pd.read_excel("data/recebimentos/Recebimentos_2025-06.xlsx")
            
            # Normaliza as datas para compara√ß√£o
            recebimentos_df['DATA_PGTO_NORM'] = pd.to_datetime(recebimentos_df['DATA PGTO']).dt.strftime('%d/%m/%Y')
            
            # Calcula valor l√≠quido (M√ÉO DE OBRA + DESCONTO) para cada recebimento
            if 'VALOR M√ÉO DE OBRA' in recebimentos_df.columns and 'DESCONTO' in recebimentos_df.columns:
                recebimentos_df['VALOR_LIQUIDO'] = recebimentos_df['VALOR M√ÉO DE OBRA'] + recebimentos_df['DESCONTO']
            else:
                recebimentos_df['VALOR_LIQUIDO'] = recebimentos_df.get('VALOR M√ÉO DE OBRA', 0)
            
            # Primeiro, tenta correspond√™ncia individual (transa√ß√£o por transa√ß√£o)
            for idx, row in pix_banco_df.iterrows():
                # Procura correspond√™ncia por data e valor com toler√¢ncia
                matching_recebimentos = recebimentos_df[
                    (recebimentos_df['DATA_PGTO_NORM'] == row['data']) & 
                    (recebimentos_df['PIX'] > 0) &  # Garante que tem valor PIX
                    (abs(recebimentos_df['PIX'] - row['valor']) <= (row['valor'] * 0.01))  # 1% toler√¢ncia
                ]
                
                if not matching_recebimentos.empty:
                    # Encontrou correspond√™ncia individual
                    os_numero = matching_recebimentos.iloc[0]['N¬∞ OS']
                    pix_banco_df.at[idx, 'os_correspondente'] = str(os_numero)
                    pix_banco_df.at[idx, 'status_correspondencia'] = 'CORRESPOND√äNCIA ENCONTRADA'
            
            # Segundo, procura por correspond√™ncias m√∫ltiplas (m√∫ltiplas transa√ß√µes para uma OS)
            # Agrupa transa√ß√µes do banco por data
            transacoes_por_data = {}
            for idx, row in pix_banco_df.iterrows():
                if row['status_correspondencia'] == 'SEM CORRESPOND√äNCIA':  # S√≥ processa as n√£o encontradas
                    data = row['data']
                    if data not in transacoes_por_data:
                        transacoes_por_data[data] = []
                    transacoes_por_data[data].append({
                        'idx': idx,
                        'valor': row['valor'],
                        'remetente': row['remetente']
                    })
            
            # Para cada data com m√∫ltiplas transa√ß√µes n√£o encontradas, procura correspond√™ncia por valor total
            for data, transacoes in transacoes_por_data.items():
                if len(transacoes) > 1:  # S√≥ processa se h√° m√∫ltiplas transa√ß√µes
                    valor_total = sum(tx['valor'] for tx in transacoes)
                    
                    # Procura recebimentos com valor total correspondente na mesma data
                    matching_recebimentos = recebimentos_df[
                        (recebimentos_df['DATA_PGTO_NORM'] == data) & 
                        (recebimentos_df['PIX'] > 0) &  # Garante que tem valor PIX
                        (abs(recebimentos_df['PIX'] - valor_total) <= (valor_total * 0.01))  # 1% toler√¢ncia
                    ]
                    
                    if not matching_recebimentos.empty:
                        # Encontrou correspond√™ncia m√∫ltipla
                        os_numero = matching_recebimentos.iloc[0]['N¬∞ OS']
                        
                        # Marca todas as transa√ß√µes com a mesma OS
                        for tx in transacoes:
                            pix_banco_df.at[tx['idx'], 'os_correspondente'] = str(os_numero)
                            pix_banco_df.at[tx['idx'], 'status_correspondencia'] = 'CORRESPOND√äNCIA M√öLTIPLA'
            
            # Terceiro, para transa√ß√µes individuais n√£o encontradas, tenta correspond√™ncia por valor total
            # (caso de uma transa√ß√£o que corresponde ao valor total de uma OS)
            for idx, row in pix_banco_df.iterrows():
                if row['status_correspondencia'] == 'SEM CORRESPOND√äNCIA':
                    # Procura recebimentos com valor total correspondente na mesma data
                    matching_recebimentos = recebimentos_df[
                        (recebimentos_df['DATA_PGTO_NORM'] == row['data']) & 
                        (recebimentos_df['PIX'] > 0) &  # Garante que tem valor PIX
                        (abs(recebimentos_df['PIX'] - row['valor']) <= (row['valor'] * 0.01))  # 1% toler√¢ncia
                    ]
                    
                    if not matching_recebimentos.empty:
                        # Encontrou correspond√™ncia por valor total
                        os_numero = matching_recebimentos.iloc[0]['N¬∞ OS']
                        pix_banco_df.at[idx, 'os_correspondente'] = str(os_numero)
                        pix_banco_df.at[idx, 'status_correspondencia'] = 'CORRESPOND√äNCIA ENCONTRADA'
            
            # Reordena colunas
            cols = ['data', 'valor', 'remetente', 'os_correspondente', 'status_correspondencia', 'descricao']
            pix_banco_df = pix_banco_df[cols]
            safe_to_excel(pix_banco_df, writer, 'PIX - Detalhes', theme, border_config)

            # PIX - Diverg√™ncias (baseado na correspond√™ncia individual)
            pix_sem_correspondencia = pix_banco_df[pix_banco_df['status_correspondencia'] == 'SEM CORRESPOND√äNCIA']
            if not pix_sem_correspondencia.empty:
                safe_to_excel(pix_sem_correspondencia, writer, 'PIX - Diverg√™ncias', theme, border_config)
            else:
                empty_df = pd.DataFrame({'Mensagem': ['Nenhuma transa√ß√£o sem correspond√™ncia']})
                safe_to_excel(empty_df, writer, 'PIX - Diverg√™ncias', theme, border_config)

            # Calcula estat√≠sticas PIX baseadas na correspond√™ncia individual
            correspondencias_encontradas = len(pix_banco_df[pix_banco_df['status_correspondencia'].isin(['CORRESPOND√äNCIA ENCONTRADA', 'CORRESPOND√äNCIA M√öLTIPLA'])])
            sem_correspondencia = len(pix_banco_df[pix_banco_df['status_correspondencia'] == 'SEM CORRESPOND√äNCIA'])
            
            # Calcula estat√≠sticas NFSe (se dispon√≠vel)
            nfse_stats = {}
            if nfse_results is not None and nfse_results:
                nfse_stats = {
                    'total_nfse': len(nfse_results),
                    'nfse_coincidentes': len([r for r in nfse_results if r['status'] == 'COINCIDENTE']),
                    'nfse_nao_encontradas': len([r for r in nfse_results if r['status'] == 'N√ÉO ENCONTRADA']),
                    'nfse_multiplas': len([r for r in nfse_results if r['status'] == 'M√öLTIPLAS CORRESPOND√äNCIAS'])
                }
            
            # Atualiza o resumo com as estat√≠sticas corretas
            metricas = [
                '=== AUDITORIA DE CART√ÉO ===',
                'Total de Transa√ß√µes',
                'Cart√£o Encontradas',
                'PIX Encontradas',
                'N√£o Encontradas',
                'Valores Coincidentes',
                'Valores Divergentes',
                'Taxa de Sucesso (%)',
                '',
                '=== AUDITORIA PIX ===',
                'Total Transa√ß√µes Banco',
                'Total Transa√ß√µes Recebimentos',
                'Correspond√™ncias Encontradas',
                'Sem Correspond√™ncia',
                'Taxa de Correspond√™ncia (%)',
                '',
                '=== AUDITORIA NFSe vs RECEBIMENTOS ===',
                'Total Notas Fiscais',
                'NFSe Coincidentes',
                'NFSe N√£o Encontradas',
                'NFSe M√∫ltiplas Correspond√™ncias',
                'Taxa de Sucesso NFSe (%)',
                '',
                'Data da Auditoria'
            ]
            
            valores = [
                '',
                cartao_stats['total_transacoes'],
                cartao_stats['cartao_encontradas'],
                cartao_stats['pix_encontradas'],
                cartao_stats['nao_encontradas'],
                cartao_stats['valores_coincidentes'],
                cartao_stats['valores_divergentes'],
                f"{(cartao_stats['valores_coincidentes'] / cartao_stats['total_transacoes']) * 100:.2f}%" if cartao_stats['total_transacoes'] > 0 else "0%",
                '',
                '',
                len(banco_transactions),  # Total de transa√ß√µes PIX do banco (n√£o agrupadas)
                len(recebimentos_transactions),  # Total de transa√ß√µes PIX dos recebimentos
                correspondencias_encontradas,  # Correspond√™ncias baseadas na correspond√™ncia individual
                sem_correspondencia,  # Sem correspond√™ncia baseada na correspond√™ncia individual
                f"{(correspondencias_encontradas / len(pix_banco_df)) * 100:.2f}%" if len(pix_banco_df) > 0 else "0%",
                '',
                '',
                nfse_stats.get('total_nfse', 0),
                nfse_stats.get('nfse_coincidentes', 0),
                nfse_stats.get('nfse_nao_encontradas', 0),
                nfse_stats.get('nfse_multiplas', 0),
                f"{(nfse_stats.get('nfse_coincidentes', 0) / nfse_stats.get('total_nfse', 1)) * 100:.2f}%" if nfse_stats.get('total_nfse', 0) > 0 else "0%",
                '',
                datetime.now().strftime('%d/%m/%Y %H:%M:%S')
            ]
            
            # Garante que as listas tenham o mesmo tamanho
            if len(metricas) != len(valores):
                diff = abs(len(metricas) - len(valores))
                if len(metricas) > len(valores):
                    valores += [''] * diff
                else:
                    metricas += [''] * diff
                    
            summary_data = {'M√©trica': metricas, 'Valor': valores}
            summary_df = pd.DataFrame(summary_data)
            safe_to_excel(summary_df, writer, 'Resumo Geral', theme, border_config)

    except Exception as e:
        logging.error(f"Erro ao gerar relat√≥rio: {e}")
        raise


def configure_worksheet_properties(worksheet, sheet_name):
    """Configura propriedades da planilha para melhor apresenta√ß√£o"""
    from openpyxl.worksheet.views import SheetView
    
    # Configura view da planilha usando a API correta
    if not hasattr(worksheet, 'sheet_view') or worksheet.sheet_view is None:
        worksheet.sheet_view = SheetView()
    
    # Configura propriedades da view
    worksheet.sheet_view.showGridLines = True
    worksheet.sheet_view.showRowColHeaders = True
    worksheet.sheet_view.zoomScale = 100
    worksheet.sheet_view.zoomScaleNormal = 100
    worksheet.sheet_view.zoomScalePageLayoutView = 100
    
    # Configura propriedades espec√≠ficas por tipo de planilha
    if 'Detalhes' in sheet_name:
        # Para detalhes, ajusta zoom para melhor visualiza√ß√£o
        worksheet.sheet_view.zoomScale = 90
    elif 'Diverg√™ncias' in sheet_name or 'Sem Correspond√™ncia' in sheet_name:
        # Para diverg√™ncias, zoom menor para ver mais dados
        worksheet.sheet_view.zoomScale = 85


def safe_to_excel(df, writer, sheet_name, theme, border_config):
    """Salva DataFrame no Excel com formata√ß√£o segura e otimizada"""
    # Processa o DataFrame para evitar problemas
    df_processed = df.copy()
    
    # Preenche valores NaN
    df_processed = df_processed.fillna('')
    
    # Converte para string e trata valores que come√ßam com "="
    for col in df_processed.columns:
        df_processed[col] = df_processed[col].astype(str).apply(
            lambda x: "'" + x if isinstance(x, str) and x.startswith('=') else x
        )
    
    # Remove linhas completamente vazias
    df_processed = df_processed.dropna(how='all')
    
    # Se o DataFrame ficou vazio, cria uma linha com mensagem
    if df_processed.empty:
        df_processed = pd.DataFrame({'Mensagem': ['Nenhum dado dispon√≠vel para esta se√ß√£o']})
    
    # Salva no Excel
    df_processed.to_excel(writer, sheet_name=sheet_name, index=False)
    
    # Obt√©m a planilha e aplica formata√ß√£o
    worksheet = writer.sheets[sheet_name]
    apply_worksheet_formatting(worksheet, df_processed, theme, border_config)
    configure_worksheet_properties(worksheet, sheet_name)


def optimize_column_widths(worksheet, df):
    """Otimiza a largura das colunas baseada no conte√∫do e configura√ß√µes"""
    from openpyxl.utils import get_column_letter
    
    for col in range(1, len(df.columns) + 1):
        column_name = df.columns[col - 1]
        
        # Largura m√≠nima baseada na configura√ß√£o
        min_width = COLUMN_WIDTHS.get(column_name, COLUMN_WIDTHS['default'])
        
        # Calcula largura baseada no conte√∫do
        header_length = len(str(column_name))
        max_content_length = header_length
        
        # Analisa o conte√∫do das c√©lulas
        for row in range(min(len(df), 100)):  # Limita a 100 linhas para performance
            try:
                cell_value = str(df.iloc[row, col - 1])
                # Remove caracteres especiais para c√°lculo mais preciso
                clean_value = cell_value.replace('R$', '').replace(',', '').replace('.', '')
                max_content_length = max(max_content_length, len(clean_value))
            except:
                continue
        
        # Aplica fatores de ajuste baseados no tipo de coluna
        if any(keyword in column_name.lower() for keyword in ['observacao', 'descricao', 'notes']):
            # Colunas de texto longo - largura maior
            content_width = max_content_length * 1.3
            max_width = 100
        elif any(keyword in column_name.lower() for keyword in ['valor', 'diferenca', 'percentual']):
            # Colunas num√©ricas - largura fixa para formata√ß√£o
            content_width = max_content_length * 1.1
            max_width = 25
        elif 'data' in column_name.lower():
            # Colunas de data - largura fixa
            content_width = 15
            max_width = 20
        else:
            # Colunas padr√£o
            content_width = max_content_length * 1.2
            max_width = 50
        
        # Define largura final
        final_width = max(min_width, min(content_width, max_width))
        worksheet.column_dimensions[get_column_letter(col)].width = final_width


def apply_worksheet_formatting(worksheet, df, theme, border_config):
    """Aplica formata√ß√£o uniforme √† planilha com largura de colunas otimizada"""
    from openpyxl.styles import Font, PatternFill, Border, Side, Alignment
    from openpyxl.utils import get_column_letter
    
    # Configura√ß√µes de borda
    border_style = Side(style=border_config['data_border'], color=border_config['border_color'])
    header_border_style = Side(style=border_config['header_border'], color=border_config['border_color'])
    
    # Estilo do cabe√ßalho
    header_font = Font(bold=True, color=theme['header_font'])
    header_fill = PatternFill(start_color=theme['header_bg'], end_color=theme['header_bg'], fill_type='solid')
    header_alignment = Alignment(horizontal='center', vertical='center')
    
    # Estilo das c√©lulas de dados
    data_font = Font(color='000000')
    data_alignment = Alignment(horizontal='left', vertical='center')
    
    # Aplica formata√ß√£o ao cabe√ßalho
    for col in range(1, len(df.columns) + 1):
        cell = worksheet.cell(row=1, column=col)
        cell.font = header_font
        cell.fill = header_fill
        cell.alignment = header_alignment
        cell.border = Border(
            left=header_border_style, right=header_border_style,
            top=header_border_style, bottom=header_border_style
        )
    
    # Aplica formata√ß√£o aos dados
    for row in range(2, len(df) + 2):
        for col in range(1, len(df.columns) + 1):
            cell = worksheet.cell(row=row, column=col)
            cell.font = data_font
            cell.alignment = data_alignment
            cell.border = Border(
                left=border_style, right=border_style,
                top=border_style, bottom=border_style
            )
            
            # Formata√ß√£o espec√≠fica para colunas num√©ricas
            column_name = df.columns[col - 1]
            if any(keyword in column_name.lower() for keyword in ['valor', 'diferenca', 'percentual']):
                if cell.value is not None and isinstance(cell.value, (int, float)):
                    cell.number_format = CURRENCY_FORMATS['BRL']
                    cell.alignment = Alignment(horizontal='right', vertical='center')
            
            # Formata√ß√£o para datas
            elif 'data' in column_name.lower():
                if cell.value is not None:
                    cell.number_format = DATE_FORMATS['pt_BR']
                    cell.alignment = Alignment(horizontal='center', vertical='center')
    
    # Otimiza largura das colunas
    optimize_column_widths(worksheet, df)


def audit_nfse_vs_recebimentos(nfse_df: pd.DataFrame, recebimentos_df: pd.DataFrame) -> List[Dict]:
    """
    Audita a compara√ß√£o entre notas fiscais e valores de m√£o de obra dos recebimentos
    
    Args:
        nfse_df: DataFrame com dados das notas fiscais
        recebimentos_df: DataFrame com dados dos recebimentos
        
    Returns:
        List[Dict]: Lista com resultados da auditoria
    """
    logger = logging.getLogger(__name__)
    logger.info("Iniciando auditoria NFSe vs Recebimentos...")
    
    results = []
    
    try:
        # Normaliza colunas dos recebimentos
        recebimentos_df = recebimentos_df.copy()
        
        # Converte DATA PGTO para string para compara√ß√£o
        if 'DATA PGTO' in recebimentos_df.columns:
            recebimentos_df['DATA_PGTO_STR'] = pd.to_datetime(recebimentos_df['DATA PGTO']).dt.strftime('%d/%m/%Y')
        
        # Calcula valor l√≠quido (M√ÉO DE OBRA + DESCONTO) para cada recebimento
        if 'VALOR M√ÉO DE OBRA' in recebimentos_df.columns and 'DESCONTO' in recebimentos_df.columns:
            recebimentos_df['VALOR_LIQUIDO'] = recebimentos_df['VALOR M√ÉO DE OBRA'] + recebimentos_df['DESCONTO']
        else:
            recebimentos_df['VALOR_LIQUIDO'] = recebimentos_df.get('VALOR M√ÉO DE OBRA', 0)
        
        # Processa cada nota fiscal
        for _, nfse_row in nfse_df.iterrows():
            numero_nfse = nfse_row.get('numero_nfse')
            nome_tomador = nfse_row.get('nome_tomador')
            valor_nfse = nfse_row.get('valor_total')
            data_nfse = nfse_row.get('data_emissao')
            
            if not all([numero_nfse, valor_nfse, data_nfse]):
                continue
            
            # Converte valor da NFSe para float (j√° deve estar como float, mas garante)
            try:
                if isinstance(valor_nfse, (int, float)):
                    valor_nfse_float = float(valor_nfse)
                else:
                    valor_nfse_float = float(str(valor_nfse).replace('R$', '').replace('.', '').replace(',', '.').strip())
            except (ValueError, AttributeError):
                valor_nfse_float = 0
            
            # Procura correspond√™ncia nos recebimentos
            matching_recebimentos = []
            
            # Busca por valor l√≠quido (compara√ß√£o exata com round(2)) - sem restri√ß√£o de data
            if 'VALOR_LIQUIDO' in recebimentos_df.columns:
                matching_recebimentos = recebimentos_df[
                    recebimentos_df['VALOR_LIQUIDO'].round(2) == round(valor_nfse_float, 2)
                ]
            
            # Determina status da auditoria
            if len(matching_recebimentos) == 1:
                # Correspond√™ncia exata encontrada
                recebimento = matching_recebimentos.iloc[0]
                valor_recebimento = recebimento['VALOR_LIQUIDO'] if 'VALOR_LIQUIDO' in recebimento.index else 0
                mao_obra = recebimento['VALOR M√ÉO DE OBRA'] if 'VALOR M√ÉO DE OBRA' in recebimento.index else 0
                desconto = recebimento['DESCONTO'] if 'DESCONTO' in recebimento.index else 0
                data_recebimento = recebimento['DATA_PGTO_STR'] if 'DATA_PGTO_STR' in recebimento.index else 'N/A'
                diferenca = valor_nfse_float - valor_recebimento
                status = 'COINCIDENTE'
                os_correspondente = recebimento['N¬∞ OS'] if 'N¬∞ OS' in recebimento.index else 'N/A'
                
            elif len(matching_recebimentos) > 1:
                # M√∫ltiplas correspond√™ncias
                recebimento = matching_recebimentos.iloc[0]  # Pega o primeiro
                valor_recebimento = recebimento['VALOR_LIQUIDO'] if 'VALOR_LIQUIDO' in recebimento.index else 0
                mao_obra = recebimento['VALOR M√ÉO DE OBRA'] if 'VALOR M√ÉO DE OBRA' in recebimento.index else 0
                desconto = recebimento['DESCONTO'] if 'DESCONTO' in recebimento.index else 0
                data_recebimento = recebimento['DATA_PGTO_STR'] if 'DATA_PGTO_STR' in recebimento.index else 'N/A'
                diferenca = valor_nfse_float - valor_recebimento
                status = 'M√öLTIPLAS CORRESPOND√äNCIAS'
                os_list = []
                for r in matching_recebimentos.head(3).itertuples():
                    os_list.append(str(getattr(r, 'N¬∞ OS', 'N/A')))
                os_correspondente = f"M√∫ltiplas OS: {', '.join(os_list)}"
                
            else:
                # Nenhuma correspond√™ncia encontrada
                valor_recebimento = 0
                mao_obra = 0
                desconto = 0
                data_recebimento = 'N/A'
                diferenca = valor_nfse_float
                status = 'N√ÉO ENCONTRADA'
                os_correspondente = 'N/A'
            
            # Calcula diferen√ßa percentual
            dif_percentual = (diferenca / valor_nfse_float * 100) if valor_nfse_float > 0 else 0
            
            # Cria resultado da auditoria
            result = {
                'numero_nfse': numero_nfse,
                'nome_tomador': nome_tomador,
                'valor_nfse': valor_nfse_float,
                'data_nfse': data_nfse,
                'valor_mao_obra': mao_obra,
                'desconto': desconto,
                'valor_liquido': valor_recebimento,
                'data_recebimento': data_recebimento,
                'diferenca': diferenca,
                'dif_percentual': dif_percentual,
                'status': status,
                'os_correspondente': os_correspondente,
                'observacao': f"NFSe {numero_nfse} - {nome_tomador}"
            }
            
            results.append(result)
        
        logger.info(f"Auditoria NFSe vs Recebimentos conclu√≠da: {len(results)} registros processados")
        
        # Estat√≠sticas
        coincidentes = len([r for r in results if r['status'] == 'COINCIDENTE'])
        nao_encontradas = len([r for r in results if r['status'] == 'N√ÉO ENCONTRADA'])
        multiplas = len([r for r in results if r['status'] == 'M√öLTIPLAS CORRESPOND√äNCIAS'])
        
        logger.info(f"  Coincidentes: {coincidentes}")
        logger.info(f"  N√£o encontradas: {nao_encontradas}")
        logger.info(f"  M√∫ltiplas correspond√™ncias: {multiplas}")
        
        return results
        
    except Exception as e:
        logger.error(f"Erro na auditoria NFSe vs Recebimentos: {e}")
        return []


def executar_auditoria(cartao_csv: str, banco_csv: str, recebimentos_excel: str, nfse_directory: str = None, output_file: str = None):
    """
    Executa a auditoria unificada com os arquivos especificados
    
    Args:
        cartao_csv: Caminho para o arquivo CSV de transa√ß√µes de cart√£o
        banco_csv: Caminho para o arquivo CSV de transa√ß√µes PIX do banco
        recebimentos_excel: Caminho para o arquivo Excel de recebimentos
        nfse_directory: Caminho para a pasta das notas fiscais (NFSe) - opcional
        output_file: Caminho para o arquivo de sa√≠da (opcional)
    """
    logger = setup_logging()
    
    try:
        logger.info("=== AUDITORIA UNIFICADA COMPLETA ===")
        
        # Define arquivo de sa√≠da padr√£o se n√£o especificado
        if not output_file:
            output_file = "data/relatorios/auditoria_unificada_completa.xlsx"
        
        # Verifica se os arquivos existem
        if not os.path.exists(cartao_csv):
            raise FileNotFoundError(f"Arquivo CSV do cart√£o n√£o encontrado: {cartao_csv}")
        
        if not os.path.exists(banco_csv):
            raise FileNotFoundError(f"Arquivo CSV do banco n√£o encontrado: {banco_csv}")
        
        if not os.path.exists(recebimentos_excel):
            raise FileNotFoundError(f"Arquivo Excel de recebimentos n√£o encontrado: {recebimentos_excel}")
        
        # Verifica se a pasta das notas fiscais existe (se fornecida)
        if nfse_directory and not os.path.exists(nfse_directory):
            logger.warning(f"Pasta das notas fiscais n√£o encontrada: {nfse_directory}")
            nfse_directory = None
        
        logger.info("Carregando dados...")
        logger.info(f"üìÑ Cart√£o: {os.path.basename(cartao_csv)}")
        logger.info(f"üè¶ Banco: {os.path.basename(banco_csv)}")
        logger.info(f"üìä Recebimentos: {os.path.basename(recebimentos_excel)}")
        if nfse_directory:
            logger.info(f"üìã Notas Fiscais: {os.path.basename(nfse_directory)}")
        
        # Carrega dados de cart√£o
        cartao_df = parse_cartao_csv(cartao_csv)
        
        # Carrega dados gerados
        auditor = DataAuditor(tolerance_percentage=0.01)
        generated_df = auditor.load_generated_data(recebimentos_excel)
        generated_df = auditor.normalize_column_names(generated_df)
        
        # Converte DATA PGTO para date se necess√°rio
        if 'DATA PGTO' in generated_df.columns:
            generated_df['DATA PGTO'] = pd.to_datetime(generated_df['DATA PGTO']).dt.date
        
        # Carrega dados PIX
        banco_transactions = load_banco_pix_csv(banco_csv)
        recebimentos_transactions = load_recebimentos_excel(recebimentos_excel)
        
        # Carrega dados das notas fiscais (se pasta fornecida)
        nfse_df = None
        if nfse_directory:
            try:
                logger.info("Carregando dados das notas fiscais...")
                from extrator_nfse import NFSeExtractor
                extrator = NFSeExtractor()
                nfse_df = extrator.process_directory(nfse_directory)
                logger.info(f"Notas fiscais carregadas: {len(nfse_df)} registros")
            except Exception as e:
                logger.warning(f"Erro ao carregar notas fiscais: {e}")
                nfse_df = None
        
        logger.info("Executando auditorias...")
        
        # Executa auditoria de cart√£o
        cartao_results = audit_cartao_transactions(cartao_df, generated_df)
        
        # Calcula estat√≠sticas do cart√£o
        cartao_stats = {
            'total_transacoes': len(cartao_df),
            'cartao_encontradas': len([r for r in cartao_results if r['tipo_pagamento'] == 'CART√ÉO' and r['status'] == 'COINCIDENTE']),
            'pix_encontradas': len([r for r in cartao_results if r['tipo_pagamento'] == 'PIX' and r['status'] == 'COINCIDENTE']),
            'nao_encontradas': len([r for r in cartao_results if r['status'] in ['N√ÉO ENCONTRADA', 'VALOR N√ÉO ENCONTRADO']]),
            'valores_coincidentes': len([r for r in cartao_results if r['status'] == 'COINCIDENTE']),
            'valores_divergentes': len([r for r in cartao_results if r['status'] == 'DIVERGENTE'])
        }
        
        # Executa auditoria PIX
        pix_results = audit_pix_transactions(banco_transactions, recebimentos_transactions)
        
        # Executa auditoria NFSe vs Recebimentos (se dados dispon√≠veis)
        nfse_results = None
        if nfse_df is not None and not nfse_df.empty:
            logger.info("Executando auditoria NFSe vs Recebimentos...")
            nfse_results = audit_nfse_vs_recebimentos(nfse_df, generated_df)
        
        logger.info("Gerando relat√≥rio unificado...")
        
        # Gera relat√≥rio unificado
        generate_unified_report(cartao_results, pix_results, cartao_stats, recebimentos_transactions, banco_transactions, output_file, banco_csv, nfse_df, nfse_results)
        
        logger.info(f"‚úÖ Auditoria unificada conclu√≠da!")
        logger.info(f"üìä Relat√≥rio salvo em: {output_file}")
        
        # Exibe resumo no console
        logger.info("\n=== RESUMO EXECUTIVO ===")
        logger.info(f"Cart√£o - Total: {cartao_stats['total_transacoes']}, Coincidentes: {cartao_stats['valores_coincidentes']}")
        logger.info(f"PIX - Banco: {len(banco_transactions)}, Recebimentos: {len(recebimentos_transactions)}")
        logger.info(f"PIX - Correspond√™ncias: {len([r for r in pix_results if r['status'] == 'CORRESPOND√äNCIA ENCONTRADA'])}")
        if nfse_df is not None:
            logger.info(f"NFSe - Total: {len(nfse_df)} notas fiscais")
        if nfse_results is not None and nfse_results:
            logger.info(f"NFSe vs Recebimentos - Coincidentes: {len([r for r in nfse_results if r['status'] == 'COINCIDENTE'])}")
            logger.info(f"NFSe vs Recebimentos - N√£o encontradas: {len([r for r in nfse_results if r['status'] == 'N√ÉO ENCONTRADA'])}")
        
        return output_file
        
    except Exception as e:
        logger.error(f"‚ùå Erro na auditoria: {e}")
        raise


def main():
    """Fun√ß√£o principal"""
    logger = setup_logging()
    
    try:
        logger.info("=== AUDITORIA UNIFICADA COMPLETA ===")
        
        # Pergunta sobre o m√©todo de sele√ß√£o de arquivos
        print("\n=== M√âTODO DE SELE√á√ÉO DE ARQUIVOS ===")
        print("1. Interface gr√°fica (recomendado)")
        print("2. PowerShell (linha de comando)")
        
        choice = input("\nEscolha o m√©todo (1 ou 2): ").strip()
        
        if choice == "1":
            files = select_files_gui()
        else:
            files = select_files_powershell()
        
        if not files:
            logger.info("Sele√ß√£o de arquivos cancelada")
            return
        
        # Extrai caminhos dos arquivos
        cartao_csv = files['cartao_csv']
        banco_csv = files['banco_csv']
        recebimentos_excel = files['recebimentos_excel']
        report_file = "data/relatorios/auditoria_unificada_completa.xlsx"
        
        # Verifica se os arquivos existem
        if not os.path.exists(cartao_csv):
            logger.error(f"Arquivo CSV do cart√£o n√£o encontrado: {cartao_csv}")
            return
        
        if not os.path.exists(banco_csv):
            logger.error(f"Arquivo CSV do banco n√£o encontrado: {banco_csv}")
            return
        
        if not os.path.exists(recebimentos_excel):
            logger.error(f"Arquivo Excel de recebimentos n√£o encontrado: {recebimentos_excel}")
            return
        
        logger.info("Carregando dados...")
        logger.info(f"üìÑ Cart√£o: {os.path.basename(cartao_csv)}")
        logger.info(f"üè¶ Banco: {os.path.basename(banco_csv)}")
        logger.info(f"üìä Recebimentos: {os.path.basename(recebimentos_excel)}")
        
        # Carrega dados de cart√£o
        cartao_df = parse_cartao_csv(cartao_csv)
        
        # Carrega dados gerados
        auditor = DataAuditor(tolerance_percentage=0.01)
        generated_df = auditor.load_generated_data(recebimentos_excel)
        generated_df = auditor.normalize_column_names(generated_df)
        
        # Converte DATA PGTO para date se necess√°rio
        if 'DATA PGTO' in generated_df.columns:
            generated_df['DATA PGTO'] = pd.to_datetime(generated_df['DATA PGTO']).dt.date
        
        # Carrega dados PIX
        banco_transactions = load_banco_pix_csv(banco_csv)
        recebimentos_transactions = load_recebimentos_excel(recebimentos_excel)
        
        logger.info("Executando auditorias...")
        
        # Executa auditoria de cart√£o
        cartao_results = audit_cartao_transactions(cartao_df, generated_df)
        
        # Calcula estat√≠sticas do cart√£o
        cartao_stats = {
            'total_transacoes': len(cartao_df),
            'cartao_encontradas': len([r for r in cartao_results if r['tipo_pagamento'] == 'CART√ÉO' and r['status'] == 'COINCIDENTE']),
            'pix_encontradas': len([r for r in cartao_results if r['tipo_pagamento'] == 'PIX' and r['status'] == 'COINCIDENTE']),
            'nao_encontradas': len([r for r in cartao_results if r['status'] in ['N√ÉO ENCONTRADA', 'VALOR N√ÉO ENCONTRADO']]),
            'valores_coincidentes': len([r for r in cartao_results if r['status'] == 'COINCIDENTE']),
            'valores_divergentes': len([r for r in cartao_results if r['status'] == 'DIVERGENTE'])
        }
        
        # Executa auditoria PIX
        pix_results = audit_pix_transactions(banco_transactions, recebimentos_transactions)
        
        # Executa auditoria NFSe vs Recebimentos (se dados dispon√≠veis)
        nfse_results = None
        if nfse_df is not None and not nfse_df.empty:
            logger.info("Executando auditoria NFSe vs Recebimentos...")
            nfse_results = audit_nfse_vs_recebimentos(nfse_df, generated_df)
        
        logger.info("Gerando relat√≥rio unificado...")
        
        # Gera relat√≥rio unificado
        generate_unified_report(cartao_results, pix_results, cartao_stats, recebimentos_transactions, banco_transactions, report_file, banco_csv, nfse_df, nfse_results)
        
        logger.info(f"‚úÖ Auditoria unificada conclu√≠da!")
        logger.info(f"üìä Relat√≥rio salvo em: {report_file}")
        
        # Exibe resumo no console
        logger.info("\n=== RESUMO EXECUTIVO ===")
        logger.info(f"Cart√£o - Total: {cartao_stats['total_transacoes']}, Coincidentes: {cartao_stats['valores_coincidentes']}")
        logger.info(f"PIX - Banco: {len(banco_transactions)}, Recebimentos: {len(recebimentos_transactions)}")
        logger.info(f"PIX - Correspond√™ncias: {len([r for r in pix_results if r['status'] == 'CORRESPOND√äNCIA ENCONTRADA'])}")
        if nfse_df is not None:
            logger.info(f"NFSe - Total: {len(nfse_df)} notas fiscais")
        if nfse_results is not None and nfse_results:
            logger.info(f"NFSe vs Recebimentos - Coincidentes: {len([r for r in nfse_results if r['status'] == 'COINCIDENTE'])}")
            logger.info(f"NFSe vs Recebimentos - N√£o encontradas: {len([r for r in nfse_results if r['status'] == 'N√ÉO ENCONTRADA'])}")
        
        # Mostra mensagem de sucesso na interface gr√°fica se dispon√≠vel
        try:
            root = tk.Tk()
            root.withdraw()
            messagebox.showinfo("Sucesso", f"Auditoria conclu√≠da com sucesso!\n\nRelat√≥rio salvo em:\n{report_file}")
            root.destroy()
        except:
            pass
        
    except Exception as e:
        logger.error(f"‚ùå Erro na auditoria: {e}")
        
        # Mostra erro na interface gr√°fica se dispon√≠vel
        try:
            root = tk.Tk()
            root.withdraw()
            messagebox.showerror("Erro", f"Erro na auditoria:\n{e}")
            root.destroy()
        except:
            pass
        
        raise


if __name__ == '__main__':
    main() 

================================================================================
ARQUIVO 8/24: config.py
TAMANHO: 5.14 KB
================================================================================

# Arquivo: config.py

import os
from dotenv import load_dotenv
from typing import Optional


class ConfigError(Exception):
    """Exce√ß√£o personalizada para erros de configura√ß√£o"""
    pass


def validate_required_env_var(var_name: str, value: Optional[str]) -> str:
    """
    Valida se uma vari√°vel de ambiente obrigat√≥ria foi carregada
    
    Args:
        var_name: Nome da vari√°vel de ambiente
        value: Valor da vari√°vel
        
    Returns:
        str: Valor validado
        
    Raises:
        ConfigError: Se a vari√°vel n√£o foi definida
    """
    if value is None or value.strip() == "":
        raise ConfigError(
            f"Vari√°vel de ambiente '{var_name}' n√£o foi definida. "
            f"Verifique se existe no arquivo .env ou nas vari√°veis do sistema."
        )
    return value.strip()


def get_env_var(var_name: str, default: Optional[str] = None) -> Optional[str]:
    """
    Obt√©m uma vari√°vel de ambiente com valor padr√£o opcional
    
    Args:
        var_name: Nome da vari√°vel de ambiente
        default: Valor padr√£o se a vari√°vel n√£o existir
        
    Returns:
        str: Valor da vari√°vel ou valor padr√£o
    """
    return os.getenv(var_name, default)


# Carrega vari√°veis de ambiente do arquivo .env
load_dotenv()

# === CONFIGURA√á√ïES OBRIGAT√ìRIAS ===
try:
    # Caminho para o arquivo .mdb e senha (obrigat√≥rias)
    MDB_FILE = validate_required_env_var("MDB_FILE", get_env_var("MDB_FILE"))
    MDB_PASSWORD = validate_required_env_var("MDB_PASSWORD", get_env_var("MDB_PASSWORD"))
except ConfigError as e:
    print(f"‚ùå Erro de configura√ß√£o: {e}")
    print("üìã Verifique se o arquivo .env existe e cont√©m as vari√°veis necess√°rias:")
    print("   MDB_FILE=caminho/para/arquivo.mdb")
    print("   MDB_PASSWORD=sua_senha")
    raise

# === CONFIGURA√á√ïES OPCIONAIS ===
# Diret√≥rio de sa√≠da para arquivos Excel
OUTPUT_DIR = get_env_var("OUTPUT_DIR", "data/recebimentos")

# Idioma da aplica√ß√£o (pt_BR, en_US, etc.)
LANGUAGE = get_env_var("LANGUAGE", "pt_BR")

# Formato de data (DD/MM/YYYY, YYYY-MM-DD, etc.)
DATE_FORMAT = get_env_var("DATE_FORMAT", "DD/MM/YYYY")

# Formato de moeda (BRL, USD, EUR, etc.)
CURRENCY_FORMAT = get_env_var("CURRENCY_FORMAT", "BRL")

# N√≠vel de log (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL = get_env_var("LOG_LEVEL", "INFO")

# Arquivo de log
LOG_FILE = get_env_var("LOG_FILE", "app.log")

# Encoding para arquivos
FILE_ENCODING = get_env_var("FILE_ENCODING", "utf-8")

# Timeout para conex√£o com banco (em segundos)
DB_TIMEOUT = int(get_env_var("DB_TIMEOUT", "30"))

# M√°ximo de registros para processar (0 = sem limite)
MAX_RECORDS = int(get_env_var("MAX_RECORDS", "0"))

# Configura√ß√µes de Excel
EXCEL_SETTINGS = {
    "engine": get_env_var("EXCEL_ENGINE", "openpyxl"),
    "sheet_name": get_env_var("EXCEL_SHEET_NAME", "Recebimentos"),
    "index": get_env_var("EXCEL_INCLUDE_INDEX", "false").lower() == "true"
}

# Configura√ß√µes de formata√ß√£o
FORMATTING = {
    "currency_format": get_env_var("CURRENCY_EXCEL_FORMAT", "R$ #,##0.00"),
    "date_format": get_env_var("DATE_EXCEL_FORMAT", "dd/mm/yyyy"),
    "auto_adjust_columns": get_env_var("AUTO_ADJUST_COLUMNS", "true").lower() == "true"
}


def validate_config() -> None:
    """
    Valida todas as configura√ß√µes carregadas
    
    Raises:
        ConfigError: Se alguma configura√ß√£o for inv√°lida
    """
    # Valida√ß√µes b√°sicas
    if not os.path.exists(MDB_FILE):
        raise ConfigError(f"Arquivo .mdb n√£o encontrado: {MDB_FILE}")
    
    if DB_TIMEOUT <= 0:
        raise ConfigError("DB_TIMEOUT deve ser maior que 0")
    
    if MAX_RECORDS < 0:
        raise ConfigError("MAX_RECORDS deve ser maior ou igual a 0")
    
    # Valida√ß√µes de diret√≥rio
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # Valida√ß√µes de formato
    valid_languages = ["pt_BR", "en_US", "es_ES"]
    if LANGUAGE not in valid_languages:
        raise ConfigError(f"LANGUAGE deve ser um dos valores: {valid_languages}")
    
    valid_currencies = ["BRL", "USD", "EUR"]
    if CURRENCY_FORMAT not in valid_currencies:
        raise ConfigError(f"CURRENCY_FORMAT deve ser um dos valores: {valid_currencies}")


def get_config_summary() -> dict:
    """
    Retorna um resumo das configura√ß√µes atuais
    
    Returns:
        dict: Dicion√°rio com as configura√ß√µes principais
    """
    return {
        "database": {
            "file": MDB_FILE,
            "timeout": DB_TIMEOUT
        },
        "output": {
            "directory": OUTPUT_DIR,
            "encoding": FILE_ENCODING
        },
        "formatting": {
            "language": LANGUAGE,
            "currency": CURRENCY_FORMAT,
            "date_format": DATE_FORMAT
        },
        "logging": {
            "level": LOG_LEVEL,
            "file": LOG_FILE
        },
        "processing": {
            "max_records": MAX_RECORDS
        }
    }


# Valida configura√ß√µes na importa√ß√£o
try:
    validate_config()
except ConfigError as e:
    print(f"‚ùå Erro na valida√ß√£o de configura√ß√µes: {e}")
    raise
 

================================================================================
ARQUIVO 9/24: debug_valor_exato.py
TAMANHO: 5.89 KB
================================================================================

import pandas as pd
import logging

def debug_valor_exato():
    """Debug para verificar compara√ß√£o exata de valores"""
    
    # Configura logging
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    logger = logging.getLogger(__name__)
    
    try:
        # Carrega recebimentos
        logger.info("Carregando recebimentos...")
        recebimentos_df = pd.read_excel("data/recebimentos/Recebimentos_2025-06.xlsx")
        
        # Calcula valor l√≠quido
        recebimentos_df['VALOR_LIQUIDO'] = recebimentos_df['VALOR M√ÉO DE OBRA'] - recebimentos_df['DESCONTO']
        
        # Converte DATA PGTO para string
        recebimentos_df['DATA_PGTO_STR'] = pd.to_datetime(recebimentos_df['DATA PGTO']).dt.strftime('%d/%m/%Y')
        
        # Valor espec√≠fico para testar
        valor_teste = 1264.54
        
        logger.info(f"Testando valor: {valor_teste}")
        logger.info(f"Tipo do valor: {type(valor_teste)}")
        
        # Procura recebimentos com esse valor exato
        matching_recebimentos = recebimentos_df[
            recebimentos_df['VALOR_LIQUIDO'].round(2) == round(valor_teste, 2)
        ]
        
        logger.info(f"Recebimentos encontrados com valor exato: {len(matching_recebimentos)}")
        
        if len(matching_recebimentos) > 0:
            for idx, row in matching_recebimentos.iterrows():
                os_numero = row['N¬∞ OS']
                mao_obra = row['VALOR M√ÉO DE OBRA']
                desconto = row['DESCONTO']
                valor_liquido = row['VALOR_LIQUIDO']
                
                logger.info(f"OS {os_numero}: M.O.={mao_obra}, Desconto={desconto}, L√≠quido={valor_liquido}")
                logger.info(f"  Tipo do valor l√≠quido: {type(valor_liquido)}")
                logger.info(f"  Valor l√≠quido == {valor_teste}: {valor_liquido == valor_teste}")
        else:
            logger.info("Nenhum recebimento encontrado com valor exato")
            
            # Mostra valores pr√≥ximos
            logger.info("Valores pr√≥ximos encontrados:")
            for idx, row in recebimentos_df.iterrows():
                valor_liquido = row['VALOR_LIQUIDO']
                diferenca = abs(valor_liquido - valor_teste)
                if diferenca <= 1:  # Diferen√ßa menor que 1 real
                    os_numero = row['N¬∞ OS']
                    mao_obra = row['VALOR M√ÉO DE OBRA']
                    desconto = row['DESCONTO']
                    
                    logger.info(f"OS {os_numero}: M.O.={mao_obra}, Desconto={desconto}, L√≠quido={valor_liquido}, Diferen√ßa={diferenca}")
                    logger.info(f"  Tipo do valor l√≠quido: {type(valor_liquido)}")
                    logger.info(f"  Valor l√≠quido == {valor_teste}: {valor_liquido == valor_teste}")
        
        # Testa com diferentes tipos de dados
        logger.info(f"\n=== TESTE DE TIPOS DE DADOS ===")
        logger.info(f"Valor teste (float): {valor_teste}")
        logger.info(f"Valor teste (str): {str(valor_teste)}")
        
        # Verifica se h√° problemas de precis√£o
        logger.info(f"\n=== VERIFICA√á√ÉO DE PRECIS√ÉO ===")
        for idx, row in recebimentos_df.iterrows():
            valor_liquido = row['VALOR_LIQUIDO']
            if abs(valor_liquido - valor_teste) < 0.01:  # Diferen√ßa muito pequena
                os_numero = row['N¬∞ OS']
                mao_obra = row['VALOR M√ÉO DE OBRA']
                desconto = row['DESCONTO']
                
                logger.info(f"OS {os_numero}: M.O.={mao_obra}, Desconto={desconto}")
                logger.info(f"  C√°lculo: {mao_obra} - {desconto} = {valor_liquido}")
                logger.info(f"  Valor l√≠quido: {valor_liquido}")
                logger.info(f"  Valor teste: {valor_teste}")
                logger.info(f"  Diferen√ßa: {valor_liquido - valor_teste}")
                logger.info(f"  Compara√ß√£o exata: {valor_liquido == valor_teste}")
                logger.info(f"  Compara√ß√£o com round(2): {round(valor_liquido, 2) == round(valor_teste, 2)}")
                logger.info(f"  Compara√ß√£o com round(4): {round(valor_liquido, 4) == round(valor_teste, 4)}")
                logger.info("")
        
        # Mostra todos os valores l√≠quidos para debug
        logger.info(f"\n=== TODOS OS VALORES L√çQUIDOS ===")
        for idx, row in recebimentos_df.iterrows():
            os_numero = row['N¬∞ OS']
            mao_obra = row['VALOR M√ÉO DE OBRA']
            desconto = row['DESCONTO']
            valor_liquido = row['VALOR_LIQUIDO']
            
            if abs(valor_liquido - valor_teste) < 10:  # Valores pr√≥ximos
                logger.info(f"OS {os_numero}: {mao_obra} - {desconto} = {valor_liquido}")
        
        # Verifica se existe algum recebimento com valor 1315 de m√£o de obra
        logger.info(f"\n=== VERIFICANDO OS 3939 ===")
        os_3939 = recebimentos_df[recebimentos_df['N¬∞ OS'] == 3939]
        if len(os_3939) > 0:
            row = os_3939.iloc[0]
            mao_obra = row['VALOR M√ÉO DE OBRA']
            desconto = row['DESCONTO']
            valor_liquido = row['VALOR_LIQUIDO']
            
            logger.info(f"OS 3939 encontrada:")
            logger.info(f"  M.O.: {mao_obra}")
            logger.info(f"  Desconto: {desconto}")
            logger.info(f"  Valor l√≠quido: {valor_liquido}")
            logger.info(f"  C√°lculo: {mao_obra} - {desconto} = {mao_obra - desconto}")
            logger.info(f"  Compara√ß√£o com 1264.54: {valor_liquido == 1264.54}")
            logger.info(f"  Compara√ß√£o com round: {round(valor_liquido, 2) == round(1264.54, 2)}")
        else:
            logger.info("OS 3939 n√£o encontrada")
        
    except Exception as e:
        logger.error(f"Erro: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    debug_valor_exato() 

================================================================================
ARQUIVO 10/24: executar_auditoria.bat
TAMANHO: 0.25 KB
================================================================================

@echo off
REM Ativa o ambiente virtual
call "%~dp0venv\Scripts\activate.bat"

REM Executa o app.py
python app.py

REM Ap√≥s finalizar o app.py, executa a interface gr√°fica
echo Iniciando interface gr√°fica...
python auditoria_gui.py

pause 

================================================================================
ARQUIVO 11/24: extrator_nfse.py
TAMANHO: 14.68 KB
================================================================================

#!/usr/bin/env python3
"""
Extrator de Notas Fiscais de Servi√ßo (NFSe)
Extrai nomes e valores totais de arquivos PDF de notas fiscais de servi√ßo
"""

import os
import re
import logging
import pandas as pd
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import pdfplumber
from pathlib import Path


class NFSeExtractor:
    """Classe para extrair dados de Notas Fiscais de Servi√ßo (NFSe)"""
    
    def __init__(self, log_level: str = "INFO"):
        """Inicializa o extrator"""
        self.setup_logging(log_level)
        self.logger = logging.getLogger(__name__)
        
        # Padr√µes para extra√ß√£o de dados
        self.patterns = {
            'numero_nfse': [
                r'N[¬∫o]:?\s*(\d+/\d+)',
                r'NFSe[\s\-:]*[Nn][¬∫o]?:?\s*(\d+/\d+)',
                r'Nota Fiscal de Servi√ßos Eletr√¥nica[\s\-:]*N[¬∫o]?:?\s*(\d+/\d+)',
                r'N[¬∫o]?:?\s*(\d+/\d+)',
            ],
            'valor_total': [
                r'Valor dos servi√ßos:?\s*R?\$?\s*([\d\.]+,[\d]{2})',
                r'Valor L√≠quido:?\s*R?\$?\s*([\d\.]+,[\d]{2})',
                r'Valor Total dos Servi√ßos[\s\-:]*R?\$?\s*([\d\.]+,[\d]{2})',
                r'Valor Total[\s\-:]*R?\$?\s*([\d\.]+,[\d]{2})',
                r'Total[\s\-:]*R?\$?\s*([\d\.]+,[\d]{2})',
                r'R?\$?\s*([\d\.]+,[\d]{2})',
            ],
            'nome_tomador': [
                r'Tomador do\(s\) Servi√ßo\(s\)[^\n]*\nCPF/CNPJ:[^\n]*\n([^\n]+)',
                r'Tomador[\s\-:]*([^\n\r]+)',
                r'Cliente[\s\-:]*([^\n\r]+)',
                r'Nome[\s\-:]*([^\n\r]+)',
                r'Raz√£o Social[\s\-:]*([^\n\r]+)',
            ],
            'cnpj_cpf': [
                r'CPF/CNPJ:\s*([\d.-]+)',
                r'CNPJ[:\s]*(\d{2}\.?\d{3}\.?\d{3}/?\d{4}-?\d{2})',
                r'CPF[:\s]*(\d{3}\.?\d{3}\.?\d{3}-?\d{2})',
                r'(\d{2}\.?\d{3}\.?\d{3}/?\d{4}-?\d{2})',  # CNPJ
                r'(\d{3}\.?\d{3}\.?\d{3}-?\d{2})',  # CPF
            ],
            'data_emissao': [
                r'Data de Emiss√£o[:\s]*(\d{2}/\d{2}/\d{4})',
                r'Emiss√£o[:\s]*(\d{2}/\d{2}/\d{4})',
                r'(\d{2}/\d{2}/\d{4})',  # Data no formato DD/MM/AAAA
            ],
            'descricao_servico': [
                r'Descri√ß√£o do Servi√ßo[:\s]*([^\n\r]+)',
                r'Servi√ßo[:\s]*([^\n\r]+)',
                r'Descri√ß√£o[:\s]*([^\n\r]+)',
            ]
        }
    
    def setup_logging(self, level: str):
        """Configura o sistema de logging"""
        logging.basicConfig(
            level=getattr(logging, level.upper()),
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('nfse_extractor.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
    
    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """
        Extrai texto de um arquivo PDF
        
        Args:
            pdf_path: Caminho para o arquivo PDF
            
        Returns:
            str: Texto extra√≠do do PDF
        """
        try:
            self.logger.info(f"Extraindo texto do PDF: {pdf_path}")
            
            text = ""
            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages, 1):
                    self.logger.debug(f"Processando p√°gina {page_num}")
                    page_text = page.extract_text()
                    if page_text:
                        text += f"\n--- P√ÅGINA {page_num} ---\n"
                        text += page_text
                        text += "\n"
            
            self.logger.info(f"Texto extra√≠do com sucesso: {len(text)} caracteres")
            return text
            
        except Exception as e:
            error_msg = f"Erro ao extrair texto do PDF {pdf_path}: {e}"
            self.logger.error(error_msg)
            raise Exception(error_msg)
    
    def extract_value_with_patterns(self, text: str, pattern_key: str) -> Optional[str]:
        """
        Extrai valor usando m√∫ltiplos padr√µes
        
        Args:
            text: Texto para extrair
            pattern_key: Chave do padr√£o a usar
            
        Returns:
            str: Valor extra√≠do ou None
        """
        patterns = self.patterns.get(pattern_key, [])
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
            if match:
                value = match.group(1).strip()
                if value:
                    self.logger.debug(f"Encontrado {pattern_key}: {value}")
                    return value
        
        return None
    
    def clean_value(self, value: str, value_type: str) -> str:
        """
        Limpa e formata valores extra√≠dos
        
        Args:
            value: Valor a ser limpo
            value_type: Tipo do valor (valor_total, cnpj_cpf, etc.)
            
        Returns:
            str: Valor limpo
        """
        if not value:
            return ""
        
        value = value.strip()
        
        if value_type == 'valor_total':
            # Remove caracteres n√£o num√©ricos exceto v√≠rgula e ponto
            value = re.sub(r'[^\d,\.]', '', value)
            # Troca ponto por nada e v√≠rgula por ponto para float
            value = value.replace('.', '').replace(',', '.')
        
        elif value_type == 'cnpj_cpf':
            # Remove caracteres n√£o num√©ricos
            value = re.sub(r'[^\d]', '', value)
        
        elif value_type == 'nome_tomador':
            # Remove caracteres especiais e normaliza espa√ßos
            value = re.sub(r'[^\w\s√Å√â√ç√ì√ö√Ç√ä√é√î√õ√É√ï√á√°√©√≠√≥√∫√¢√™√Æ√¥√ª√£√µ√ß]', '', value)
            value = re.sub(r'\s+', ' ', value)
        
        return value.strip()
    
    def extract_nfse_data(self, pdf_path: str) -> dict:
        """
        Extrai dados de uma NFSe do PDF
        
        Args:
            pdf_path: Caminho para o arquivo PDF
            
        Returns:
            dict: Dicion√°rio com os dados extra√≠dos
        """
        try:
            self.logger.info(f"Processando NFSe: {pdf_path}")
            
            # Extrai texto do PDF
            texto = self.extract_text_from_pdf(pdf_path)
            
            # Extrai dados usando regex
            numero_nfse = self.extract_value_with_patterns(texto, 'numero_nfse')
            nome_tomador = self.extract_value_with_patterns(texto, 'nome_tomador')
            valor_total_text = self.extract_value_with_patterns(texto, 'valor_total')
            data_emissao = self.extract_value_with_patterns(texto, 'data_emissao')
            
            # Converte valor_total para float
            valor_total = None
            if valor_total_text:
                try:
                    # Remove caracteres n√£o num√©ricos exceto v√≠rgula e ponto
                    valor_limpo = re.sub(r'[^\d,\.]', '', valor_total_text)
                    # Troca ponto por nada e v√≠rgula por ponto para float
                    valor_limpo = valor_limpo.replace('.', '').replace(',', '.')
                    valor_total = float(valor_limpo)
                except (ValueError, AttributeError):
                    self.logger.warning(f"Erro ao converter valor_total '{valor_total_text}' para float")
                    valor_total = None
            
            # Cria dicion√°rio com dados essenciais
            dados = {
                'numero_nfse': numero_nfse,
                'nome_tomador': nome_tomador,
                'valor_total': valor_total,
                'data_emissao': data_emissao
            }
            
            self.logger.info(f"Dados extra√≠dos: {dados}")
            return dados
            
        except Exception as e:
            error_msg = f"Erro ao extrair dados de {pdf_path}: {e}"
            self.logger.error(error_msg)
            raise Exception(error_msg)
    
    def process_directory(self, directory_path: str) -> pd.DataFrame:
        """
        Processa todos os PDFs em um diret√≥rio
        
        Args:
            directory_path: Caminho para o diret√≥rio
            
        Returns:
            pd.DataFrame: DataFrame com dados extra√≠dos
        """
        try:
            self.logger.info(f"Processando diret√≥rio: {directory_path}")
            
            # Encontra todos os arquivos PDF (evita duplicatas)
            pdf_files = set()
            for ext in ['*.pdf', '*.PDF']:
                pdf_files.update(Path(directory_path).glob(ext))
            
            # Converte para lista e ordena
            pdf_files = sorted(list(pdf_files))
            
            if not pdf_files:
                self.logger.warning(f"Nenhum arquivo PDF encontrado em: {directory_path}")
                return pd.DataFrame()
            
            self.logger.info(f"Encontrados {len(pdf_files)} arquivos PDF √∫nicos")
            
            # Processa cada arquivo
            results = []
            processed_files = set()  # Para evitar duplicatas
            
            for pdf_file in pdf_files:
                if str(pdf_file) in processed_files:
                    self.logger.warning(f"Arquivo j√° processado, pulando: {pdf_file}")
                    continue
                    
                try:
                    data = self.extract_nfse_data(str(pdf_file))
                    results.append(data)
                    processed_files.add(str(pdf_file))
                except Exception as e:
                    self.logger.error(f"Erro ao processar {pdf_file}: {e}")
                    results.append({
                        'numero_nfse': None,
                        'nome_tomador': None,
                        'valor_total': None,
                        'data_emissao': None
                    })
                    processed_files.add(str(pdf_file))
            
            # Cria DataFrame
            df = pd.DataFrame(results)
            
            # Converte valor_total para float se ainda n√£o estiver
            if 'valor_total' in df.columns:
                df['valor_total'] = pd.to_numeric(df['valor_total'], errors='coerce')
            
            # Reordena colunas
            column_order = ['numero_nfse', 'nome_tomador', 'valor_total', 'data_emissao']
            df = df[[col for col in column_order if col in df.columns]]
            
            self.logger.info(f"Processamento conclu√≠do: {len(df)} registros √∫nicos")
            return df
            
        except Exception as e:
            error_msg = f"Erro ao processar diret√≥rio {directory_path}: {e}"
            self.logger.error(error_msg)
            raise Exception(error_msg)
    
    def save_results(self, df: pd.DataFrame, output_path: str):
        """
        Salva resultados em arquivo Excel
        
        Args:
            df: DataFrame com resultados
            output_path: Caminho para salvar
        """
        try:
            self.logger.info(f"Salvando resultados em: {output_path}")
            
            # Garante que o diret√≥rio existe
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # Salva em Excel
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name='NFSe_Extraidas', index=False)
                
                # Cria planilha de resumo
                summary_data = {
                    'M√©trica': [
                        'Total de arquivos processados',
                        'Arquivos com sucesso',
                        'Arquivos com erro',
                        'Total de valores extra√≠dos',
                        'Valor total das NFSe',
                        'Data do processamento'
                    ],
                    'Valor': [
                        len(df),
                        len(df[df['numero_nfse'].notna()]),
                        len(df[df['numero_nfse'].isna()]),
                        len(df[df['valor_total'].notna()]),
                        df[df['valor_total'].notna()]['valor_total'].sum() if len(df[df['valor_total'].notna()]) > 0 else 0,
                        datetime.now().strftime('%d/%m/%Y %H:%M:%S')
                    ]
                }
                
                summary_df = pd.DataFrame(summary_data)
                summary_df.to_excel(writer, sheet_name='Resumo', index=False)
            
            self.logger.info(f"Resultados salvos com sucesso: {output_path}")
            
        except Exception as e:
            error_msg = f"Erro ao salvar resultados: {e}"
            self.logger.error(error_msg)
            raise Exception(error_msg)


def main():
    """Fun√ß√£o principal"""
    try:
        # Configura logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        
        # Cria extrator
        extrator = NFSeExtractor()
        
        # Processa diret√≥rio
        directory_path = "data/06-JUN"
        df = extrator.process_directory(directory_path)
        
        if df.empty:
            print("Nenhum arquivo PDF encontrado para processar.")
            return
        
        # Calcula totais
        total_arquivos = len(df)
        arquivos_sucesso = len(df[df['numero_nfse'].notna()])
        arquivos_erro = total_arquivos - arquivos_sucesso
        
        # Calcula valor total (j√° est√° como float)
        valores_validos = df[df['valor_total'].notna()]['valor_total']
        valor_total = valores_validos.sum()
        
        # Salva resultados
        output_file = "data/relatorios/nfse_extraidas.xlsx"
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        df.to_excel(output_file, index=False)
        extrator.logger.info(f"Resultados salvos com sucesso: {output_file}")
        
        # Exibe resumo
        print("\n=== RESUMO DA EXTRA√á√ÉO ===")
        print(f"Total de arquivos processados: {total_arquivos}")
        print(f"Arquivos com sucesso: {arquivos_sucesso}")
        print(f"Arquivos com erro: {arquivos_erro}")
        print(f"Valor total das NFSe: R$ {valor_total:,.2f}")
        print(f"\nArquivo de sa√≠da: {output_file}")
        
        # Mostra primeiras linhas
        print(f"\n=== PRIMEIRAS 5 LINHAS ===")
        print(df.head().to_string(index=False))
        
    except Exception as e:
        print(f"Erro: {e}")
        logging.error(f"Erro na execu√ß√£o: {e}")


if __name__ == "__main__":
    main() 

================================================================================
ARQUIVO 12/24: gerar_arquivo_projeto.py
TAMANHO: 3.52 KB
================================================================================

#!/usr/bin/env python3
"""
Script para gerar um arquivo .txt com todos os arquivos do projeto
Exclui pastas venv, historico, _historico e __pycache__
"""

import os
import glob
from pathlib import Path

def should_ignore_path(path):
    """Verifica se o caminho deve ser ignorado"""
    ignore_dirs = ['venv', 'historico', '_historico', '__pycache__', '.git']
    path_parts = Path(path).parts
    
    for ignore_dir in ignore_dirs:
        if ignore_dir in path_parts:
            return True
    return False

def get_file_content(file_path):
    """L√™ o conte√∫do de um arquivo com tratamento de encoding"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except UnicodeDecodeError:
        try:
            with open(file_path, 'r', encoding='latin-1') as f:
                return f.read()
        except:
            return f"[ERRO: N√£o foi poss√≠vel ler o arquivo {file_path}]"
    except Exception as e:
        return f"[ERRO: {e} ao ler {file_path}]"

def main():
    """Fun√ß√£o principal"""
    # Extens√µes de arquivos relevantes
    relevant_extensions = [
        '*.py', '*.txt', '*.md', '*.json', '*.yml', '*.yaml', 
        '*.ini', '*.cfg', '*.conf', '*.bat', '*.sh'
    ]
    
    # Nomes de arquivos relevantes
    relevant_names = [
        'requirements*', 'setup*', 'config*', 'README*', 
        '.gitignore', 'Dockerfile*', 'docker-compose*'
    ]
    
    # Lista todos os arquivos
    all_files = []
    
    # Busca por extens√µes
    for ext in relevant_extensions:
        files = glob.glob(f"**/{ext}", recursive=True)
        all_files.extend(files)
    
    # Busca por nomes espec√≠ficos
    for name in relevant_names:
        files = glob.glob(f"**/{name}", recursive=True)
        all_files.extend(files)
    
    # Remove duplicatas e ordena
    all_files = sorted(list(set(all_files)))
    
    # Filtra arquivos ignorados
    filtered_files = []
    for file_path in all_files:
        if not should_ignore_path(file_path) and os.path.isfile(file_path):
            filtered_files.append(file_path)
    
    # Gera o arquivo de sa√≠da
    output_file = "projeto_completo.txt"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("PROJETO RECEBIMENTOS - ARQUIVOS COMPLETOS\n")
        f.write("=" * 80 + "\n")
        f.write(f"Total de arquivos: {len(filtered_files)}\n")
        f.write("=" * 80 + "\n\n")
        
        for i, file_path in enumerate(filtered_files, 1):
            try:
                # Obt√©m estat√≠sticas do arquivo
                file_size = os.path.getsize(file_path)
                file_size_kb = file_size / 1024
                
                f.write(f"\n{'='*80}\n")
                f.write(f"ARQUIVO {i}/{len(filtered_files)}: {file_path}\n")
                f.write(f"TAMANHO: {file_size_kb:.2f} KB\n")
                f.write(f"{'='*80}\n\n")
                
                # L√™ e escreve o conte√∫do
                content = get_file_content(file_path)
                f.write(content)
                f.write("\n")
                
            except Exception as e:
                f.write(f"[ERRO ao processar {file_path}: {e}]\n")
    
    print(f"Arquivo gerado com sucesso: {output_file}")
    print(f"Total de arquivos inclu√≠dos: {len(filtered_files)}")
    print("\nArquivos inclu√≠dos:")
    for file_path in filtered_files:
        print(f"  - {file_path}")

if __name__ == "__main__":
    main() 

================================================================================
ARQUIVO 13/24: modules\__init__.py
TAMANHO: 0.92 KB
================================================================================

# M√≥dulos do sistema de processamento de recebimentos

from .access_db import get_connection, get_connection_context, DatabaseConnectionError, test_connection, get_database_info
from .extractors import extract_all_data, ExtractionError, get_ordens, get_contas, get_fcaixa
from .processors import process_recebimentos
from .exporters import export_to_excel
from .auditor import DataAuditor, AuditError, AuditResult, AuditSummary

__all__ = [
    # Database
    'get_connection',
    'get_connection_context', 
    'DatabaseConnectionError',
    'test_connection',
    'get_database_info',
    
    # Extractors
    'extract_all_data',
    'ExtractionError',
    'get_ordens',
    'get_contas', 
    'get_fcaixa',
    
    # Processors
    'process_recebimentos',
    
    # Exporters
    'export_to_excel',
    
    # Auditor
    'DataAuditor',
    'AuditError',
    'AuditResult',
    'AuditSummary'
]


================================================================================
ARQUIVO 14/24: modules\access_db.py
TAMANHO: 5.66 KB
================================================================================

# Arquivo: modules/access_db.py

import pyodbc
import logging
from typing import Optional
from contextlib import contextmanager


class DatabaseConnectionError(Exception):
    """Exce√ß√£o personalizada para erros de conex√£o com banco de dados"""
    pass


def get_connection(mdb_file: str, password: str):
    """
    Conecta ao .mdb/.accdb usando ODBC.
    
    Args:
        mdb_file: Caminho para o arquivo .mdb/.accdb
        password: Senha do banco de dados
        
    Returns:
        pyodbc.Connection: Conex√£o com o banco de dados
        
    Raises:
        DatabaseConnectionError: Se houver erro na conex√£o
    """
    try:
        conn_str = (
            r"DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};"
            rf"DBQ={mdb_file};"
            rf"PWD={password};"
        )
        
        logging.info(f"Tentando conectar ao banco: {mdb_file}")
        connection = pyodbc.connect(conn_str)
        logging.info("Conex√£o estabelecida com sucesso")
        
        return connection
        
    except pyodbc.Error as e:
        error_msg = str(e)
        logging.error(f"Erro pyodbc na conex√£o: {error_msg}")
        
        # Identifica tipos espec√≠ficos de erro
        if "authentication" in error_msg.lower() or "password" in error_msg.lower():
            raise DatabaseConnectionError(
                f"Erro de autentica√ß√£o: Senha incorreta ou usu√°rio n√£o autorizado. "
                f"Detalhes: {error_msg}"
            )
        elif "driver" in error_msg.lower() or "microsoft access driver" in error_msg.lower():
            raise DatabaseConnectionError(
                f"Driver ODBC n√£o encontrado: Microsoft Access Driver (*.mdb, *.accdb) "
                f"n√£o est√° instalado. Instale o Microsoft Access Database Engine. "
                f"Detalhes: {error_msg}"
            )
        elif "file" in error_msg.lower() or "path" in error_msg.lower():
            raise DatabaseConnectionError(
                f"Arquivo n√£o encontrado ou inacess√≠vel: {mdb_file}. "
                f"Verifique se o arquivo existe e tem permiss√µes de leitura. "
                f"Detalhes: {error_msg}"
            )
        elif "locked" in error_msg.lower() or "exclusive" in error_msg.lower():
            raise DatabaseConnectionError(
                f"Arquivo bloqueado: O banco de dados est√° sendo usado por outro processo. "
                f"Feche outros programas que possam estar usando o arquivo. "
                f"Detalhes: {error_msg}"
            )
        else:
            raise DatabaseConnectionError(
                f"Erro de conex√£o com o banco de dados: {error_msg}"
            )
            
    except Exception as e:
        logging.error(f"Erro inesperado na conex√£o: {e}")
        raise DatabaseConnectionError(
            f"Erro inesperado ao conectar ao banco de dados: {e}"
        )


@contextmanager
def get_connection_context(mdb_file: str, password: str):
    """
    Context manager para conex√£o com banco de dados.
    Garante que a conex√£o seja fechada automaticamente.
    
    Args:
        mdb_file: Caminho para o arquivo .mdb/.accdb
        password: Senha do banco de dados
        
    Yields:
        pyodbc.Connection: Conex√£o com o banco de dados
        
    Raises:
        DatabaseConnectionError: Se houver erro na conex√£o
    """
    connection = None
    try:
        connection = get_connection(mdb_file, password)
        yield connection
        
    except Exception as e:
        logging.error(f"Erro durante uso da conex√£o: {e}")
        raise
        
    finally:
        if connection:
            try:
                connection.close()
                logging.info("Conex√£o fechada com sucesso")
            except Exception as e:
                logging.warning(f"Erro ao fechar conex√£o: {e}")


def test_connection(mdb_file: str, password: str) -> bool:
    """
    Testa a conex√£o com o banco de dados sem executar queries.
    
    Args:
        mdb_file: Caminho para o arquivo .mdb/.accdb
        password: Senha do banco de dados
        
    Returns:
        bool: True se a conex√£o for bem-sucedida, False caso contr√°rio
    """
    try:
        with get_connection_context(mdb_file, password) as conn:
            # Testa se a conex√£o est√° ativa
            cursor = conn.cursor()
            cursor.execute("SELECT 1")
            cursor.fetchone()
            cursor.close()
            logging.info("Teste de conex√£o bem-sucedido")
            return True
            
    except Exception as e:
        logging.error(f"Teste de conex√£o falhou: {e}")
        return False


def get_database_info(mdb_file: str, password: str) -> Optional[dict]:
    """
    Obt√©m informa√ß√µes sobre o banco de dados.
    
    Args:
        mdb_file: Caminho para o arquivo .mdb/.accdb
        password: Senha do banco de dados
        
    Returns:
        dict: Informa√ß√µes do banco ou None se houver erro
    """
    try:
        with get_connection_context(mdb_file, password) as conn:
            cursor = conn.cursor()
            
            # Lista as tabelas dispon√≠veis
            tables = []
            for table_info in cursor.tables():
                if table_info.table_type == 'TABLE':
                    tables.append(table_info.table_name)
            
            cursor.close()
            
            return {
                "file_path": mdb_file,
                "tables": tables,
                "table_count": len(tables)
            }
            
    except Exception as e:
        logging.error(f"Erro ao obter informa√ß√µes do banco: {e}")
        return None

================================================================================
ARQUIVO 15/24: modules\auditor.py
TAMANHO: 21.91 KB
================================================================================

"""
M√≥dulo de Auditoria - Compara dados CSV com dados gerados pela aplica√ß√£o
"""

import pandas as pd
import logging
from typing import Dict, List, Tuple, Any, Optional
from datetime import datetime
import os
from dataclasses import dataclass


@dataclass
class AuditResult:
    """Resultado de uma auditoria individual"""
    field_name: str
    csv_value: Any
    generated_value: Any
    is_match: bool
    difference: Optional[float] = None
    percentage_diff: Optional[float] = None
    notes: str = ""


@dataclass
class AuditSummary:
    """Resumo geral da auditoria"""
    total_records: int
    matching_records: int
    mismatched_records: int
    total_fields_checked: int
    matching_fields: int
    mismatched_fields: int
    audit_date: datetime
    csv_file: str
    generated_file: str
    tolerance_percentage: float = 0.01  # 1% de toler√¢ncia por padr√£o


class AuditError(Exception):
    """Exce√ß√£o personalizada para erros de auditoria"""
    pass


class DataAuditor:
    """
    Classe principal para auditoria de dados CSV contra dados gerados
    """
    
    def __init__(self, tolerance_percentage: float = 0.01):
        """
        Inicializa o auditor
        
        Args:
            tolerance_percentage: Percentual de toler√¢ncia para compara√ß√µes num√©ricas (padr√£o: 1%)
        """
        self.tolerance_percentage = tolerance_percentage
        self.logger = logging.getLogger(__name__)
    
    def load_csv_data(self, csv_file_path: str) -> pd.DataFrame:
        """
        Carrega dados do arquivo CSV
        
        Args:
            csv_file_path: Caminho para o arquivo CSV
            
        Returns:
            pd.DataFrame: Dados carregados do CSV
            
        Raises:
            AuditError: Se houver erro ao carregar o arquivo
        """
        try:
            self.logger.info(f"Carregando dados CSV: {csv_file_path}")
            
            # Tenta diferentes encodings
            encodings = ['utf-8', 'latin1', 'cp1252']
            df = None
            
            for encoding in encodings:
                try:
                    df = pd.read_csv(csv_file_path, encoding=encoding)
                    self.logger.info(f"CSV carregado com encoding: {encoding}")
                    break
                except UnicodeDecodeError:
                    continue
                except pd.errors.EmptyDataError:
                    # DataFrame vazio - cria um DataFrame vazio com colunas padr√£o
                    self.logger.warning(f"Arquivo CSV vazio: {csv_file_path}")
                    df = pd.DataFrame(columns=['N¬∞ OS'])  # Coluna m√≠nima necess√°ria
                    break
            
            if df is None:
                raise AuditError(f"N√£o foi poss√≠vel carregar o arquivo CSV: {csv_file_path}")
            
            self.logger.info(f"CSV carregado com sucesso: {len(df)} registros, {len(df.columns)} colunas")
            return df
            
        except Exception as e:
            error_msg = f"Erro ao carregar arquivo CSV {csv_file_path}: {e}"
            self.logger.error(error_msg)
            raise AuditError(error_msg)
    
    def load_generated_data(self, excel_file_path: str, sheet_name: str = None) -> pd.DataFrame:
        """
        Carrega dados do arquivo Excel gerado pela aplica√ß√£o
        
        Args:
            excel_file_path: Caminho para o arquivo Excel
            sheet_name: Nome da planilha (se None, usa a primeira)
            
        Returns:
            pd.DataFrame: Dados carregados do Excel
            
        Raises:
            AuditError: Se houver erro ao carregar o arquivo
        """
        try:
            self.logger.info(f"Carregando dados Excel: {excel_file_path}")
            
            if sheet_name:
                df = pd.read_excel(excel_file_path, sheet_name=sheet_name)
            else:
                # L√™ a primeira planilha
                excel_file = pd.ExcelFile(excel_file_path)
                sheet_name = excel_file.sheet_names[0]
                df = pd.read_excel(excel_file_path, sheet_name=sheet_name)
            
            self.logger.info(f"Excel carregado com sucesso: {len(df)} registros, {len(df.columns)} colunas")
            self.logger.info(f"Planilha utilizada: {sheet_name}")
            
            return df
            
        except Exception as e:
            error_msg = f"Erro ao carregar arquivo Excel {excel_file_path}: {e}"
            self.logger.error(error_msg)
            raise AuditError(error_msg)
    
    def normalize_column_names(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Normaliza nomes das colunas para facilitar compara√ß√£o
        
        Args:
            df: DataFrame a ser normalizado
            
        Returns:
            pd.DataFrame: DataFrame com colunas normalizadas
        """
        df_normalized = df.copy()
        
        # Mapeamento de normaliza√ß√£o
        normalization_map = {
            'N¬∞ OS': ['N_OS', 'N¬∞ OS', 'NUMERO_OS', 'OS', 'numero_os'],
            'DATA PGTO': ['DATA_PGTO', 'DATA PGTO', 'DATA_PAGAMENTO', 'data_pagamento'],
            'VALOR TOTAL': ['VALOR_TOTAL', 'VALOR TOTAL', 'TOTAL', 'valor_total'],
            'VALOR PAGO': ['VALOR_PAGO', 'VALOR PAGO', 'PAGO', 'valor_pago'],
            'C√ìDIGO CLIENTE': ['CODIGO_CLIENTE', 'C√ìDIGO CLIENTE', 'CLIENTE', 'codigo_cliente'],
            'VE√çCULO (PLACA)': ['VEICULO_PLACA', 'VE√çCULO (PLACA)', 'PLACA', 'placa_veiculo']
        }
        
        # Aplica normaliza√ß√£o
        for standard_name, variations in normalization_map.items():
            for col in df_normalized.columns:
                if col in variations:
                    df_normalized = df_normalized.rename(columns={col: standard_name})
                    break
        
        return df_normalized
    
    def compare_numeric_values(self, value1: Any, value2: Any, field_name: str) -> AuditResult:
        """
        Compara valores num√©ricos com toler√¢ncia
        
        Args:
            value1: Primeiro valor (CSV)
            value2: Segundo valor (gerado)
            field_name: Nome do campo sendo comparado
            
        Returns:
            AuditResult: Resultado da compara√ß√£o
        """
        try:
            # Converte para float
            val1 = float(value1) if pd.notna(value1) else 0.0
            val2 = float(value2) if pd.notna(value2) else 0.0
            
            # Calcula diferen√ßa
            difference = abs(val1 - val2)
            percentage_diff = (difference / max(val1, val2)) * 100 if max(val1, val2) > 0 else 0
            
            # Verifica se est√° dentro da toler√¢ncia
            is_match = percentage_diff <= (self.tolerance_percentage * 100)
            
            notes = f"Diferen√ßa: {difference:.2f} ({percentage_diff:.2f}%)"
            if not is_match:
                notes += f" - Excede toler√¢ncia de {self.tolerance_percentage * 100:.2f}%"
            
            return AuditResult(
                field_name=field_name,
                csv_value=val1,
                generated_value=val2,
                is_match=is_match,
                difference=difference,
                percentage_diff=percentage_diff,
                notes=notes
            )
            
        except (ValueError, TypeError) as e:
            return AuditResult(
                field_name=field_name,
                csv_value=value1,
                generated_value=value2,
                is_match=False,
                notes=f"Erro na convers√£o num√©rica: {e}"
            )
    
    def compare_text_values(self, value1: Any, value2: Any, field_name: str) -> AuditResult:
        """
        Compara valores de texto
        
        Args:
            value1: Primeiro valor (CSV)
            value2: Segundo valor (gerado)
            field_name: Nome do campo sendo comparado
            
        Returns:
            AuditResult: Resultado da compara√ß√£o
        """
        # Normaliza valores
        str1 = str(value1).strip().upper() if pd.notna(value1) else ""
        str2 = str(value2).strip().upper() if pd.notna(value2) else ""
        
        is_match = str1 == str2
        notes = "Valores id√™nticos" if is_match else f"CSV: '{str1}' vs Gerado: '{str2}'"
        
        return AuditResult(
            field_name=field_name,
            csv_value=str1,
            generated_value=str2,
            is_match=is_match,
            notes=notes
        )
    
    def compare_date_values(self, value1: Any, value2: Any, field_name: str) -> AuditResult:
        """
        Compara valores de data
        
        Args:
            value1: Primeiro valor (CSV)
            value2: Segundo valor (gerado)
            field_name: Nome do campo sendo comparado
            
        Returns:
            AuditResult: Resultado da compara√ß√£o
        """
        try:
            # Converte para datetime
            date1 = pd.to_datetime(value1) if pd.notna(value1) else None
            date2 = pd.to_datetime(value2) if pd.notna(value2) else None
            
            is_match = date1 == date2
            notes = "Datas id√™nticas" if is_match else f"CSV: {date1} vs Gerado: {date2}"
            
            return AuditResult(
                field_name=field_name,
                csv_value=date1,
                generated_value=date2,
                is_match=is_match,
                notes=notes
            )
            
        except Exception as e:
            return AuditResult(
                field_name=field_name,
                csv_value=value1,
                generated_value=value2,
                is_match=False,
                notes=f"Erro na convers√£o de data: {e}"
            )
    
    def audit_record(self, csv_row: pd.Series, generated_row: pd.Series, 
                    field_mappings: Dict[str, str]) -> List[AuditResult]:
        """
        Audita um registro individual
        
        Args:
            csv_row: Linha do CSV
            generated_row: Linha dos dados gerados
            field_mappings: Mapeamento de campos CSV -> Gerado
            
        Returns:
            List[AuditResult]: Lista de resultados da auditoria
        """
        results = []
        
        for csv_field, generated_field in field_mappings.items():
            if csv_field not in csv_row.index:
                results.append(AuditResult(
                    field_name=csv_field,
                    csv_value=None,
                    generated_value=None,
                    is_match=False,
                    notes=f"Campo '{csv_field}' n√£o encontrado no CSV"
                ))
                continue
            
            if generated_field not in generated_row.index:
                results.append(AuditResult(
                    field_name=generated_field,
                    csv_value=csv_row[csv_field],
                    generated_value=None,
                    is_match=False,
                    notes=f"Campo '{generated_field}' n√£o encontrado nos dados gerados"
                ))
                continue
            
            csv_value = csv_row[csv_field]
            generated_value = generated_row[generated_field]
            
            # Determina tipo de compara√ß√£o baseado no nome do campo
            if any(keyword in generated_field.upper() for keyword in ['VALOR', 'PAGO', 'DEVEDOR', 'CART√ÉO', 'DINHEIRO', 'PIX', 'TROCO']):
                result = self.compare_numeric_values(csv_value, generated_value, generated_field)
            elif any(keyword in generated_field.upper() for keyword in ['DATA']):
                result = self.compare_date_values(csv_value, generated_value, generated_field)
            else:
                result = self.compare_text_values(csv_value, generated_value, generated_field)
            
            results.append(result)
        
        return results
    
    def audit_data(self, csv_file_path: str, generated_file_path: str, 
                   field_mappings: Dict[str, str], key_field: str = 'N¬∞ OS') -> AuditSummary:
        """
        Executa auditoria completa dos dados
        
        Args:
            csv_file_path: Caminho para o arquivo CSV
            generated_file_path: Caminho para o arquivo Excel gerado
            field_mappings: Mapeamento de campos CSV -> Gerado
            key_field: Campo chave para relacionar registros
            
        Returns:
            AuditSummary: Resumo da auditoria
            
        Raises:
            AuditError: Se houver erro na auditoria
        """
        try:
            self.logger.info("Iniciando auditoria de dados...")
            
            # Carrega dados
            csv_df = self.load_csv_data(csv_file_path)
            generated_df = self.load_generated_data(generated_file_path)
            
            # Normaliza nomes das colunas
            csv_df = self.normalize_column_names(csv_df)
            generated_df = self.normalize_column_names(generated_df)
            
            # Determina o campo chave normalizado
            normalized_key_field = None
            for standard_name, variations in [
                ('N¬∞ OS', ['N_OS', 'N¬∞ OS', 'NUMERO_OS', 'OS', 'numero_os']),
                ('DATA PGTO', ['DATA_PGTO', 'DATA PGTO', 'DATA_PAGAMENTO', 'data_pagamento']),
                ('VALOR TOTAL', ['VALOR_TOTAL', 'VALOR TOTAL', 'TOTAL', 'valor_total']),
                ('VALOR PAGO', ['VALOR_PAGO', 'VALOR PAGO', 'PAGO', 'valor_pago']),
                ('C√ìDIGO CLIENTE', ['CODIGO_CLIENTE', 'C√ìDIGO CLIENTE', 'CLIENTE', 'codigo_cliente']),
                ('VE√çCULO (PLACA)', ['VEICULO_PLACA', 'VE√çCULO (PLACA)', 'PLACA', 'placa_veiculo'])
            ]:
                if key_field in variations:
                    normalized_key_field = standard_name
                    break
            
            if normalized_key_field is None:
                normalized_key_field = key_field
            
            # Verifica se o campo chave existe
            if normalized_key_field not in csv_df.columns:
                raise AuditError(f"Campo chave '{key_field}' (normalizado: '{normalized_key_field}') n√£o encontrado no CSV. Colunas dispon√≠veis: {list(csv_df.columns)}")
            if normalized_key_field not in generated_df.columns:
                raise AuditError(f"Campo chave '{key_field}' (normalizado: '{normalized_key_field}') n√£o encontrado nos dados gerados. Colunas dispon√≠veis: {list(generated_df.columns)}")
            
            # Executa auditoria
            all_results = []
            matching_records = 0
            mismatched_records = 0
            
            for _, csv_row in csv_df.iterrows():
                key_value = csv_row[normalized_key_field]
                
                # Encontra registro correspondente nos dados gerados
                matching_generated = generated_df[generated_df[normalized_key_field] == key_value]
                
                if len(matching_generated) == 0:
                    # Registro n√£o encontrado nos dados gerados
                    mismatched_records += 1
                    for csv_field, generated_field in field_mappings.items():
                        all_results.append(AuditResult(
                            field_name=generated_field,
                            csv_value=csv_row.get(csv_field),
                            generated_value=None,
                            is_match=False,
                            notes=f"Registro com {normalized_key_field}={key_value} n√£o encontrado nos dados gerados"
                        ))
                else:
                    # Registro encontrado - compara campos
                    generated_row = matching_generated.iloc[0]
                    record_results = self.audit_record(csv_row, generated_row, field_mappings)
                    all_results.extend(record_results)
                    
                    # Verifica se todos os campos do registro coincidem
                    record_matches = all(result.is_match for result in record_results)
                    if record_matches:
                        matching_records += 1
                    else:
                        mismatched_records += 1
            
            # Calcula estat√≠sticas
            total_records = len(csv_df)
            total_fields_checked = len(all_results)
            matching_fields = sum(1 for result in all_results if result.is_match)
            mismatched_fields = total_fields_checked - matching_fields
            
            # Cria resumo
            summary = AuditSummary(
                total_records=total_records,
                matching_records=matching_records,
                mismatched_records=mismatched_records,
                total_fields_checked=total_fields_checked,
                matching_fields=matching_fields,
                mismatched_fields=mismatched_fields,
                audit_date=datetime.now(),
                csv_file=csv_file_path,
                generated_file=generated_file_path,
                tolerance_percentage=self.tolerance_percentage
            )
            
            self.logger.info("Auditoria conclu√≠da com sucesso")
            self.logger.info(f"Resumo: {matching_records}/{total_records} registros coincidem")
            self.logger.info(f"Campos: {matching_fields}/{total_fields_checked} campos coincidem")
            
            return summary, all_results
            
        except Exception as e:
            error_msg = f"Erro durante auditoria: {e}"
            self.logger.error(error_msg)
            raise AuditError(error_msg)
    
    def generate_audit_report(self, summary: AuditSummary, results: List[AuditResult], 
                            output_file: str) -> None:
        """
        Gera relat√≥rio detalhado da auditoria
        
        Args:
            summary: Resumo da auditoria
            results: Resultados detalhados
            output_file: Arquivo de sa√≠da para o relat√≥rio
        """
        try:
            self.logger.info(f"Gerando relat√≥rio de auditoria: {output_file}")
            
            # Cria relat√≥rio em Excel
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                # Resumo
                summary_data = {
                    'M√©trica': [
                        'Total de Registros',
                        'Registros Coincidentes',
                        'Registros Divergentes',
                        'Total de Campos Verificados',
                        'Campos Coincidentes',
                        'Campos Divergentes',
                        'Taxa de Sucesso (Registros)',
                        'Taxa de Sucesso (Campos)',
                        'Data da Auditoria',
                        'Arquivo CSV',
                        'Arquivo Gerado',
                        'Toler√¢ncia (%)'
                    ],
                    'Valor': [
                        summary.total_records,
                        summary.matching_records,
                        summary.mismatched_records,
                        summary.total_fields_checked,
                        summary.matching_fields,
                        summary.mismatched_fields,
                        f"{(summary.matching_records/summary.total_records)*100:.2f}%" if summary.total_records > 0 else "0%",
                        f"{(summary.matching_fields/summary.total_fields_checked)*100:.2f}%" if summary.total_fields_checked > 0 else "0%",
                        summary.audit_date.strftime('%d/%m/%Y %H:%M:%S'),
                        summary.csv_file,
                        summary.generated_file,
                        f"{summary.tolerance_percentage*100:.2f}%"
                    ]
                }
                
                summary_df = pd.DataFrame(summary_data)
                summary_df.to_excel(writer, sheet_name='Resumo', index=False)
                
                # Detalhes
                details_data = []
                for result in results:
                    details_data.append({
                        'Campo': result.field_name,
                        'Valor CSV': result.csv_value,
                        'Valor Gerado': result.generated_value,
                        'Coincide': 'Sim' if result.is_match else 'N√£o',
                        'Diferen√ßa': result.difference,
                        'Diferen√ßa (%)': result.percentage_diff,
                        'Observa√ß√µes': result.notes
                    })
                
                details_df = pd.DataFrame(details_data)
                details_df.to_excel(writer, sheet_name='Detalhes', index=False)
                
                # Campos com diverg√™ncias
                divergences = [r for r in results if not r.is_match]
                if divergences:
                    divergence_data = []
                    for result in divergences:
                        divergence_data.append({
                            'Campo': result.field_name,
                            'Valor CSV': result.csv_value,
                            'Valor Gerado': result.generated_value,
                            'Diferen√ßa': result.difference,
                            'Diferen√ßa (%)': result.percentage_diff,
                            'Observa√ß√µes': result.notes
                        })
                    
                    divergence_df = pd.DataFrame(divergence_data)
                    divergence_df.to_excel(writer, sheet_name='Diverg√™ncias', index=False)
            
            self.logger.info(f"Relat√≥rio gerado com sucesso: {output_file}")
            
        except Exception as e:
            error_msg = f"Erro ao gerar relat√≥rio: {e}"
            self.logger.error(error_msg)
            raise AuditError(error_msg) 

================================================================================
ARQUIVO 16/24: modules\exporters.py
TAMANHO: 4.45 KB
================================================================================

import os
import pandas as pd
from openpyxl.utils import get_column_letter
from openpyxl.styles import Alignment, PatternFill, Font, Border, Side
from style_config import (
    CONTABEIS_COLS, CURRENCY_FORMATS, DATE_FORMATS, THEMES, 
    DECIMAL_SEPARATORS, COLUMN_WIDTHS, BORDER_STYLES, BORDER_CONFIGS
)


def export_to_excel(
    dataframes_by_month: dict,
    output_dir: str,
    currency: str = 'BRL',
    language: str = 'pt_BR',
    theme: str = 'default',
    decimal_separator: str = None,
    border_theme: str = 'default'
):
    """
    Salva cada DataFrame em planilhas Excel separadas por m√™s,
    ajustando automaticamente a largura das colunas e formatando
    colunas num√©ricas em estilo cont√°bil com duas casas decimais.
    Permite customizar s√≠mbolo, separador decimal, tema de cores e bordas.
    """
    os.makedirs(output_dir, exist_ok=True)

    currency_format = CURRENCY_FORMATS.get(currency, 'R$ #,##0.00')
    date_format = DATE_FORMATS.get(language, 'dd/mm/yyyy')
    theme_cfg = THEMES.get(theme, THEMES['default'])
    border_cfg = BORDER_CONFIGS.get(border_theme, BORDER_CONFIGS['default'])
    decimal_sep = decimal_separator or DECIMAL_SEPARATORS.get(language, ',')

    for month, df in dataframes_by_month.items():
        filepath = os.path.join(output_dir, f"Recebimentos_{month}.xlsx")
        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            sheet_name = month
            df.to_excel(writer, sheet_name=sheet_name, index=False)
            ws = writer.sheets[sheet_name]

            # Estilo de cabe√ßalho
            header_fill = PatternFill(start_color=theme_cfg['header_bg'], end_color=theme_cfg['header_bg'], fill_type='solid')
            header_font = Font(color=theme_cfg['header_font'], bold=True)

            # Configurar bordas
            border_color = border_cfg['border_color']
            header_border_style = BORDER_STYLES.get(border_cfg['header_border'])
            data_border_style = BORDER_STYLES.get(border_cfg['data_border'])

            for idx, col in enumerate(df.columns, start=1):
                # Ajusta largura da coluna usando configura√ß√£o personalizada
                column_width = COLUMN_WIDTHS.get(col, COLUMN_WIDTHS['default'])
                ws.column_dimensions[get_column_letter(idx)].width = column_width

                # Aplica formata√ß√£o cont√°bil para colunas num√©ricas
                if col in CONTABEIS_COLS:
                    for row_idx, cell in enumerate(ws[get_column_letter(idx)][1:], start=2):
                        cell.number_format = currency_format
                        cell.alignment = Alignment(horizontal='left')
                        cell.fill = PatternFill(start_color=theme_cfg['contabil_bg'], end_color=theme_cfg['contabil_bg'], fill_type='solid')
                        cell.font = Font(color=theme_cfg['contabil_font'])
                        
                        # Aplica bordas aos dados
                        if data_border_style:
                            cell.border = Border(
                                left=Side(style=data_border_style, color=border_color),
                                right=Side(style=data_border_style, color=border_color),
                                top=Side(style=data_border_style, color=border_color),
                                bottom=Side(style=data_border_style, color=border_color)
                            )

                # Aplica estilo ao cabe√ßalho
                header_cell = ws[f"{get_column_letter(idx)}1"]
                header_cell.fill = header_fill
                header_cell.font = header_font
                header_cell.alignment = Alignment(horizontal='center')
                
                # Aplica bordas ao cabe√ßalho
                if header_border_style:
                    header_cell.border = Border(
                        left=Side(style=header_border_style, color=border_color),
                        right=Side(style=header_border_style, color=border_color),
                        top=Side(style=header_border_style, color=border_color),
                        bottom=Side(style=header_border_style, color=border_color)
                    )

            # Ajusta separador decimal se necess√°rio (apenas visual, n√£o altera valores)
            # (Excel usa o separador do sistema, mas podemos ajustar o formato se necess√°rio)
            # N√£o implementado aqui pois depende do Excel do usu√°rio


================================================================================
ARQUIVO 17/24: modules\extractors.py
TAMANHO: 9.86 KB
================================================================================

# Arquivo: modules/extractors.py

import pandas as pd
import logging
from typing import List, Dict, Any, Tuple


class ExtractionError(Exception):
    """Exce√ß√£o personalizada para erros de extra√ß√£o de dados"""
    pass


def validate_required_columns(df: pd.DataFrame, table_name: str, expected_columns: List[str]) -> bool:
    """
    Valida se o DataFrame cont√©m todas as colunas esperadas.
    
    Args:
        df: DataFrame a ser validado
        table_name: Nome da tabela para mensagens de erro
        expected_columns: Lista de colunas esperadas
        
    Returns:
        bool: True se todas as colunas estiverem presentes
        
    Raises:
        ExtractionError: Se alguma coluna estiver faltando
    """
    missing_columns = [col for col in expected_columns if col not in df.columns]
    
    if missing_columns:
        error_msg = f"Colunas faltando na tabela {table_name}: {missing_columns}"
        logging.error(error_msg)
        logging.error(f"Colunas encontradas: {list(df.columns)}")
        raise ExtractionError(error_msg)
    
    logging.info(f"‚úÖ Valida√ß√£o de colunas da tabela {table_name} passou")
    return True


def get_ordens(conn) -> pd.DataFrame:
    """
    Extrai dados da tabela ORDEMS usando SQL parametrizado.
    
    Args:
        conn: Conex√£o com banco de dados
        
    Returns:
        pd.DataFrame: Dados extra√≠dos da tabela ORDEMS
        
    Raises:
        ExtractionError: Se houver erro na extra√ß√£o
    """
    try:
        # Define colunas esperadas (usando nomes reais da tabela)
        expected_columns = [
            'CODIGO', 'COD_CLIENTE', 'SAIDA', 'V_MAO', 'V_PECAS', 
            'V_DESLOCA', 'V_TERCEIRO', 'V_OUTROS', 'APARELHO', 'MODELO'
        ]
        
        # Query como string simples para compatibilidade com pyodbc
        query = """
        SELECT
            CODIGO,
            COD_CLIENTE,
            SAIDA,
            V_MAO,
            V_PECAS,
            V_DESLOCA,
            V_TERCEIRO,
            V_OUTROS,
            APARELHO,
            MODELO
        FROM ORDEMS
        """
        
        logging.info("Iniciando extra√ß√£o da tabela ORDEMS...")
        
        # Executa query usando pandas
        df = pd.read_sql(query, conn)
        
        # Valida colunas
        validate_required_columns(df, 'ORDEMS', expected_columns)
        
        # Log detalhado da extra√ß√£o
        logging.info(f"‚úÖ Extra√ß√£o ORDEMS conclu√≠da: {len(df)} registros")
        logging.info(f"   Colunas extra√≠das: {list(df.columns)}")
        
        # Log de estat√≠sticas b√°sicas
        if not df.empty:
            logging.info(f"   Per√≠odo: {df['SAIDA'].min()} a {df['SAIDA'].max()}")
            logging.info(f"   Valor total m√©dio (m√£o de obra): {df['V_MAO'].mean():.2f}")
            logging.info(f"   Valor total m√©dio (pe√ßas): {df['V_PECAS'].mean():.2f}")
        
        return df
        
    except Exception as e:
        error_msg = f"Erro na extra√ß√£o da tabela ORDEMS: {e}"
        logging.error(error_msg)
        raise ExtractionError(error_msg)


def get_contas(conn) -> pd.DataFrame:
    """
    Extrai dados da tabela CONTAS usando SQL parametrizado.
    
    Args:
        conn: Conex√£o com banco de dados
        
    Returns:
        pd.DataFrame: Dados extra√≠dos da tabela CONTAS
        
    Raises:
        ExtractionError: Se houver erro na extra√ß√£o
    """
    try:
        # Define colunas esperadas
        expected_columns = ['CODIGO', 'REFERENCIA', 'VALOR', 'PAGO', 'DATA_PGTO', 'COD_CLIENTE', 'ECF_CARTAO', 'ECF_DINHEIRO', 'ECF_TROCO']
        
        # Query como string simples para compatibilidade com pyodbc
        query = """
        SELECT
            CODIGO,
            REFERENCIA,
            VALOR,
            PAGO,
            DATA_PGTO,
            COD_CLIENTE,
            ECF_CARTAO,
            ECF_DINHEIRO,
            ECF_TROCO
        FROM CONTAS
        """
        
        logging.info("Iniciando extra√ß√£o da tabela CONTAS...")
        
        # Executa query
        df = pd.read_sql(query, conn)
        
        # Valida colunas
        validate_required_columns(df, 'CONTAS', expected_columns)
        
        # Log detalhado da extra√ß√£o
        logging.info(f"‚úÖ Extra√ß√£o CONTAS conclu√≠da: {len(df)} registros")
        logging.info(f"   Colunas extra√≠das: {list(df.columns)}")
        
        # Log de estat√≠sticas b√°sicas
        if not df.empty:
            logging.info(f"   Refer√™ncias √∫nicas: {df['REFERENCIA'].nunique()}")
            logging.info(f"   Registros pagos: {len(df[df['PAGO'] == 'S'])}")
            logging.info(f"   Registros pendentes: {len(df[df['PAGO'] == 'N'])}")
            logging.info(f"   Valor total: {df['VALOR'].sum():.2f}")
        
        return df
        
    except Exception as e:
        error_msg = f"Erro na extra√ß√£o da tabela CONTAS: {e}"
        logging.error(error_msg)
        raise ExtractionError(error_msg)


def get_fcaixa(conn) -> pd.DataFrame:
    """
    Extrai dados da tabela FCAIXA usando SQL parametrizado.
    
    Args:
        conn: Conex√£o com banco de dados
        
    Returns:
        pd.DataFrame: Dados extra√≠dos da tabela FCAIXA
        
    Raises:
        ExtractionError: Se houver erro na extra√ß√£o
    """
    try:
        # Define colunas esperadas
        expected_columns = ['CODIGO', 'DIA', 'RECEITA', 'COD_CONTA', 'FORMA']
        
        # Query como string simples para compatibilidade com pyodbc
        query = """
        SELECT
            CODIGO,
            DIA,
            RECEITA,
            COD_CONTA,
            FORMA
        FROM FCAIXA
        """
        
        logging.info("Iniciando extra√ß√£o da tabela FCAIXA...")
        
        # Executa query
        df = pd.read_sql(query, conn)
        
        # Valida colunas
        validate_required_columns(df, 'FCAIXA', expected_columns)
        
        # Log detalhado da extra√ß√£o
        logging.info(f"‚úÖ Extra√ß√£o FCAIXA conclu√≠da: {len(df)} registros")
        logging.info(f"   Colunas extra√≠das: {list(df.columns)}")
        
        # Log de estat√≠sticas b√°sicas
        if not df.empty:
            logging.info(f"   Per√≠odo: {df['DIA'].min()} a {df['DIA'].max()}")
            logging.info(f"   Receita total: {df['RECEITA'].sum():.2f}")
            
            # Estat√≠sticas por forma de pagamento
            formas_pgto = df['FORMA'].value_counts()
            logging.info(f"   Formas de pagamento: {dict(formas_pgto)}")
        
        return df
        
    except Exception as e:
        error_msg = f"Erro na extra√ß√£o da tabela FCAIXA: {e}"
        logging.error(error_msg)
        raise ExtractionError(error_msg)


def get_extraction_summary(ordens_df: pd.DataFrame, contas_df: pd.DataFrame, fcaixa_df: pd.DataFrame) -> Dict[str, Any]:
    """
    Gera um resumo da extra√ß√£o de dados para auditoria.
    
    Args:
        ordens_df: DataFrame da tabela ORDEMS
        contas_df: DataFrame da tabela CONTAS
        fcaixa_df: DataFrame da tabela FCAIXA
        
    Returns:
        dict: Resumo da extra√ß√£o
    """
    try:
        summary = {
            'timestamp': pd.Timestamp.now(),
            'tables': {
                'ORDEMS': {
                    'records': len(ordens_df),
                    'columns': list(ordens_df.columns),
                    'date_range': {
                        'min': ordens_df['SAIDA'].min() if not ordens_df.empty else None,
                        'max': ordens_df['SAIDA'].max() if not ordens_df.empty else None
                    }
                },
                'CONTAS': {
                    'records': len(contas_df),
                    'columns': list(contas_df.columns),
                    'unique_references': contas_df['REFERENCIA'].nunique() if not contas_df.empty else 0
                },
                'FCAIXA': {
                    'records': len(fcaixa_df),
                    'columns': list(fcaixa_df.columns),
                    'unique_orders': fcaixa_df['CODIGO'].nunique() if not fcaixa_df.empty else 0
                }
            },
            'total_records': len(ordens_df) + len(contas_df) + len(fcaixa_df)
        }
        
        logging.info("üìä RESUMO DA EXTRA√á√ÉO:")
        logging.info(f"   Total de registros: {summary['total_records']}")
        logging.info(f"   ORDEMS: {summary['tables']['ORDEMS']['records']} registros")
        logging.info(f"   CONTAS: {summary['tables']['CONTAS']['records']} registros")
        logging.info(f"   FCAIXA: {summary['tables']['FCAIXA']['records']} registros")
        
        return summary
        
    except Exception as e:
        logging.error(f"Erro ao gerar resumo da extra√ß√£o: {e}")
        return {}


def extract_all_data(conn) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    """
    Extrai dados de todas as tabelas necess√°rias.
    
    Args:
        conn: Conex√£o com banco de dados
        
    Returns:
        tuple: (ordens_df, contas_df, fcaixa_df)
        
    Raises:
        ExtractionError: Se houver erro em qualquer extra√ß√£o
    """
    try:
        logging.info("üöÄ Iniciando extra√ß√£o completa de dados...")
        
        # Extrai dados de todas as tabelas
        ordens_df = get_ordens(conn)
        contas_df = get_contas(conn)
        fcaixa_df = get_fcaixa(conn)
        
        # Gera resumo para auditoria
        summary = get_extraction_summary(ordens_df, contas_df, fcaixa_df)
        
        logging.info("‚úÖ Extra√ß√£o completa conclu√≠da com sucesso!")
        
        return ordens_df, contas_df, fcaixa_df
        
    except Exception as e:
        error_msg = f"Erro na extra√ß√£o completa de dados: {e}"
        logging.error(error_msg)
        raise ExtractionError(error_msg)

================================================================================
ARQUIVO 18/24: modules\processors.py
TAMANHO: 10.73 KB
================================================================================

import pandas as pd
import logging
from typing import Optional, Tuple


def _prepara_ordens(ordens_df: pd.DataFrame) -> pd.DataFrame:
    """
    Prepara e processa dados da tabela ORDEMS.
    
    Args:
        ordens_df: DataFrame da tabela ORDEMS
        
    Returns:
        pd.DataFrame: DataFrame processado com colunas renomeadas
    """
    logging.info("üìã Processando tabela ORDEMS...")
    ordens = ordens_df.copy()
    
    # Calcula VALOR TOTAL conforme especifica√ß√£o
    ordens['VALOR TOTAL'] = ordens[['V_MAO', 'V_PECAS', 'V_DESLOCA', 'V_TERCEIRO', 'V_OUTROS']].sum(axis=1)
    
    # Cria VE√çCULO (PLACA) conforme especifica√ß√£o
    ordens['VE√çCULO (PLACA)'] = ordens['APARELHO'].astype(str) + ' (' + ordens['MODELO'].astype(str) + ')'
    
    # Renomeia colunas conforme especifica√ß√£o
    ordens_proc = ordens.rename(columns={
        'CODIGO': 'N¬∞ OS',
        'SAIDA': 'DATA ENCERRAMENTO',
        'V_MAO': 'VALOR M√ÉO DE OBRA',
        'V_PECAS': 'VALOR PE√áAS',
        'V_OUTROS': 'DESCONTO'
    })[[
        'N¬∞ OS', 'DATA ENCERRAMENTO', 'VALOR TOTAL',
        'VALOR M√ÉO DE OBRA', 'VALOR PE√áAS', 'DESCONTO', 'VE√çCULO (PLACA)'
    ]]
    
    logging.info(f"‚úÖ ORDEMS processada: {len(ordens_proc)} registros")
    return ordens_proc


def _extrai_receitas(fcaixa_df: pd.DataFrame) -> Tuple[pd.Series, pd.Series]:
    """
    Extrai receitas por forma de pagamento da tabela FCAIXA.
    
    Args:
        fcaixa_df: DataFrame da tabela FCAIXA
        
    Returns:
        Tuple[pd.Series, pd.Series]: (pix_receita, dinheiro_receita)
    """
    logging.info("üí∞ Processando tabela FCAIXA...")
    fcaixa = fcaixa_df.copy()
    
    # Extrai c√≥digo num√©rico da coluna COD_CONTA
    fcaixa['COD_CONTA_NUM'] = (
        fcaixa['COD_CONTA']
        .astype(str)
        .str.extract(r'(\d+)', expand=False)
        .fillna('0')
        .astype(int)
    )
    
    # Calcula receitas por forma de pagamento
    pix_receita = fcaixa[fcaixa['FORMA'] == 0].groupby('COD_CONTA_NUM')['RECEITA'].sum()
    dinheiro_receita = fcaixa[fcaixa['FORMA'] == 5].groupby('COD_CONTA_NUM')['RECEITA'].sum()
    
    logging.info(f"‚úÖ FCAIXA processada: {len(fcaixa)} registros")
    logging.info(f"   Receitas PIX (FORMA=0): {len(pix_receita)} registros")
    logging.info(f"   Receitas Dinheiro (FORMA=5): {len(dinheiro_receita)} registros")
    
    return pix_receita, dinheiro_receita


def _valida_referencia_os(referencia: str) -> bool:
    """
    Valida se a refer√™ncia est√° no formato correto para OS.
    
    Args:
        referencia: String da refer√™ncia
        
    Returns:
        bool: True se estiver no formato O\d+
    """
    import re
    return bool(re.match(r'^O\d+$', str(referencia)))


def _processa_contas_pagas(
    contas_df: pd.DataFrame, 
    periodo: Optional[str],
    pix_receita: pd.Series,
    dinheiro_receita: pd.Series
) -> pd.DataFrame:
    """
    Processa contas pagas (PAGO = 'S') e calcula formas de pagamento.
    
    Args:
        contas_df: DataFrame da tabela CONTAS
        periodo: Per√≠odo para filtrar (YYYY-MM)
        pix_receita: Series com receitas PIX
        dinheiro_receita: Series com receitas Dinheiro
        
    Returns:
        pd.DataFrame: DataFrame agregado por OS
    """
    logging.info("üí≥ Processando tabela CONTAS (pagas)...")
    contas_pagas = contas_df.copy()
    
    # Converte CODIGO para num√©rico
    contas_pagas['CODIGO'] = pd.to_numeric(contas_pagas['CODIGO'], errors='coerce').fillna(0).astype(int)
    
    # Valida e extrai n√∫mero da OS da refer√™ncia
    contas_pagas['REFERENCIA_VALIDA'] = contas_pagas['REFERENCIA'].apply(_valida_referencia_os)
    contas_pagas['OS'] = contas_pagas['REFERENCIA'].astype(str).str.extract(r'^O(\d+)$', expand=False)
    
    # Log de refer√™ncias inv√°lidas
    refs_invalidas = contas_pagas[~contas_pagas['REFERENCIA_VALIDA']]['REFERENCIA'].unique()
    if len(refs_invalidas) > 0:
        logging.warning(f"   Refer√™ncias inv√°lidas encontradas: {refs_invalidas[:10]}...")
    
    contas_pagas = contas_pagas.dropna(subset=['OS']).copy()
    contas_pagas['OS'] = contas_pagas['OS'].astype(int)
    
    # Filtra apenas contas pagas (PAGO = 'S')
    contas_pagas = contas_pagas[contas_pagas['PAGO'] == 'S'].copy()
    
    # Filtra por DATA_PGTO do per√≠odo especificado
    if periodo:
        contas_pagas['DATA_PGTO'] = pd.to_datetime(contas_pagas['DATA_PGTO'], errors='coerce')
        contas_pagas['MES_PGTO'] = contas_pagas['DATA_PGTO'].dt.strftime('%Y-%m')
        contas_pagas = contas_pagas[contas_pagas['MES_PGTO'] == periodo].copy()
        contas_pagas = contas_pagas.drop(columns=['MES_PGTO'])
        logging.info(f"   Filtrado para per√≠odo: {periodo}")
    
    # Merge com receitas do FCAIXA para c√°lculos de DINHEIRO e PIX
    contas_pagas = contas_pagas.merge(
        pix_receita.rename('RECEITA_PIX'),
        left_on='CODIGO', right_index=True, how='left'
    )
    contas_pagas = contas_pagas.merge(
        dinheiro_receita.rename('RECEITA_DINHEIRO'),
        left_on='CODIGO', right_index=True, how='left'
    )
    contas_pagas = contas_pagas.fillna(0)
    
    # Calcula DINHEIRO e PIX conforme especifica√ß√£o CORRETA
    # DINHEIRO = ECF_DINHEIRO - RECEITA (FORMA = 5)
    # PIX = ECF_DINHEIRO - RECEITA (FORMA = 0)
    contas_pagas['DINHEIRO'] = contas_pagas['ECF_DINHEIRO'] - contas_pagas['RECEITA_DINHEIRO']
    contas_pagas['PIX'] = contas_pagas['ECF_DINHEIRO'] - contas_pagas['RECEITA_PIX']
    
    # Garante que DATA_PGTO seja datetime e agrega por OS
    contas_pagas['DATA_PGTO'] = pd.to_datetime(contas_pagas['DATA_PGTO'], errors='coerce')
    agg_pagas = contas_pagas.groupby('OS').agg({
        'COD_CLIENTE': 'first',
        'VALOR': 'sum',
        'ECF_CARTAO': 'sum',
        'DINHEIRO': 'sum',
        'PIX': 'sum',
        'ECF_TROCO': 'sum',
        'DATA_PGTO': 'max'
    }).rename(columns={
        'COD_CLIENTE': 'C√ìDIGO CLIENTE',
        'VALOR': 'VALOR PAGO',
        'ECF_CARTAO': 'CART√ÉO',
        'ECF_TROCO': 'TROCO',
        'DATA_PGTO': 'DATA PGTO'
    })
    
    logging.info(f"‚úÖ CONTAS (pagas) processada: {len(agg_pagas)} registros")
    return agg_pagas


def _processa_contas_devidas(contas_df: pd.DataFrame) -> pd.Series:
    """
    Processa contas devidas (PAGO = 'N') para c√°lculo do DEVEDOR.
    
    Args:
        contas_df: DataFrame da tabela CONTAS
        
    Returns:
        pd.Series: Series com valores devidos por OS
    """
    logging.info("üí∏ Processando tabela CONTAS (devidas)...")
    contas_devidas = contas_df.copy()
    
    # Converte CODIGO para num√©rico
    contas_devidas['CODIGO'] = pd.to_numeric(contas_devidas['CODIGO'], errors='coerce').fillna(0).astype(int)
    
    # Valida e extrai n√∫mero da OS da refer√™ncia
    contas_devidas['REFERENCIA_VALIDA'] = contas_devidas['REFERENCIA'].apply(_valida_referencia_os)
    contas_devidas['OS'] = contas_devidas['REFERENCIA'].astype(str).str.extract(r'^O(\d+)$', expand=False)
    contas_devidas = contas_devidas.dropna(subset=['OS']).copy()
    contas_devidas['OS'] = contas_devidas['OS'].astype(int)
    
    # Filtra apenas contas devidas (PAGO = 'N')
    contas_devidas = contas_devidas[contas_devidas['PAGO'] == 'N'].copy()
    
    # Agrega DEVEDOR por OS
    agg_devidas = contas_devidas.groupby('OS')['VALOR'].sum().rename('DEVEDOR')
    
    logging.info(f"‚úÖ CONTAS (devidas) processada: {len(agg_devidas)} registros")
    return agg_devidas


def process_recebimentos(
    ordens_df: pd.DataFrame,
    contas_df: pd.DataFrame,
    fcaixa_df: pd.DataFrame,
    periodo: Optional[str] = None
) -> pd.DataFrame:
    """
    Monta a tabela consolidada de recebimentos conforme especifica√ß√µes:
    
    Mapeamento:
    - N¬∞ OS = CODIGO da tabela ORDEMS
    - DATA ENCERRAMENTO = SAIDA da tabela ORDEMS
    - VALOR TOTAL = soma de (V_MAO, V_PECAS, V_DESLOCA, V_TERCEIRO, V_OUTROS) da tabela ORDEMS
    - VALOR M√ÉO DE OBRA = V_MAO da tabela ORDEMS
    - VALOR PE√áAS = V_PECAS da tabela ORDEMS
    - DESCONTO = V_OUTROS da tabela ORDEMS
    - VE√çCULO (PLACA) = "APARELHO + (MODELO)" da tabela ORDEMS
    - C√ìDIGO CLIENTE = COD_CLIENTE da tabela CONTAS
    - VALOR PAGO = soma de todos os valores em VALOR respectivos a ordem de servi√ßo
    - CART√ÉO = ECF_CARTAO
    - DINHEIRO = ECF_DINHEIRO - RECEITA (se a RECEITA respectiva tiver FORMA = 5)
    - PIX = ECF_DINHEIRO - RECEITA (se a RECEITA respectiva tiver FORMA = 0)
    - TROCO = ECF_TROCO da tabela CONTAS
    
    Args:
        ordens_df: DataFrame da tabela ORDEMS
        contas_df: DataFrame da tabela CONTAS
        fcaixa_df: DataFrame da tabela FCAIXA
        periodo: Formato 'YYYY-MM' para filtrar DATA_PGTO (ex: '2024-01')
        
    Returns:
        pd.DataFrame: Tabela consolidada de recebimentos
    """
    try:
        logging.info("üîÑ Iniciando processamento de recebimentos...")
        
        # Prepara ordens
        ordens_proc = _prepara_ordens(ordens_df)
        
        # Extrai receitas
        pix_receita, dinheiro_receita = _extrai_receitas(fcaixa_df)
        
        # Processa contas pagas
        agg_pagas = _processa_contas_pagas(contas_df, periodo, pix_receita, dinheiro_receita)
        
        # Processa contas devidas
        agg_devidas = _processa_contas_devidas(contas_df)
        
        # Merge final com as ordens
        logging.info("üîó Fazendo merge final...")
        final = ordens_proc.merge(agg_pagas, left_on='N¬∞ OS', right_index=True, how='left')
        final = final.merge(agg_devidas, left_on='N¬∞ OS', right_index=True, how='left')
        
        # Preenche valores nulos com 0
        final['DEVEDOR'] = final['DEVEDOR'].fillna(0)
        final['VALOR PAGO'] = final['VALOR PAGO'].fillna(0)
        final['CART√ÉO'] = final['CART√ÉO'].fillna(0)
        final['DINHEIRO'] = final['DINHEIRO'].fillna(0)
        final['PIX'] = final['PIX'].fillna(0)
        final['TROCO'] = final['TROCO'].fillna(0)
        
        # Reordena colunas conforme especifica√ß√£o
        colunas_finais = [
            'N¬∞ OS', 'DATA ENCERRAMENTO', 'VALOR TOTAL', 'VALOR M√ÉO DE OBRA',
            'VALOR PE√áAS', 'DESCONTO', 'VE√çCULO (PLACA)', 'C√ìDIGO CLIENTE',
            'VALOR PAGO', 'DEVEDOR', 'CART√ÉO', 'DINHEIRO', 'PIX', 'TROCO', 'DATA PGTO'
        ]
        
        final = final[colunas_finais]
        
        logging.info(f"‚úÖ Processamento conclu√≠do: {len(final)} registros finais")
        logging.info(f"   Colunas finais: {list(final.columns)}")
        
        return final
        
    except Exception as e:
        error_msg = f"Erro no processamento de recebimentos: {e}"
        logging.error(error_msg)
        raise Exception(error_msg)


================================================================================
ARQUIVO 19/24: requirements.txt
TAMANHO: 0.05 KB
================================================================================

pyodbc
pandas
python-dotenv
openpyxl
sqlalchemy

================================================================================
ARQUIVO 20/24: style_config.py
TAMANHO: 3.32 KB
================================================================================

# Arquivo: style_config.py

# Colunas cont√°beis (valores financeiros)
CONTABEIS_COLS = [
    "VALOR TOTAL", "VALOR M√ÉO DE OBRA", "VALOR PE√áAS",
    "DESCONTO", "VALOR PAGO", "DEVEDOR", "CART√ÉO", "DINHEIRO",
    "PIX", "TROCO"
]

# Formatos de moeda e data
CURRENCY_FORMATS = {
    'BRL': 'R$ #,##0.00',
    'USD': 'US$ #,##0.00',
    'EUR': '‚Ç¨ #,##0.00',
}

DATE_FORMATS = {
    'pt_BR': 'dd/mm/yyyy',
    'en_US': 'mm/dd/yyyy',
    'iso': 'yyyy-mm-dd',
}

# Configura√ß√µes de largura das colunas - Expandido para auditoria unificada
COLUMN_WIDTHS = {
    # Colunas originais
    'N¬∞ OS': 12,
    'DATA ENCERRAMENTO': 18,
    'VALOR TOTAL': 15,
    'VALOR M√ÉO DE OBRA': 18,
    'VALOR PE√áAS': 15,
    'DESCONTO': 12,
    'VE√çCULO (PLACA)': 25,
    'C√ìDIGO CLIENTE': 15,
    'VALOR PAGO': 15,
    'DEVEDOR': 12,
    'CART√ÉO': 12,
    'DINHEIRO': 12,
    'PIX': 12,
    'TROCO': 12,
    'DATA PGTO': 15,
    
    # Colunas da auditoria de cart√£o
    'identificador': 25,
    'data_cartao': 15,
    'tipo_pagamento': 15,
    'valor_cartao': 15,
    'valor_gerado': 15,
    'diferenca': 15,
    'dif_percentual': 15,
    'status': 20,
    'os_correspondente': 15,
    'observacao': 50,
    
    # Colunas da auditoria PIX
    'data_banco': 15,
    'valor_banco': 15,
    'descricao_banco': 60,
    'data_recebimentos': 15,
    'valor_recebimentos': 15,
    'os_recebimentos': 15,
    
    # Novas colunas da auditoria PIX com agrupamento
    'remetente_banco': 30,
    'qtd_transacoes_banco': 20,
    'detalhes_banco': 80,
    'qtd_transacoes_recebimentos': 25,
    'detalhes_recebimentos': 80,
    'tipo_agrupamento': 20,
    'status_correspondencia': 25,
    
    # Colunas do resumo
    'M√©trica': 35,
    'Valor': 20,
    'Mensagem': 50,
    
    # Larguras espec√≠ficas para melhor legibilidade
    'descricao': 60,
    'origem': 15,
    'referencia': 20,
    'match_type': 15,
    'confidence': 15,
    'notes': 50,
    
    'default': 20,  # Largura padr√£o aumentada para colunas n√£o especificadas
}

# Configura√ß√µes de bordas
BORDER_STYLES = {
    'none': None,
    'thin': 'thin',
    'medium': 'medium',
    'thick': 'thick',
    'dashed': 'dashed',
    'dotted': 'dotted',
}

# Configura√ß√µes de bordas por tema
BORDER_CONFIGS = {
    'default': {
        'header_border': 'thin',
        'data_border': 'thin',
        'border_color': '000000',  # Preto
    },
    'dark': {
        'header_border': 'medium',
        'data_border': 'thin',
        'border_color': 'FFFFFF',  # Branco
    },
    'corporate': {
        'header_border': 'thick',
        'data_border': 'thin',
        'border_color': '1F4E78',  # Azul escuro
    },
    'minimal': {
        'header_border': 'thin',
        'data_border': 'none',
        'border_color': 'CCCCCC',  # Cinza claro
    },
}

# Temas de cores (exemplo)
THEMES = {
    'default': {
        'header_bg': 'D9E1F2',
        'header_font': '000000',
        'contabil_bg': 'F2F2F2',
        'contabil_font': '1F4E78',
    },
    'dark': {
        'header_bg': '222222',
        'header_font': 'FFFFFF',
        'contabil_bg': '333333',
        'contabil_font': '00FF00',
    }
}

# Separadores decimais por idioma
DECIMAL_SEPARATORS = {
    'pt_BR': ',',
    'en_US': '.',
    'es_ES': ',',
} 

================================================================================
ARQUIVO 21/24: teste_valor.py
TAMANHO: 1.76 KB
================================================================================

import pdfplumber
import re

def testar_extracao_valor():
    """Testa a extra√ß√£o de valor de um PDF espec√≠fico"""
    
    # Abre um PDF de exemplo
    pdf_path = "data/06-JUN/2025-146.pdf"
    
    try:
        with pdfplumber.open(pdf_path) as pdf:
            texto = ""
            for page in pdf.pages:
                texto += page.extract_text() + "\n"
        
        print("=== TEXTO EXTRA√çDO DO PDF ===")
        print(texto[:1000])  # Primeiros 1000 caracteres
        print("\n" + "="*50)
        
        # Testa diferentes padr√µes para valor total
        padroes_valor = [
            r'Valor dos servi√ßos:?\s*R?\$?\s*([\d\.]+,[\d]{2})',
            r'Valor L√≠quido:?\s*R?\$?\s*([\d\.]+,[\d]{2})',
            r'Valor Total dos Servi√ßos[\s\-:]*R?\$?\s*([\d\.]+,[\d]{2})',
            r'Valor Total[\s\-:]*R?\$?\s*([\d\.]+,[\d]{2})',
            r'Total[\s\-:]*R?\$?\s*([\d\.]+,[\d]{2})',
            r'R?\$?\s*([\d\.]+,[\d]{2})',
            r'([\d\.]+,[\d]{2})',  # Qualquer valor com v√≠rgula
        ]
        
        print("=== TESTANDO PADR√ïES DE VALOR ===")
        for i, padrao in enumerate(padroes_valor):
            matches = re.findall(padrao, texto, re.IGNORECASE | re.MULTILINE)
            print(f"Padr√£o {i+1}: {padrao}")
            print(f"  Encontrados: {matches}")
            print()
        
        # Procura por linhas que contenham "valor" ou "total"
        print("=== LINHAS COM 'VALOR' OU 'TOTAL' ===")
        linhas = texto.split('\n')
        for linha in linhas:
            if 'valor' in linha.lower() or 'total' in linha.lower():
                print(f"Linha: {linha}")
        
    except Exception as e:
        print(f"Erro: {e}")

if __name__ == "__main__":
    testar_extracao_valor() 

================================================================================
ARQUIVO 22/24: tests\test_audit_cartao.py
TAMANHO: 9.30 KB
================================================================================

#!/usr/bin/env python3
"""
Testes automatizados para auditoria de transa√ß√µes de cart√£o
"""

import pytest
import pandas as pd
import tempfile
import os
from datetime import datetime, date
from unittest.mock import patch, MagicMock

# Importa as fun√ß√µes do script de auditoria
import sys
sys.path.append('..')
from audit_cartao import parse_cartao_csv, create_audit_mappings, audit_cartao_transactions, generate_cartao_report


class TestAuditCartao:
    """Testes para auditoria de cart√£o"""
    
    def setup_method(self):
        """Configura√ß√£o para cada teste"""
        self.sample_csv_data = '''Data e hora,Meio - Meio,Meio - Bandeira,Meio - Parcelas,Tipo - Origem,Tipo - Dados adicionais,Identificador,Status,Valor (R$),L√≠quido (R$),Taxa Aplicada - Valor(R$),Taxa Aplicada - Aplicada(%),Plano
"27 Jun, 2025 ¬∑ 18:38",Credito,visa,6,Maquininha,NS: PB58221N79820,039898,Aprovada,"2.487,17","2.329,98","- 157,19",6.32,1 Dia Util
"27 Jun, 2025 ¬∑ 17:28",Credito,visa,A Vista,Maquininha,NS: PB58221N79820,037844,Aprovada,"200,00","194,42","- 5,58",2.79,1 Dia Util
"26 Jun, 2025 ¬∑ 09:34",Debito,visa,A Vista,Maquininha,NS: PB58221N79820,202988,Aprovada,"2.001,80","1.985,99","- 15,81",0.78,1 Dia Util
"25 Jun, 2025 ¬∑ 11:35",PIX,visa,A Vista,Maquininha,NS: PB58221N79820,227355,Aprovada,"323,75","314,72","- 9,03",2.78,1 Dia Util'''
        
        self.sample_generated_data = pd.DataFrame({
            'DATA PGTO': [date(2025, 6, 27), date(2025, 6, 26), date(2025, 6, 25)],
            'CART√ÉO': [2487.17, 2001.80, 0],
            'PIX': [0, 0, 323.75],
            'OUTROS': [0, 0, 0]
        })
    
    def test_parse_cartao_csv(self):
        """Testa o parsing do CSV de cart√£o"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8') as f:
            f.write(self.sample_csv_data)
            csv_path = f.name
        
        try:
            df = parse_cartao_csv(csv_path)
            
            # Verifica se o DataFrame foi criado corretamente
            assert len(df) == 4
            assert 'DATA_PGTO' in df.columns
            assert 'TIPO_PAGAMENTO' in df.columns
            assert 'VALOR_AUDITORIA' in df.columns
            
            # Verifica tipos de pagamento
            tipos = df['TIPO_PAGAMENTO'].value_counts()
            assert tipos['CART√ÉO'] == 3  # 2 Credito + 1 Debito
            assert tipos['PIX'] == 1
            
            # Verifica valores
            assert df.loc[0, 'VALOR_AUDITORIA'] == 2487.17
            assert df.loc[1, 'VALOR_AUDITORIA'] == 200.00
            
            # Verifica datas
            assert df.loc[0, 'DATA_PGTO'] == date(2025, 6, 27)
            assert df.loc[2, 'DATA_PGTO'] == date(2025, 6, 26)
            
        finally:
            os.unlink(csv_path)
    
    def test_create_audit_mappings(self):
        """Testa a cria√ß√£o de mapeamentos de auditoria"""
        # Cria DataFrame de teste
        df = pd.DataFrame({
            'Identificador': ['039898', '037844', '202988', '227355'],
            'TIPO_PAGAMENTO': ['CART√ÉO', 'CART√ÉO', 'CART√ÉO', 'PIX'],
            'VALOR_AUDITORIA': [2487.17, 200.00, 2001.80, 323.75],
            'DATA_PGTO': [date(2025, 6, 27), date(2025, 6, 27), date(2025, 6, 26), date(2025, 6, 25)]
        })
        
        mappings = create_audit_mappings(df)
        
        # Verifica se os mapeamentos foram criados corretamente
        assert len(mappings) == 4
        
        # Verifica mapeamento de cart√£o
        assert mappings['039898']['generated_field'] == 'CART√ÉO'
        assert mappings['039898']['tipo'] == 'CART√ÉO'
        assert mappings['039898']['valor'] == 2487.17
        
        # Verifica mapeamento de PIX
        assert mappings['227355']['generated_field'] == 'PIX'
        assert mappings['227355']['tipo'] == 'PIX'
        assert mappings['227355']['valor'] == 323.75
    
    @patch('audit_cartao.DataAuditor')
    def test_audit_cartao_transactions_success(self, mock_auditor):
        """Testa auditoria bem-sucedida"""
        # Configura mock
        mock_auditor_instance = MagicMock()
        mock_auditor.return_value = mock_auditor_instance
        mock_auditor_instance.load_generated_data.return_value = self.sample_generated_data
        mock_auditor_instance.normalize_column_names.return_value = self.sample_generated_data
        
        # Cria arquivos tempor√°rios
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8') as csv_f:
            csv_f.write(self.sample_csv_data)
            csv_path = csv_f.name
        
        with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as excel_f:
            excel_path = excel_f.name
        
        with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as report_f:
            report_path = report_f.name
        
        try:
            # Executa auditoria
            audit_cartao_transactions(csv_path, excel_path, report_path)
            
            # Verifica se o relat√≥rio foi gerado
            assert os.path.exists(report_path)
            
        finally:
            # Limpa arquivos tempor√°rios
            for path in [csv_path, excel_path, report_path]:
                if os.path.exists(path):
                    os.unlink(path)
    
    def test_generate_cartao_report(self):
        """Testa gera√ß√£o de relat√≥rio Excel"""
        # Dados de teste
        results = [
            {
                'identificador': '039898',
                'data_cartao': date(2025, 6, 27),
                'valor_cartao': 2487.17,
                'tipo_pagamento': 'CART√ÉO',
                'status': 'COINCIDENTE',
                'valor_gerado': 2487.17,
                'diferenca': 0.0,
                'observacao': 'Encontrado na coluna CART√ÉO'
            },
            {
                'identificador': '037844',
                'data_cartao': date(2025, 6, 27),
                'valor_cartao': 200.00,
                'tipo_pagamento': 'CART√ÉO',
                'status': 'N√ÉO ENCONTRADA',
                'valor_gerado': None,
                'diferenca': None,
                'observacao': 'Data 2025-06-27 n√£o encontrada nos dados gerados'
            }
        ]
        
        summary_stats = {
            'total_transacoes': 2,
            'cartao_encontradas': 1,
            'pix_encontradas': 0,
            'nao_encontradas': 1,
            'valores_coincidentes': 1,
            'valores_divergentes': 0
        }
        
        # Gera relat√≥rio
        with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as f:
            report_path = f.name
        
        try:
            generate_cartao_report(results, summary_stats, report_path)
            
            # Verifica se o arquivo foi criado
            assert os.path.exists(report_path)
            assert os.path.getsize(report_path) > 0
            
            # Verifica se as abas foram criadas
            with pd.ExcelFile(report_path) as xl:
                assert 'Resumo' in xl.sheet_names
                assert 'Detalhes' in xl.sheet_names
                assert 'Diverg√™ncias' in xl.sheet_names
                
                # Verifica dados do resumo
                resumo_df = pd.read_excel(report_path, sheet_name='Resumo')
                assert len(resumo_df) == 8  # 8 m√©tricas
                assert resumo_df.iloc[0]['Valor'] == 2  # Total de transa√ß√µes
                
                # Verifica dados dos detalhes
                detalhes_df = pd.read_excel(report_path, sheet_name='Detalhes')
                assert len(detalhes_df) == 2  # 2 resultados
                
                # Verifica dados das diverg√™ncias
                divergencias_df = pd.read_excel(report_path, sheet_name='Diverg√™ncias')
                assert len(divergencias_df) == 1  # 1 diverg√™ncia
                
        finally:
            if os.path.exists(report_path):
                os.unlink(report_path)
    
    def test_parse_cartao_csv_invalid_format(self):
        """Testa parsing de CSV com formato inv√°lido"""
        invalid_csv_data = '''Data e hora,Meio - Meio,Identificador,Valor (R$)
"data invalida",Credito,039898,"valor invalido"'''
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8') as f:
            f.write(invalid_csv_data)
            csv_path = f.name
        
        try:
            with pytest.raises(Exception):
                parse_cartao_csv(csv_path)
        finally:
            os.unlink(csv_path)
    
    @patch('audit_cartao.DataAuditor')
    def test_audit_cartao_transactions_missing_files(self, mock_auditor):
        """Testa auditoria com arquivos ausentes"""
        # Testa com CSV ausente
        audit_cartao_transactions('arquivo_inexistente.csv', 'arquivo_inexistente.xlsx')
        
        # Testa com Excel ausente
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8') as f:
            f.write(self.sample_csv_data)
            csv_path = f.name
        
        try:
            audit_cartao_transactions(csv_path, 'arquivo_inexistente.xlsx')
        finally:
            os.unlink(csv_path)


if __name__ == '__main__':
    pytest.main([__file__]) 

================================================================================
ARQUIVO 23/24: tests\test_auditor.py
TAMANHO: 12.66 KB
================================================================================

import pytest
import pandas as pd
import os
import tempfile
from datetime import datetime
from modules.auditor import DataAuditor, AuditError, AuditResult, AuditSummary


class TestDataAuditor:
    """Testes para o m√≥dulo de auditoria"""
    
    @pytest.fixture
    def sample_csv_data(self):
        """Dados CSV de exemplo para testes"""
        return pd.DataFrame({
            'numero_os': ['001', '002', '003'],
            'data_pagamento': ['2024-01-15', '2024-01-16', '2024-01-17'],
            'valor_total': [1000.50, 2500.75, 1500.00],
            'valor_pago': [1000.50, 2400.75, 1500.00],
            'valor_devedor': [0.00, 100.00, 0.00],
            'cartao': [500.25, 1200.00, 750.00],
            'dinheiro': [300.25, 800.75, 500.00],
            'pix': [200.00, 400.00, 250.00],
            'troco': [0.00, 0.00, 0.00],
            'placa_veiculo': ['ABC1234', 'XYZ5678', 'DEF9012'],
            'codigo_cliente': ['CLI001', 'CLI002', 'CLI003'],
            'data_encerramento': ['2024-01-15', '2024-01-16', '2024-01-17']
        })
    
    @pytest.fixture
    def sample_generated_data(self):
        """Dados gerados de exemplo para testes"""
        return pd.DataFrame({
            'N¬∞ OS': ['001', '002', '003'],
            'DATA PGTO': ['2024-01-15', '2024-01-16', '2024-01-17'],
            'VALOR TOTAL': [1000.50, 2500.75, 1500.00],
            'VALOR PAGO': [1000.50, 2400.75, 1500.00],
            'DEVEDOR': [0.00, 100.00, 0.00],
            'CART√ÉO': [500.25, 1200.00, 750.00],
            'DINHEIRO': [300.25, 800.75, 500.00],
            'PIX': [200.00, 400.00, 250.00],
            'TROCO': [0.00, 0.00, 0.00],
            'VE√çCULO (PLACA)': ['ABC1234', 'XYZ5678', 'DEF9012'],
            'C√ìDIGO CLIENTE': ['CLI001', 'CLI002', 'CLI003'],
            'DATA ENCERRAMENTO': ['2024-01-15', '2024-01-16', '2024-01-17']
        })
    
    @pytest.fixture
    def temp_dir(self):
        """Diret√≥rio tempor√°rio para testes"""
        with tempfile.TemporaryDirectory() as temp_dir:
            yield temp_dir
    
    def test_auditor_initialization(self):
        """Testa inicializa√ß√£o do auditor"""
        auditor = DataAuditor(tolerance_percentage=0.01)
        assert auditor.tolerance_percentage == 0.01
        
        auditor = DataAuditor(tolerance_percentage=0.05)
        assert auditor.tolerance_percentage == 0.05
    
    def test_load_csv_data(self, sample_csv_data, temp_dir):
        """Testa carregamento de dados CSV"""
        csv_file = os.path.join(temp_dir, "test.csv")
        sample_csv_data.to_csv(csv_file, index=False)
        
        auditor = DataAuditor()
        df = auditor.load_csv_data(csv_file)
        
        assert len(df) == 3
        assert list(df.columns) == list(sample_csv_data.columns)
    
    def test_load_generated_data(self, sample_generated_data, temp_dir):
        """Testa carregamento de dados Excel"""
        excel_file = os.path.join(temp_dir, "test.xlsx")
        sample_generated_data.to_excel(excel_file, index=False)
        
        auditor = DataAuditor()
        df = auditor.load_generated_data(excel_file)
        
        assert len(df) == 3
        assert 'N¬∞ OS' in df.columns
    
    def test_normalize_column_names(self):
        """Testa normaliza√ß√£o de nomes de colunas"""
        df = pd.DataFrame({
            'N_OS': [1, 2],
            'VALOR_TOTAL': [100, 200],
            'DATA_PGTO': ['2024-01-01', '2024-01-02']
        })
        
        auditor = DataAuditor()
        normalized_df = auditor.normalize_column_names(df)
        
        # Verifica se algumas normaliza√ß√µes foram aplicadas
        assert 'N¬∞ OS' in normalized_df.columns or 'N_OS' in normalized_df.columns
    
    def test_compare_numeric_values(self):
        """Testa compara√ß√£o de valores num√©ricos"""
        auditor = DataAuditor(tolerance_percentage=0.01)
        
        # Valores iguais
        result = auditor.compare_numeric_values(100.0, 100.0, 'VALOR')
        assert result.is_match is True
        assert result.difference == 0.0
        
        # Valores dentro da toler√¢ncia
        result = auditor.compare_numeric_values(100.0, 100.5, 'VALOR')
        assert result.is_match is True  # 0.5% de diferen√ßa < 1% toler√¢ncia
        
        # Valores fora da toler√¢ncia
        result = auditor.compare_numeric_values(100.0, 102.0, 'VALOR')
        assert result.is_match is False  # 2% de diferen√ßa > 1% toler√¢ncia
    
    def test_compare_text_values(self):
        """Testa compara√ß√£o de valores de texto"""
        auditor = DataAuditor()
        
        # Valores iguais
        result = auditor.compare_text_values("ABC123", "ABC123", 'PLACA')
        assert result.is_match is True
        
        # Valores diferentes
        result = auditor.compare_text_values("ABC123", "XYZ789", 'PLACA')
        assert result.is_match is False
        
        # Case insensitive
        result = auditor.compare_text_values("abc123", "ABC123", 'PLACA')
        assert result.is_match is True
    
    def test_compare_date_values(self):
        """Testa compara√ß√£o de valores de data"""
        auditor = DataAuditor()
        
        # Datas iguais
        result = auditor.compare_date_values('2024-01-15', '2024-01-15', 'DATA')
        assert result.is_match is True
        
        # Datas diferentes
        result = auditor.compare_date_values('2024-01-15', '2024-01-16', 'DATA')
        assert result.is_match is False
    
    def test_audit_record(self, sample_csv_data, sample_generated_data):
        """Testa auditoria de um registro individual"""
        auditor = DataAuditor()
        
        csv_row = sample_csv_data.iloc[0]
        generated_row = sample_generated_data.iloc[0]
        
        field_mappings = {
            'numero_os': 'N¬∞ OS',
            'valor_total': 'VALOR TOTAL',
            'valor_pago': 'VALOR PAGO'
        }
        
        results = auditor.audit_record(csv_row, generated_row, field_mappings)
        
        assert len(results) == 3
        assert all(result.is_match for result in results)
    
    def test_audit_data_perfect_match(self, sample_csv_data, sample_generated_data, temp_dir):
        """Testa auditoria com dados perfeitamente coincidentes"""
        csv_file = os.path.join(temp_dir, "test.csv")
        excel_file = os.path.join(temp_dir, "test.xlsx")
        
        sample_csv_data.to_csv(csv_file, index=False)
        sample_generated_data.to_excel(excel_file, index=False)
        
        auditor = DataAuditor()
        field_mappings = {
            'numero_os': 'N¬∞ OS',
            'valor_total': 'VALOR TOTAL',
            'valor_pago': 'VALOR PAGO'
        }
        
        summary, results = auditor.audit_data(
            csv_file_path=csv_file,
            generated_file_path=excel_file,
            field_mappings=field_mappings,
            key_field='numero_os'
        )
        
        assert summary.total_records == 3
        assert summary.matching_records == 3
        assert summary.mismatched_records == 0
        assert summary.total_fields_checked == 9  # 3 registros √ó 3 campos
        assert summary.matching_fields == 9
        assert summary.mismatched_fields == 0
    
    def test_audit_data_with_differences(self, sample_csv_data, sample_generated_data, temp_dir):
        """Testa auditoria com diferen√ßas nos dados"""
        # Modifica alguns valores para criar diferen√ßas
        sample_csv_data.loc[0, 'valor_total'] = 1001.00  # Diferen√ßa pequena
        sample_csv_data.loc[1, 'valor_pago'] = 2401.00   # Diferen√ßa maior
        
        csv_file = os.path.join(temp_dir, "test.csv")
        excel_file = os.path.join(temp_dir, "test.xlsx")
        
        sample_csv_data.to_csv(csv_file, index=False)
        sample_generated_data.to_excel(excel_file, index=False)
        
        auditor = DataAuditor(tolerance_percentage=0.01)
        field_mappings = {
            'numero_os': 'N¬∞ OS',
            'valor_total': 'VALOR TOTAL',
            'valor_pago': 'VALOR PAGO'
        }
        
        summary, results = auditor.audit_data(
            csv_file_path=csv_file,
            generated_file_path=excel_file,
            field_mappings=field_mappings,
            key_field='numero_os'
        )
        
        # Deve encontrar algumas diferen√ßas
        assert summary.mismatched_fields > 0
        assert summary.matching_fields < summary.total_fields_checked
    
    def test_audit_data_missing_records(self, sample_csv_data, sample_generated_data, temp_dir):
        """Testa auditoria com registros faltando"""
        # Remove um registro do CSV
        sample_csv_data = sample_csv_data.iloc[:2]
        
        csv_file = os.path.join(temp_dir, "test.csv")
        excel_file = os.path.join(temp_dir, "test.xlsx")
        
        sample_csv_data.to_csv(csv_file, index=False)
        sample_generated_data.to_excel(excel_file, index=False)
        
        auditor = DataAuditor()
        field_mappings = {
            'numero_os': 'N¬∞ OS',
            'valor_total': 'VALOR TOTAL'
        }
        
        summary, results = auditor.audit_data(
            csv_file_path=csv_file,
            generated_file_path=excel_file,
            field_mappings=field_mappings,
            key_field='numero_os'
        )
        
        assert summary.total_records == 2
        assert summary.matching_records == 2
        assert summary.mismatched_records == 0
    
    def test_generate_audit_report(self, sample_csv_data, sample_generated_data, temp_dir):
        """Testa gera√ß√£o de relat√≥rio de auditoria"""
        csv_file = os.path.join(temp_dir, "test.csv")
        excel_file = os.path.join(temp_dir, "test.xlsx")
        report_file = os.path.join(temp_dir, "report.xlsx")
        
        sample_csv_data.to_csv(csv_file, index=False)
        sample_generated_data.to_excel(excel_file, index=False)
        
        auditor = DataAuditor()
        field_mappings = {
            'numero_os': 'N¬∞ OS',
            'valor_total': 'VALOR TOTAL'
        }
        
        summary, results = auditor.audit_data(
            csv_file_path=csv_file,
            generated_file_path=excel_file,
            field_mappings=field_mappings,
            key_field='numero_os'
        )
        
        auditor.generate_audit_report(summary, results, report_file)
        
        # Verifica se o relat√≥rio foi criado
        assert os.path.exists(report_file)
        
        # Verifica se o relat√≥rio tem as planilhas esperadas
        report_df = pd.ExcelFile(report_file)
        assert 'Resumo' in report_df.sheet_names
        assert 'Detalhes' in report_df.sheet_names
    
    def test_audit_error_handling(self, temp_dir):
        """Testa tratamento de erros"""
        auditor = DataAuditor()
        
        # Arquivo CSV inexistente
        with pytest.raises(AuditError):
            auditor.load_csv_data("arquivo_inexistente.csv")
        
        # Arquivo Excel inexistente
        with pytest.raises(AuditError):
            auditor.load_generated_data("arquivo_inexistente.xlsx")
    
    def test_different_tolerance_levels(self):
        """Testa diferentes n√≠veis de toler√¢ncia"""
        # Toler√¢ncia 0% (exata)
        auditor_strict = DataAuditor(tolerance_percentage=0.0)
        result = auditor_strict.compare_numeric_values(100.0, 100.1, 'VALOR')
        assert result.is_match is False
        
        # Toler√¢ncia 5%
        auditor_loose = DataAuditor(tolerance_percentage=0.05)
        result = auditor_loose.compare_numeric_values(100.0, 100.1, 'VALOR')
        assert result.is_match is True  # 0.1% < 5%
    
    def test_empty_dataframes(self, temp_dir):
        """Testa auditoria com DataFrames vazios"""
        # Cria DataFrames vazios mas com colunas
        empty_csv = pd.DataFrame(columns=['numero_os', 'valor_total'])
        empty_excel = pd.DataFrame(columns=['N¬∞ OS', 'VALOR TOTAL'])
        
        csv_file = os.path.join(temp_dir, "empty.csv")
        excel_file = os.path.join(temp_dir, "empty.xlsx")
        
        empty_csv.to_csv(csv_file, index=False)
        empty_excel.to_excel(excel_file, index=False)
        
        auditor = DataAuditor()
        field_mappings = {'numero_os': 'N¬∞ OS'}
        
        summary, results = auditor.audit_data(
            csv_file_path=csv_file,
            generated_file_path=excel_file,
            field_mappings=field_mappings,
            key_field='numero_os'
        )
        
        assert summary.total_records == 0
        assert summary.matching_records == 0
        assert summary.mismatched_records == 0 

================================================================================
ARQUIVO 24/24: tests\test_exporters.py
TAMANHO: 13.94 KB
================================================================================

import pytest
import pandas as pd
import os
from openpyxl import load_workbook
from modules.exporters import export_to_excel
from style_config import COLUMN_WIDTHS, BORDER_CONFIGS, THEMES
from openpyxl.utils import get_column_letter


class TestExcelExport:
    """Testes para a funcionalidade de exporta√ß√£o Excel"""
    
    @pytest.fixture
    def sample_data(self):
        """Dados de exemplo para testes"""
        return {
            '2024-01': pd.DataFrame({
                'N¬∞ OS': ['001', '002'],
                'DATA ENCERRAMENTO': ['2024-01-15', '2024-01-16'],
                'VALOR TOTAL': [1000.50, 2500.75],
                'VALOR M√ÉO DE OBRA': [500.25, 1200.00],
                'VALOR PE√áAS': [500.25, 1300.75],
                'DESCONTO': [0.00, 100.00],
                'VE√çCULO (PLACA)': ['ABC1234', 'XYZ5678'],
                'C√ìDIGO CLIENTE': ['CLI001', 'CLI002'],
                'VALOR PAGO': [1000.50, 2400.75],
                'DEVEDOR': [0.00, 100.00],
                'CART√ÉO': [500.25, 1200.00],
                'DINHEIRO': [300.25, 800.75],
                'PIX': [200.00, 400.00],
                'TROCO': [0.00, 0.00],
                'DATA PGTO': ['2024-01-15', '2024-01-16']
            })
        }
    
    @pytest.fixture
    def output_dir(self, tmp_path):
        """Diret√≥rio tempor√°rio para testes"""
        return str(tmp_path / "test_output")
    
    def test_excel_file_creation(self, sample_data, output_dir):
        """Testa se o arquivo Excel √© criado corretamente"""
        export_to_excel(sample_data, output_dir)
        
        # Verifica se o arquivo foi criado
        expected_file = os.path.join(output_dir, "Recebimentos_2024-01.xlsx")
        assert os.path.exists(expected_file), "Arquivo Excel n√£o foi criado"
    
    def test_worksheet_creation(self, sample_data, output_dir):
        """Testa se a planilha √© criada com o nome correto"""
        export_to_excel(sample_data, output_dir)
        
        file_path = os.path.join(output_dir, "Recebimentos_2024-01.xlsx")
        wb = load_workbook(file_path)
        
        # Verifica se a planilha existe
        assert "2024-01" in wb.sheetnames, "Planilha n√£o foi criada com o nome correto"
        
        ws = wb["2024-01"]
        assert ws is not None, "Planilha n√£o foi encontrada"
    
    def test_data_integrity(self, sample_data, output_dir):
        """Testa se os dados foram exportados corretamente"""
        export_to_excel(sample_data, output_dir)
        
        file_path = os.path.join(output_dir, "Recebimentos_2024-01.xlsx")
        wb = load_workbook(file_path)
        ws = wb["2024-01"]
        
        # Verifica se os dados est√£o corretos
        assert ws['A1'].value == 'N¬∞ OS', "Cabe√ßalho N¬∞ OS n√£o encontrado"
        assert ws['A2'].value == '001', "Primeiro valor N¬∞ OS incorreto"
        assert ws['A3'].value == '002', "Segundo valor N¬∞ OS incorreto"
    
    def test_currency_formatting(self, sample_data, output_dir):
        """Testa se as colunas cont√°beis recebem formata√ß√£o de moeda"""
        export_to_excel(sample_data, output_dir)
        
        file_path = os.path.join(output_dir, "Recebimentos_2024-01.xlsx")
        wb = load_workbook(file_path)
        ws = wb["2024-01"]
        
        # Verifica se a coluna VALOR TOTAL tem formata√ß√£o de moeda
        valor_total_cell = ws['C2']  # VALOR TOTAL, primeira linha de dados
        assert valor_total_cell.number_format == 'R$ #,##0.00', "Formata√ß√£o de moeda n√£o aplicada"
    
    def test_header_styling(self, sample_data, output_dir):
        """Testa se o cabe√ßalho recebe a formata√ß√£o correta"""
        export_to_excel(sample_data, output_dir)
        
        file_path = os.path.join(output_dir, "Recebimentos_2024-01.xlsx")
        wb = load_workbook(file_path)
        ws = wb["2024-01"]
        
        # Verifica estilo do cabe√ßalho
        header_cell = ws['A1']
        expected_bg = THEMES['default']['header_bg']
        expected_font = THEMES['default']['header_font']
        
        # openpyxl adiciona '00' no in√≠cio (alpha channel)
        assert header_cell.fill.start_color.rgb[2:] == expected_bg, "Cor de fundo do cabe√ßalho incorreta"
        assert header_cell.font.color.rgb[2:] == expected_font, "Cor da fonte do cabe√ßalho incorreta"
        assert header_cell.font.bold, "Cabe√ßalho n√£o est√° em negrito"
    
    def test_contabil_styling(self, sample_data, output_dir):
        """Testa se as c√©lulas cont√°beis recebem a formata√ß√£o correta"""
        export_to_excel(sample_data, output_dir)
        
        file_path = os.path.join(output_dir, "Recebimentos_2024-01.xlsx")
        wb = load_workbook(file_path)
        ws = wb["2024-01"]
        
        # Verifica estilo das c√©lulas cont√°beis
        contabil_cell = ws['C2']  # VALOR TOTAL, primeira linha de dados
        expected_bg = THEMES['default']['contabil_bg']
        expected_font = THEMES['default']['contabil_font']
        
        # openpyxl adiciona '00' no in√≠cio (alpha channel)
        assert contabil_cell.fill.start_color.rgb[2:] == expected_bg, "Cor de fundo cont√°bil incorreta"
        assert contabil_cell.font.color.rgb[2:] == expected_font, "Cor da fonte cont√°bil incorreta"
    
    def test_column_widths(self, sample_data, output_dir):
        """Testa se as larguras das colunas s√£o aplicadas corretamente"""
        export_to_excel(sample_data, output_dir)
        
        file_path = os.path.join(output_dir, "Recebimentos_2024-01.xlsx")
        wb = load_workbook(file_path)
        ws = wb["2024-01"]
        
        # Verifica larguras das colunas
        for col_name, expected_width in COLUMN_WIDTHS.items():
            if col_name != 'default':
                # Encontra o √≠ndice da coluna
                col_idx = None
                for idx, cell in enumerate(ws[1], 1):
                    if cell.value == col_name:
                        col_idx = idx
                        break
                
                if col_idx:
                    col_letter = ws.cell(row=1, column=col_idx).column_letter
                    actual_width = ws.column_dimensions[col_letter].width
                    assert actual_width == expected_width, f"Largura da coluna {col_name} incorreta"
    
    def test_border_styling(self, sample_data, output_dir):
        """Testa se as bordas s√£o aplicadas corretamente"""
        export_to_excel(sample_data, output_dir, border_theme='default')
        
        file_path = os.path.join(output_dir, "Recebimentos_2024-01.xlsx")
        wb = load_workbook(file_path)
        ws = wb["2024-01"]
        
        # Verifica bordas do cabe√ßalho
        header_cell = ws['A1']
        border_config = BORDER_CONFIGS['default']
        
        if border_config['header_border']:
            assert header_cell.border.left.style == border_config['header_border'], "Borda esquerda do cabe√ßalho incorreta"
            assert header_cell.border.right.style == border_config['header_border'], "Borda direita do cabe√ßalho incorreta"
            assert header_cell.border.top.style == border_config['header_border'], "Borda superior do cabe√ßalho incorreta"
            assert header_cell.border.bottom.style == border_config['header_border'], "Borda inferior do cabe√ßalho incorreta"
    
    def test_border_colors(self, sample_data, output_dir):
        """Testa se as cores das bordas s√£o aplicadas corretamente"""
        export_to_excel(sample_data, output_dir, border_theme='corporate')
        
        file_path = os.path.join(output_dir, "Recebimentos_2024-01.xlsx")
        wb = load_workbook(file_path)
        ws = wb["2024-01"]
        
        # Verifica cor das bordas
        header_cell = ws['A1']
        border_config = BORDER_CONFIGS['corporate']
        
        if border_config['header_border']:
            expected_color = border_config['border_color']
            # openpyxl adiciona '00' no in√≠cio (alpha channel)
            assert header_cell.border.left.color.rgb[2:] == expected_color, "Cor da borda esquerda incorreta"
            assert header_cell.border.right.color.rgb[2:] == expected_color, "Cor da borda direita incorreta"
            assert header_cell.border.top.color.rgb[2:] == expected_color, "Cor da borda superior incorreta"
            assert header_cell.border.bottom.color.rgb[2:] == expected_color, "Cor da borda inferior incorreta"
    
    def test_multiple_border_themes(self, sample_data, output_dir):
        """Testa diferentes temas de bordas"""
        themes_to_test = ['default', 'corporate', 'dark', 'minimal']
        
        for theme in themes_to_test:
            # Limpa diret√≥rio para cada teste
            if os.path.exists(output_dir):
                for file in os.listdir(output_dir):
                    os.remove(os.path.join(output_dir, file))
            
            export_to_excel(sample_data, output_dir, border_theme=theme)
            
            file_path = os.path.join(output_dir, "Recebimentos_2024-01.xlsx")
            assert os.path.exists(file_path), f"Arquivo n√£o criado para tema {theme}"
            
            wb = load_workbook(file_path)
            ws = wb["2024-01"]
            
            # Verifica se pelo menos o cabe√ßalho tem bordas (exceto minimal)
            header_cell = ws['A1']
            if theme != 'minimal':
                assert header_cell.border.left.style is not None, f"Bordas n√£o aplicadas para tema {theme}"
    
    def test_currency_formats(self, sample_data, output_dir):
        """Testa diferentes formatos de moeda"""
        currencies = ['BRL', 'USD', 'EUR']
        
        for currency in currencies:
            # Limpa diret√≥rio para cada teste
            if os.path.exists(output_dir):
                for file in os.listdir(output_dir):
                    os.remove(os.path.join(output_dir, file))
            
            export_to_excel(sample_data, output_dir, currency=currency)
            
            file_path = os.path.join(output_dir, "Recebimentos_2024-01.xlsx")
            wb = load_workbook(file_path)
            ws = wb["2024-01"]
            
            # Verifica formato de moeda
            valor_cell = ws['C2']  # VALOR TOTAL
            if currency == 'BRL':
                assert valor_cell.number_format == 'R$ #,##0.00', "Formato BRL incorreto"
            elif currency == 'USD':
                assert valor_cell.number_format == 'US$ #,##0.00', "Formato USD incorreto"
            elif currency == 'EUR':
                assert valor_cell.number_format == '‚Ç¨ #,##0.00', "Formato EUR incorreto"
    
    def test_theme_colors(self, sample_data, output_dir):
        """Testa diferentes temas de cores"""
        themes_to_test = ['default', 'dark']
        
        for theme in themes_to_test:
            # Limpa diret√≥rio para cada teste
            if os.path.exists(output_dir):
                for file in os.listdir(output_dir):
                    os.remove(os.path.join(output_dir, file))
            
            export_to_excel(sample_data, output_dir, theme=theme)
            
            file_path = os.path.join(output_dir, "Recebimentos_2024-01.xlsx")
            wb = load_workbook(file_path)
            ws = wb["2024-01"]
            
            # Verifica cores do tema
            header_cell = ws['A1']
            theme_config = THEMES[theme]
            
            # openpyxl adiciona '00' no in√≠cio (alpha channel)
            assert header_cell.fill.start_color.rgb[2:] == theme_config['header_bg'], f"Cor de fundo do cabe√ßalho incorreta para tema {theme}"
            assert header_cell.font.color.rgb[2:] == theme_config['header_font'], f"Cor da fonte do cabe√ßalho incorreta para tema {theme}"
    
    def test_empty_dataframe(self, output_dir):
        """Testa exporta√ß√£o com DataFrame vazio"""
        empty_data = {'2024-01': pd.DataFrame()}
        
        export_to_excel(empty_data, output_dir)
        
        file_path = os.path.join(output_dir, "Recebimentos_2024-01.xlsx")
        assert os.path.exists(file_path), "Arquivo n√£o criado para DataFrame vazio"
        
        wb = load_workbook(file_path)
        ws = wb["2024-01"]
        
        # Verifica se a planilha existe mesmo vazia
        assert ws is not None, "Planilha n√£o criada para DataFrame vazio"
    
    def test_invalid_output_dir(self, sample_data):
        """Testa comportamento com diret√≥rio de sa√≠da inv√°lido"""
        invalid_dir = "/caminho/inexistente/para/teste"
        
        # Deve criar o diret√≥rio automaticamente
        export_to_excel(sample_data, invalid_dir)
        
        # Verifica se o diret√≥rio foi criado
        assert os.path.exists(invalid_dir), "Diret√≥rio n√£o foi criado automaticamente"
        
        # Limpa ap√≥s o teste
        import shutil
        shutil.rmtree(invalid_dir, ignore_errors=True)

    def test_column_widths_auto(self, sample_data, output_dir):
        """Testa se as larguras das colunas s√£o aplicadas corretamente"""
        export_to_excel(sample_data, output_dir)
        
        file_path = os.path.join(output_dir, "Recebimentos_2024-01.xlsx")
        wb = load_workbook(file_path)
        ws = wb["2024-01"]
        
        # Verifica larguras das colunas
        for col in range(1, len(sample_data['2024-01']) + 1):
            column_name = sample_data['2024-01'].columns[col - 1]
            # Largura sugerida pelo style_config
            width = COLUMN_WIDTHS.get(column_name, COLUMN_WIDTHS['default'])
            # Largura baseada no conte√∫do
            max_content_width = max(
                [len(str(cell)) for cell in [column_name] + sample_data['2024-01'][column_name].astype(str).tolist()]
            )
            # Ajusta para o maior valor entre o sugerido e o necess√°rio (+2 para margem)
            final_width = max(width, max_content_width + 2)
            ws.column_dimensions[get_column_letter(col)].width = final_width 
